{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95165149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T13:53:18.454201Z",
     "iopub.status.busy": "2025-12-06T13:53:18.453622Z",
     "iopub.status.idle": "2025-12-06T13:53:27.275641Z",
     "shell.execute_reply": "2025-12-06T13:53:27.275007Z"
    },
    "papermill": {
     "duration": 8.829262,
     "end_time": "2025-12-06T13:53:27.277189",
     "exception": false,
     "start_time": "2025-12-06T13:53:18.447927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.set_default_dtype(torch.float64)\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from scipy.stats import qmc\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c07793e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T13:53:27.285953Z",
     "iopub.status.busy": "2025-12-06T13:53:27.285229Z",
     "iopub.status.idle": "2025-12-06T13:53:27.339840Z",
     "shell.execute_reply": "2025-12-06T13:53:27.339197Z"
    },
    "papermill": {
     "duration": 0.060086,
     "end_time": "2025-12-06T13:53:27.341033",
     "exception": false,
     "start_time": "2025-12-06T13:53:27.280947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d21574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T13:53:27.349353Z",
     "iopub.status.busy": "2025-12-06T13:53:27.349111Z",
     "iopub.status.idle": "2025-12-06T13:53:27.355890Z",
     "shell.execute_reply": "2025-12-06T13:53:27.355289Z"
    },
    "papermill": {
     "duration": 0.012108,
     "end_time": "2025-12-06T13:53:27.357057",
     "exception": false,
     "start_time": "2025-12-06T13:53:27.344949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DNN1(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN1, self).__init__()\n",
    "        \n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        # 设置激活函数\n",
    "        self.activation1 = torch.nn.Tanh\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation1()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        \n",
    "        # # 使用Lambda层实现 -exp(x)\n",
    "        # layer_list.append(('output_activation', LambdaLayer(lambda x: -torch.exp(x))))\n",
    "        \n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # 部署层\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.layers(X)\n",
    "        return out\n",
    "    \n",
    "    def weights_init(m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8aed53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T13:53:27.365074Z",
     "iopub.status.busy": "2025-12-06T13:53:27.364836Z",
     "iopub.status.idle": "2025-12-06T13:53:27.383332Z",
     "shell.execute_reply": "2025-12-06T13:53:27.382607Z"
    },
    "papermill": {
     "duration": 0.024164,
     "end_time": "2025-12-06T13:53:27.384609",
     "exception": false,
     "start_time": "2025-12-06T13:53:27.360445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the physics-guided neural network\n",
    "class PINN_theta(torch.nn.Module):\n",
    "    def __init__(self, X_ub,X_lb,X_ic,X_res,u_ic,v_ic,alpha,beta,gamma,layers):\n",
    "        super(PINN_theta, self).__init__()\n",
    "        \n",
    "        # data\n",
    "        self.z_ub = torch.tensor(X_ub[:, 0:1], requires_grad=True).double().to(device)\n",
    "        self.t_ub = torch.tensor(X_ub[:, 1:2], requires_grad=True).double().to(device)\n",
    "\n",
    "        self.z_lb = torch.tensor(X_lb[:, 0:1], requires_grad=True).double().to(device)\n",
    "        self.t_lb = torch.tensor(X_lb[:, 1:2], requires_grad=True).double().to(device)\n",
    "\n",
    "        self.z_ic = torch.tensor(X_ic[:, 0:1], requires_grad=True).double().to(device)\n",
    "        self.t_ic = torch.tensor(X_ic[:, 1:2], requires_grad=True).double().to(device)\n",
    "        self.u_ic = torch.tensor(u_ic).double().to(device)\n",
    "        self.v_ic = torch.tensor(v_ic).double().to(device)\n",
    "\n",
    "        self.z_res = torch.tensor(X_res[:, 0:1], requires_grad=True).double().to(device)\n",
    "        self.t_res = torch.tensor(X_res[:, 1:2], requires_grad=True).double().to(device)\n",
    "\n",
    "        self.alpha = torch.tensor(alpha).double().to(device)\n",
    "        self.beta = torch.tensor(beta).double().to(device)\n",
    "        self.gamma = torch.tensor(gamma).double().to(device)\n",
    "\n",
    "\n",
    "        self.layers_theta = layers\n",
    "        self.dnn_theta = DNN1(layers).to(device)\n",
    "\n",
    "        self.iter = 0\n",
    "        #self.pre_iter = 0\n",
    "\n",
    "        self.optimizer1 = torch.optim.Adam(self.dnn_theta.parameters(),lr=1e-3)\n",
    "\n",
    "        self.optimizer2 = torch.optim.LBFGS(\n",
    "            self.dnn_theta.parameters(), \n",
    "            lr=1.0, #步长缩放因子，用于控制拟牛顿算法中搜索的步长\n",
    "            max_iter=40000, #最大迭代次数\n",
    "            max_eval=40000, #函数和梯度最大评估次数\n",
    "            history_size=50, #存储和更新历史信息的缓存大小\n",
    "            tolerance_grad=1e-7, #表示梯度的容差，即梯度的变化小于该容差时，算法将终止\n",
    "            tolerance_change=1.0 * np.finfo(float).eps, #表示优化变化的容差，即参数变化量的绝对值小于该容差时，算法将终止\n",
    "            line_search_fn=\"strong_wolfe\" #can be \"strong_wolfe\"\n",
    "        )\n",
    "\n",
    "        self.loss_history = {\n",
    "            'total': [],\n",
    "            'residual': [],\n",
    "            'ic': [],\n",
    "            'b': []\n",
    "        }\n",
    "\n",
    "    def net_h(self, z, t):  \n",
    "        H = self.dnn_theta(torch.cat([z, t], dim=1))\n",
    "        u = H[:, 0:1]\n",
    "        v = H[:, 1:2]\n",
    "        return u,v\n",
    "        \n",
    "    def gradient(self, y, x):\n",
    "        return torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    def net_b(self, z, t):\n",
    "\n",
    "        u,v = self.net_h(z, t)\n",
    "        u_z = self.gradient(u, z)\n",
    "        v_z = self.gradient(v, z)\n",
    "\n",
    "        return u, v, u_z, v_z            \n",
    "    \n",
    "    def net_ic(self, z, t):\n",
    "\n",
    "        u, v = self.net_h(z, t)\n",
    "\n",
    "        return u, v      \n",
    "    \n",
    "    def net_f(self, z, t):\n",
    "\n",
    "        u,v = self.net_h(z, t)\n",
    "        v_t = self.gradient(v, t)\n",
    "        v_z = self.gradient(v, z)\n",
    "\n",
    "        u_t = self.gradient(u, t)\n",
    "        u_z = self.gradient(u, z)\n",
    "        u_zz = self.gradient(u_z, z)\n",
    "        u_zzz = self.gradient(u_zz, z)\n",
    "\n",
    "        f1 = u_t - v_z\n",
    "        f2 = v_t + self.alpha * u_z + self.beta * (2*u*u_z) + self.gamma * u_zzz\n",
    "\n",
    "        return f1, f2\n",
    "\n",
    "    def loss_func(self):\n",
    "\n",
    "        self.optimizer1.zero_grad()\n",
    "        self.optimizer2.zero_grad()\n",
    "\n",
    "        u_ic_pred, v_ic_pred = self.net_ic(self.z_ic, self.t_ic)\n",
    "\n",
    "        u_ub_pred, v_ub_pred, u_z_ub_pred, v_z_ub_pred = self.net_b(self.z_ub, self.t_ub)\n",
    "\n",
    "        u_lb_pred, v_lb_pred, u_z_lb_pred, v_z_lb_pred = self.net_b(self.z_lb, self.t_lb)\n",
    "\n",
    "        f1_res_pred, f2_res_pred = self.net_f(self.z_res, self.t_res)\n",
    "\n",
    "        loss_res1 = torch.mean(f1_res_pred**2)\n",
    "        loss_res2 = torch.mean(f2_res_pred**2)\n",
    "        loss_res = loss_res1 + loss_res2\n",
    "        \n",
    "        loss_ic1 = torch.mean((u_ic_pred - self.u_ic)**2)\n",
    "        loss_ic2 = torch.mean((v_ic_pred - self.v_ic)**2)\n",
    "        loss_b1 = torch.mean((u_ub_pred - u_lb_pred)**2)\n",
    "        loss_b2 = torch.mean((v_ub_pred - v_lb_pred)**2)\n",
    "        loss_b3 = torch.mean((u_z_ub_pred - u_z_lb_pred)**2)\n",
    "        loss_b4 = torch.mean((v_z_ub_pred - v_z_lb_pred)**2)\n",
    "\n",
    "        loss_ic = loss_ic1 + loss_ic2\n",
    "        loss_b = loss_b1 + loss_b2 + loss_b3 + loss_b4\n",
    "\n",
    "        loss = loss_res + loss_ic1 + loss_ic2 + loss_b1 + loss_b2 + loss_b3 + loss_b4\n",
    "        \n",
    "        loss.backward()\n",
    "        self.iter += 1\n",
    "        if self.iter % 100 == 0:\n",
    "            self.loss_history['total'].append(loss.item())\n",
    "            self.loss_history['residual'].append(loss_res.item())\n",
    "            self.loss_history['ic'].append(loss_ic.item())\n",
    "            self.loss_history['b'].append(loss_b.item())   \n",
    "            print(\n",
    "                'Iter %d, Loss: %.5e, Loss_res: %.5e, Loss_ic1: %.5e, Loss_ic2: %.5e, Loss_b1: %.5e, Loss_b2: %.5e, Loss_b3: %.5e, Loss_b4: %.5e' % \n",
    "                (   self.iter, \n",
    "                    loss.item(), \n",
    "                    loss_res.item(), \n",
    "                    loss_ic1.item(),\n",
    "                    loss_ic2.item(), \n",
    "                    loss_b1.item(),\n",
    "                    loss_b2.item(),\n",
    "                    loss_b3.item(),\n",
    "                    loss_b4.item()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def train(self):\n",
    "        self.dnn_theta.train()\n",
    "        print(\"采用Adam优化器\")\n",
    "        for i in range(20000):\n",
    "            self.optimizer1.step(self.loss_func)\n",
    "        # 然后运行lbfgs优化器\n",
    "        print(\"采用L-BFGS优化器\")\n",
    "        self.optimizer2.step(self.loss_func) \n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        z = torch.tensor(X[:, 0:1], requires_grad=True).double().to(device)\n",
    "        t = torch.tensor(X[:, 1:2], requires_grad=True).double().to(device)\n",
    "\n",
    "        self.dnn_theta.eval()\n",
    "        u,v = self.net_h(z, t)\n",
    "        u = u.detach().cpu().numpy()\n",
    "        v = v.detach().cpu().numpy()\n",
    "\n",
    "        return u, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb83173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T13:53:27.392719Z",
     "iopub.status.busy": "2025-12-06T13:53:27.392111Z",
     "iopub.status.idle": "2025-12-06T13:53:27.395665Z",
     "shell.execute_reply": "2025-12-06T13:53:27.395105Z"
    },
    "papermill": {
     "duration": 0.008721,
     "end_time": "2025-12-06T13:53:27.396756",
     "exception": false,
     "start_time": "2025-12-06T13:53:27.388035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alpha = -1\n",
    "# beta = -3\n",
    "# gamma = -1\n",
    "\n",
    "# N_res = 1000\n",
    "# N_b = 100\n",
    "# N_ic = 100\n",
    "\n",
    "# x = np.linspace(-15, 15, 201)\n",
    "# t = np.linspace(0, 5, 201) \n",
    "# x_mesh, t_mesh = np.meshgrid(x, t)\n",
    "\n",
    "# X = np.hstack((x_mesh.flatten()[:,None], t_mesh.flatten()[:,None]))\n",
    "\n",
    "# lb = X.min(0) #下界x'QxQ\n",
    "# ub = X.max(0)  #上界 \n",
    "\n",
    "# def lhs(n, size):\n",
    "#     \"\"\"生成n维拉丁超立方采样，返回size个样本点\"\"\"\n",
    "#     sampler = qmc.LatinHypercube(d=n)\n",
    "#     return sampler.random(n=size)\n",
    "\n",
    "# # 使用简洁形式进行采样（与你要求的形式一致）\n",
    "# X_res = lb + (ub - lb) * lhs(2, N_res)  # 2维残差点采样\n",
    "\n",
    "# t_samples = lb[1] + (ub[1] - lb[1]) * lhs(1, N_b)  # 时间t的采样：[N_b, 1]\n",
    "\n",
    "# # 上边界点（x=ub[0]，与下边界对称）\n",
    "# X_ub = np.hstack((ub[0] * np.ones((N_b, 1)),t_samples))\n",
    "# X_lb = np.hstack((lb[0] * np.ones((N_b, 1)),t_samples))\n",
    "\n",
    "# X_ic = np.hstack((lb[0] + (ub[0] - lb[0]) * lhs(1, N_ic), \n",
    "#                   lb[1] * np.ones((N_ic, 1))))  # 初始条件点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bae6ace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T13:53:27.404136Z",
     "iopub.status.busy": "2025-12-06T13:53:27.403917Z",
     "iopub.status.idle": "2025-12-06T13:53:27.437200Z",
     "shell.execute_reply": "2025-12-06T13:53:27.436624Z"
    },
    "papermill": {
     "duration": 0.038577,
     "end_time": "2025-12-06T13:53:27.438589",
     "exception": false,
     "start_time": "2025-12-06T13:53:27.400012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = -1\n",
    "beta = -3\n",
    "gamma = -1\n",
    "\n",
    "x = np.linspace(-15, 15, 301)\n",
    "t = np.linspace(0, 5, 201) \n",
    "x_mesh, t_mesh = np.meshgrid(x, t)\n",
    "\n",
    "X = np.hstack((x_mesh.flatten()[:,None], t_mesh.flatten()[:,None]))\n",
    "\n",
    "lb = X.min(0) #下界x'QxQ\n",
    "ub = X.max(0)  #上界 \n",
    "\n",
    "df_h = np.load(\"/kaggle/input/bq-soliton-residual-0-15-10000points/residual_10000.npz\")\n",
    "X_res = df_h['X_res']\n",
    "X_ub = df_h['X_ub']\n",
    "X_lb = df_h['X_lb']\n",
    "X_ic = df_h['X_ic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43e37e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T13:53:27.447009Z",
     "iopub.status.busy": "2025-12-06T13:53:27.446759Z",
     "iopub.status.idle": "2025-12-06T13:53:27.693247Z",
     "shell.execute_reply": "2025-12-06T13:53:27.692662Z"
    },
    "papermill": {
     "duration": 0.252489,
     "end_time": "2025-12-06T13:53:27.694603",
     "exception": false,
     "start_time": "2025-12-06T13:53:27.442114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func_u(X):\n",
    "    x, t = X[:, 0:1], X[:, 1:2]\n",
    "    zeta = 1/6\n",
    "    y1 = 0\n",
    "    y2 = 0\n",
    "    y3 = 2\n",
    "    k1 = 1\n",
    "    k2 = 1\n",
    "    k3 = 5/4\n",
    "    varsigma1 = -2\n",
    "    varsigma2 = 4\n",
    "    varsigma3 = -4\n",
    "\n",
    "    u=-alpha/(2*beta) + zeta + 6*gamma*(-k1**2*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + varsigma1) - k2**2*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma2) - k3**2*np.exp(k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma3) + (k1 + k2)**2*(2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma1 + varsigma2)/(2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2) + (k1 + k3)**2*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma3)/(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (k2 + k3)**2*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma2 + varsigma3)/(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (k1 + k2 + k3)**2*(2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma2 + varsigma3)/((2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)) - (-k1*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + varsigma1) - k2*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma2) - k3*np.exp(k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma3) + (k1 + k2)*(2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma1 + varsigma2)/(2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2) + (k1 + k3)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma3)/(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (k2 + k3)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma2 + varsigma3)/(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (k1 + k2 + k3)*(2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma2 + varsigma3)/((2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)))**2/((2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma2 + varsigma3)/((2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)) + (2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma1 + varsigma2)/(2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2) + (2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma3)/(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma2 + varsigma3)/(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) - np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + varsigma1) - np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma2) - np.exp(k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma3) - 1))/(beta*((2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma2 + varsigma3)/((2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)) + (2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma1 + varsigma2)/(2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2) + (2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma3)/(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma2 + varsigma3)/(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) - np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + varsigma1) - np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma2) - np.exp(k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma3) - 1))\n",
    "    return u\n",
    "\n",
    "def func_v(X):\n",
    "    x, t = X[:, 0:1], X[:, 1:2]\n",
    "    zeta = 1/6\n",
    "    y1 = 0\n",
    "    y2 = 0\n",
    "    y3 = 2\n",
    "    k1 = 1\n",
    "    k2 = 1\n",
    "    k3 = 5/4\n",
    "    varsigma1 = -2\n",
    "    varsigma2 = 4\n",
    "    varsigma3 = -4\n",
    "\n",
    "    v=6*gamma*(-k1**2*np.sqrt(-2*beta*zeta - gamma*k1**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + varsigma1) + k2**2*np.sqrt(-2*beta*zeta - gamma*k2**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma2) - k3**2*np.sqrt(-2*beta*zeta - gamma*k3**2)*np.exp(k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma3) + (k1 + k2)*(k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))*(2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma1 + varsigma2)/(2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2) + (k1 + k3)*(k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma3)/(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) - (k2 + k3)*(k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma2 + varsigma3)/(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (k1 + k2 + k3)*(k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))*(2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma2 + varsigma3)/((2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)) - (-k1*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + varsigma1) - k2*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma2) - k3*np.exp(k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma3) + (k1 + k2)*(2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma1 + varsigma2)/(2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2) + (k1 + k3)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma3)/(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (k2 + k3)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma2 + varsigma3)/(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (k1 + k2 + k3)*(2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma2 + varsigma3)/((2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)))*(-k1*np.sqrt(-2*beta*zeta - gamma*k1**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + varsigma1) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2)*np.exp(k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma3) + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))*(2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma1 + varsigma2)/(2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2) + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma3)/(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) - (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma2 + varsigma3)/(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))*(2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma2 + varsigma3)/((2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)))/((2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma2 + varsigma3)/((2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)) + (2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma1 + varsigma2)/(2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2) + (2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma3)/(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma2 + varsigma3)/(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) - np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + varsigma1) - np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma2) - np.exp(k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma3) - 1))/(beta*((2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma2 + varsigma3)/((2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)) + (2*beta*zeta*(k1 - k2)**2 + gamma*(k1 - k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) - k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma1 + varsigma2)/(2*beta*zeta*(k1 + k2)**2 + gamma*(k1 + k2)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k2*np.sqrt(-2*beta*zeta - gamma*k2**2))**2) + (2*beta*zeta*(k1 - k3)**2 + gamma*(k1 - k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma1 + varsigma3)/(2*beta*zeta*(k1 + k3)**2 + gamma*(k1 + k3)**4 + (k1*np.sqrt(-2*beta*zeta - gamma*k1**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) + (2*beta*zeta*(k2 - k3)**2 + gamma*(k2 - k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) + k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2)*np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma2 + varsigma3)/(2*beta*zeta*(k2 + k3)**2 + gamma*(k2 + k3)**4 + (k2*np.sqrt(-2*beta*zeta - gamma*k2**2) - k3*np.sqrt(-2*beta*zeta - gamma*k3**2))**2) - np.exp(k1*t*np.sqrt(-2*beta*zeta - gamma*k1**2) + k1*(x + y1) + varsigma1) - np.exp(-k2*t*np.sqrt(-2*beta*zeta - gamma*k2**2) + k2*(x + y2) + varsigma2) - np.exp(k3*t*np.sqrt(-2*beta*zeta - gamma*k3**2) + k3*(x + y3) + varsigma3) - 1))\n",
    "    return v\n",
    "\n",
    "u_ic = func_u(X_ic)\n",
    "v_ic = func_v(X_ic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51ee70d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T13:53:27.702404Z",
     "iopub.status.busy": "2025-12-06T13:53:27.702127Z",
     "iopub.status.idle": "2025-12-06T13:53:30.367131Z",
     "shell.execute_reply": "2025-12-06T13:53:30.366155Z"
    },
    "papermill": {
     "duration": 2.670445,
     "end_time": "2025-12-06T13:53:30.368532",
     "exception": false,
     "start_time": "2025-12-06T13:53:27.698087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "layers = [2] + 6 * [31] + [2]\n",
    "model = PINN_theta(X_ub,X_lb,X_ic,X_res,u_ic,v_ic,alpha,beta,gamma,layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31132df2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T13:53:30.376666Z",
     "iopub.status.busy": "2025-12-06T13:53:30.376036Z",
     "iopub.status.idle": "2025-12-06T13:53:30.381083Z",
     "shell.execute_reply": "2025-12-06T13:53:30.380289Z"
    },
    "papermill": {
     "duration": 0.010193,
     "end_time": "2025-12-06T13:53:30.382229",
     "exception": false,
     "start_time": "2025-12-06T13:53:30.372036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型可训练参数总个数: 5,117\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"计算模型中可训练参数的总个数\"\"\"\n",
    "    total_params = 0\n",
    "    for param in model.parameters():\n",
    "        # 累加每个参数张量的元素数量\n",
    "        total_params += param.numel()\n",
    "    return total_params\n",
    "\n",
    "param_count = count_parameters(model)\n",
    "print(f\"模型可训练参数总个数: {param_count:,}\")  # 使用逗号作为千位分隔符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "540609fe",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-06T13:53:30.390211Z",
     "iopub.status.busy": "2025-12-06T13:53:30.389526Z",
     "iopub.status.idle": "2025-12-06T14:30:10.138460Z",
     "shell.execute_reply": "2025-12-06T14:30:10.137659Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2199.754102,
     "end_time": "2025-12-06T14:30:10.139770",
     "exception": false,
     "start_time": "2025-12-06T13:53:30.385668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "采用Adam优化器\n",
      "Iter 100, Loss: 4.54002e-02, Loss_res: 5.74481e-03, Loss_ic1: 1.49478e-02, Loss_ic2: 2.31246e-02, Loss_b1: 2.68259e-04, Loss_b2: 1.19921e-03, Loss_b3: 8.76893e-05, Loss_b4: 2.78227e-05\n",
      "Iter 200, Loss: 3.25150e-02, Loss_res: 3.12129e-03, Loss_ic1: 9.75096e-03, Loss_ic2: 1.91590e-02, Loss_b1: 1.13102e-04, Loss_b2: 1.44144e-04, Loss_b3: 1.16580e-04, Loss_b4: 1.09929e-04\n",
      "Iter 300, Loss: 2.88335e-02, Loss_res: 2.52045e-03, Loss_ic1: 7.96223e-03, Loss_ic2: 1.76221e-02, Loss_b1: 7.12682e-05, Loss_b2: 3.55307e-04, Loss_b3: 1.30681e-04, Loss_b4: 1.71532e-04\n",
      "Iter 400, Loss: 2.59867e-02, Loss_res: 2.29560e-03, Loss_ic1: 7.02941e-03, Loss_ic2: 1.58591e-02, Loss_b1: 1.07978e-05, Loss_b2: 4.35152e-04, Loss_b3: 1.51505e-04, Loss_b4: 2.05085e-04\n",
      "Iter 500, Loss: 2.30621e-02, Loss_res: 2.15278e-03, Loss_ic1: 6.31613e-03, Loss_ic2: 1.40798e-02, Loss_b1: 2.82064e-05, Loss_b2: 5.58415e-05, Loss_b3: 1.72040e-04, Loss_b4: 2.57301e-04\n",
      "Iter 600, Loss: 2.03822e-02, Loss_res: 1.99529e-03, Loss_ic1: 5.62118e-03, Loss_ic2: 1.20890e-02, Loss_b1: 2.58152e-05, Loss_b2: 1.81665e-04, Loss_b3: 1.81032e-04, Loss_b4: 2.88276e-04\n",
      "Iter 700, Loss: 2.06615e-02, Loss_res: 2.14593e-03, Loss_ic1: 5.17894e-03, Loss_ic2: 1.10198e-02, Loss_b1: 1.32426e-04, Loss_b2: 1.75964e-03, Loss_b3: 1.59529e-04, Loss_b4: 2.65236e-04\n",
      "Iter 800, Loss: 1.39091e-02, Loss_res: 1.93865e-03, Loss_ic1: 4.14245e-03, Loss_ic2: 7.07059e-03, Loss_b1: 4.69155e-05, Loss_b2: 1.49591e-04, Loss_b3: 2.04041e-04, Loss_b4: 3.56903e-04\n",
      "Iter 900, Loss: 1.26230e-02, Loss_res: 2.15446e-03, Loss_ic1: 3.67773e-03, Loss_ic2: 6.02654e-03, Loss_b1: 1.08619e-04, Loss_b2: 2.58477e-04, Loss_b3: 1.77802e-04, Loss_b4: 2.19366e-04\n",
      "Iter 1000, Loss: 9.99459e-03, Loss_res: 2.01143e-03, Loss_ic1: 2.97258e-03, Loss_ic2: 4.41884e-03, Loss_b1: 6.05920e-05, Loss_b2: 1.37803e-04, Loss_b3: 1.66794e-04, Loss_b4: 2.26545e-04\n",
      "Iter 1100, Loss: 7.98734e-03, Loss_res: 1.95129e-03, Loss_ic1: 2.36354e-03, Loss_ic2: 3.21776e-03, Loss_b1: 5.12207e-05, Loss_b2: 1.05971e-04, Loss_b3: 1.26128e-04, Loss_b4: 1.71430e-04\n",
      "Iter 1200, Loss: 7.22562e-03, Loss_res: 2.01037e-03, Loss_ic1: 1.91118e-03, Loss_ic2: 2.93736e-03, Loss_b1: 5.63795e-05, Loss_b2: 1.66290e-04, Loss_b3: 7.08816e-05, Loss_b4: 7.31578e-05\n",
      "Iter 1300, Loss: 5.21966e-03, Loss_res: 1.99932e-03, Loss_ic1: 1.37987e-03, Loss_ic2: 1.65750e-03, Loss_b1: 3.60813e-05, Loss_b2: 4.22993e-05, Loss_b3: 5.52799e-05, Loss_b4: 4.93063e-05\n",
      "Iter 1400, Loss: 4.14108e-03, Loss_res: 1.92977e-03, Loss_ic1: 1.01450e-03, Loss_ic2: 1.10123e-03, Loss_b1: 2.09673e-05, Loss_b2: 2.70377e-05, Loss_b3: 2.98604e-05, Loss_b4: 1.77092e-05\n",
      "Iter 1500, Loss: 3.52532e-03, Loss_res: 1.82088e-03, Loss_ic1: 7.71101e-04, Loss_ic2: 8.81315e-04, Loss_b1: 1.56221e-05, Loss_b2: 2.23636e-05, Loss_b3: 1.16030e-05, Loss_b4: 2.43052e-06\n",
      "Iter 1600, Loss: 2.89437e-03, Loss_res: 1.68983e-03, Loss_ic1: 5.64310e-04, Loss_ic2: 6.13774e-04, Loss_b1: 4.79009e-06, Loss_b2: 1.28684e-05, Loss_b3: 6.23090e-06, Loss_b4: 2.56150e-06\n",
      "Iter 1700, Loss: 2.60128e-03, Loss_res: 1.58313e-03, Loss_ic1: 4.64615e-04, Loss_ic2: 5.28353e-04, Loss_b1: 2.68126e-06, Loss_b2: 8.81681e-06, Loss_b3: 8.11515e-06, Loss_b4: 5.56340e-06\n",
      "Iter 1800, Loss: 8.61169e-03, Loss_res: 1.87285e-03, Loss_ic1: 1.82879e-03, Loss_ic2: 4.43052e-03, Loss_b1: 6.45744e-05, Loss_b2: 3.81681e-04, Loss_b3: 1.75148e-05, Loss_b4: 1.57551e-05\n",
      "Iter 1900, Loss: 2.15383e-03, Loss_res: 1.40342e-03, Loss_ic1: 3.20638e-04, Loss_ic2: 3.96975e-04, Loss_b1: 3.60057e-06, Loss_b2: 6.81514e-06, Loss_b3: 1.47707e-05, Loss_b4: 7.60811e-06\n",
      "Iter 2000, Loss: 2.01918e-03, Loss_res: 1.32795e-03, Loss_ic1: 2.86751e-04, Loss_ic2: 3.71398e-04, Loss_b1: 3.51167e-06, Loss_b2: 5.56446e-06, Loss_b3: 1.62609e-05, Loss_b4: 7.74563e-06\n",
      "Iter 2100, Loss: 1.95261e-03, Loss_res: 1.24944e-03, Loss_ic1: 2.76619e-04, Loss_ic2: 3.92679e-04, Loss_b1: 4.49987e-06, Loss_b2: 5.30385e-06, Loss_b3: 1.67696e-05, Loss_b4: 7.29663e-06\n",
      "Iter 2200, Loss: 2.08338e-03, Loss_res: 1.22264e-03, Loss_ic1: 3.47932e-04, Loss_ic2: 4.69885e-04, Loss_b1: 4.72407e-06, Loss_b2: 1.86464e-05, Loss_b3: 1.44759e-05, Loss_b4: 5.06965e-06\n",
      "Iter 2300, Loss: 2.32251e-03, Loss_res: 1.15167e-03, Loss_ic1: 3.70197e-04, Loss_ic2: 7.29604e-04, Loss_b1: 2.12939e-05, Loss_b2: 2.80774e-05, Loss_b3: 1.55605e-05, Loss_b4: 6.09775e-06\n",
      "Iter 2400, Loss: 2.40955e-03, Loss_res: 1.11644e-03, Loss_ic1: 4.10035e-04, Loss_ic2: 8.04515e-04, Loss_b1: 2.46947e-05, Loss_b2: 3.24371e-05, Loss_b3: 1.57633e-05, Loss_b4: 5.66280e-06\n",
      "Iter 2500, Loss: 1.46907e-03, Loss_res: 1.02825e-03, Loss_ic1: 1.86534e-04, Loss_ic2: 2.29877e-04, Loss_b1: 2.20286e-06, Loss_b2: 3.81594e-06, Loss_b3: 1.43031e-05, Loss_b4: 4.08684e-06\n",
      "Iter 2600, Loss: 1.56607e-03, Loss_res: 1.03043e-03, Loss_ic1: 2.14792e-04, Loss_ic2: 2.90826e-04, Loss_b1: 2.71536e-06, Loss_b2: 9.28059e-06, Loss_b3: 1.43779e-05, Loss_b4: 3.65249e-06\n",
      "Iter 2700, Loss: 1.40584e-03, Loss_res: 9.41055e-04, Loss_ic1: 1.66844e-04, Loss_ic2: 2.71969e-04, Loss_b1: 3.92162e-06, Loss_b2: 3.33299e-06, Loss_b3: 1.49281e-05, Loss_b4: 3.79015e-06\n",
      "Iter 2800, Loss: 1.40520e-03, Loss_res: 9.16766e-04, Loss_ic1: 1.99647e-04, Loss_ic2: 2.63016e-04, Loss_b1: 1.86755e-06, Loss_b2: 8.36469e-06, Loss_b3: 1.28529e-05, Loss_b4: 2.68755e-06\n",
      "Iter 2900, Loss: 1.26800e-03, Loss_res: 8.47239e-04, Loss_ic1: 1.45958e-04, Loss_ic2: 2.47041e-04, Loss_b1: 8.31722e-06, Loss_b2: 2.81128e-06, Loss_b3: 1.37035e-05, Loss_b4: 2.93151e-06\n",
      "Iter 3000, Loss: 2.29384e-03, Loss_res: 8.94986e-04, Loss_ic1: 4.37600e-04, Loss_ic2: 9.11879e-04, Loss_b1: 9.37766e-06, Loss_b2: 2.19142e-05, Loss_b3: 1.49095e-05, Loss_b4: 3.17167e-06\n",
      "Iter 3100, Loss: 1.07734e-03, Loss_res: 7.98698e-04, Loss_ic1: 1.13192e-04, Loss_ic2: 1.42673e-04, Loss_b1: 5.17399e-06, Loss_b2: 2.17456e-06, Loss_b3: 1.31884e-05, Loss_b4: 2.23634e-06\n",
      "Iter 3200, Loss: 1.11980e-03, Loss_res: 7.70031e-04, Loss_ic1: 1.28610e-04, Loss_ic2: 1.30601e-04, Loss_b1: 4.46936e-05, Loss_b2: 3.03121e-05, Loss_b3: 1.32024e-05, Loss_b4: 2.35031e-06\n",
      "Iter 3300, Loss: 1.01726e-03, Loss_res: 7.03894e-04, Loss_ic1: 1.04996e-04, Loss_ic2: 1.86405e-04, Loss_b1: 4.55045e-06, Loss_b2: 2.09208e-06, Loss_b3: 1.29835e-05, Loss_b4: 2.33679e-06\n",
      "Iter 3400, Loss: 9.34960e-04, Loss_res: 6.96250e-04, Loss_ic1: 9.58648e-05, Loss_ic2: 1.24408e-04, Loss_b1: 3.27428e-06, Loss_b2: 2.09968e-06, Loss_b3: 1.10724e-05, Loss_b4: 1.99051e-06\n",
      "Iter 3500, Loss: 2.23676e-03, Loss_res: 8.56658e-04, Loss_ic1: 4.41129e-04, Loss_ic2: 8.36931e-04, Loss_b1: 2.71375e-05, Loss_b2: 6.31200e-05, Loss_b3: 9.76293e-06, Loss_b4: 2.02039e-06\n",
      "Iter 3600, Loss: 1.33951e-03, Loss_res: 7.06329e-04, Loss_ic1: 2.18017e-04, Loss_ic2: 3.77318e-04, Loss_b1: 2.61249e-05, Loss_b2: 2.90229e-07, Loss_b3: 9.32849e-06, Loss_b4: 2.09973e-06\n",
      "Iter 3700, Loss: 8.46993e-04, Loss_res: 5.78139e-04, Loss_ic1: 8.84132e-05, Loss_ic2: 1.51593e-04, Loss_b1: 1.60717e-05, Loss_b2: 3.46669e-07, Loss_b3: 1.02837e-05, Loss_b4: 2.14577e-06\n",
      "Iter 3800, Loss: 8.51415e-04, Loss_res: 5.59292e-04, Loss_ic1: 9.23075e-05, Loss_ic2: 1.39132e-04, Loss_b1: 4.40213e-05, Loss_b2: 5.49572e-06, Loss_b3: 8.88698e-06, Loss_b4: 2.28016e-06\n",
      "Iter 3900, Loss: 9.67395e-04, Loss_res: 5.20335e-04, Loss_ic1: 1.35666e-04, Loss_ic2: 2.66396e-04, Loss_b1: 7.79261e-07, Loss_b2: 3.31940e-05, Loss_b3: 8.85923e-06, Loss_b4: 2.16586e-06\n",
      "Iter 4000, Loss: 1.18926e-03, Loss_res: 5.95321e-04, Loss_ic1: 2.21208e-04, Loss_ic2: 3.40880e-04, Loss_b1: 2.11082e-05, Loss_b2: 2.08773e-06, Loss_b3: 6.19087e-06, Loss_b4: 2.46864e-06\n",
      "Iter 4100, Loss: 7.56190e-04, Loss_res: 5.10436e-04, Loss_ic1: 9.01158e-05, Loss_ic2: 1.35979e-04, Loss_b1: 6.60393e-06, Loss_b2: 3.77478e-06, Loss_b3: 7.03099e-06, Loss_b4: 2.24967e-06\n",
      "Iter 4200, Loss: 6.86863e-04, Loss_res: 4.82349e-04, Loss_ic1: 7.52222e-05, Loss_ic2: 1.08563e-04, Loss_b1: 1.09023e-05, Loss_b2: 7.50174e-07, Loss_b3: 6.72438e-06, Loss_b4: 2.35182e-06\n",
      "Iter 4300, Loss: 5.63611e-04, Loss_res: 4.30686e-04, Loss_ic1: 5.79725e-05, Loss_ic2: 6.21165e-05, Loss_b1: 3.50466e-06, Loss_b2: 1.22645e-06, Loss_b3: 5.60081e-06, Loss_b4: 2.50353e-06\n",
      "Iter 4400, Loss: 9.02667e-04, Loss_res: 4.24030e-04, Loss_ic1: 1.48111e-04, Loss_ic2: 3.01520e-04, Loss_b1: 9.02516e-06, Loss_b2: 1.16490e-05, Loss_b3: 6.08955e-06, Loss_b4: 2.24321e-06\n",
      "Iter 4500, Loss: 6.31249e-04, Loss_res: 4.24881e-04, Loss_ic1: 6.18977e-05, Loss_ic2: 7.64076e-05, Loss_b1: 4.19048e-05, Loss_b2: 1.84742e-05, Loss_b3: 5.41454e-06, Loss_b4: 2.26984e-06\n",
      "Iter 4600, Loss: 5.31614e-04, Loss_res: 3.63728e-04, Loss_ic1: 5.35377e-05, Loss_ic2: 1.00295e-04, Loss_b1: 2.37193e-06, Loss_b2: 4.22571e-06, Loss_b3: 5.25648e-06, Loss_b4: 2.19946e-06\n",
      "Iter 4700, Loss: 5.49327e-04, Loss_res: 3.75831e-04, Loss_ic1: 6.68381e-05, Loss_ic2: 8.96993e-05, Loss_b1: 1.01807e-06, Loss_b2: 9.20267e-06, Loss_b3: 4.48035e-06, Loss_b4: 2.25833e-06\n",
      "Iter 4800, Loss: 4.71862e-04, Loss_res: 3.27059e-04, Loss_ic1: 4.79632e-05, Loss_ic2: 8.26805e-05, Loss_b1: 6.23205e-06, Loss_b2: 1.04244e-06, Loss_b3: 4.47934e-06, Loss_b4: 2.40512e-06\n",
      "Iter 4900, Loss: 1.31954e-03, Loss_res: 4.62015e-04, Loss_ic1: 2.36330e-04, Loss_ic2: 5.48423e-04, Loss_b1: 3.41632e-05, Loss_b2: 3.22189e-05, Loss_b3: 3.57950e-06, Loss_b4: 2.81166e-06\n",
      "Iter 5000, Loss: 4.68281e-04, Loss_res: 3.31555e-04, Loss_ic1: 5.20404e-05, Loss_ic2: 7.63591e-05, Loss_b1: 2.52244e-06, Loss_b2: 4.88744e-07, Loss_b3: 2.98619e-06, Loss_b4: 2.32911e-06\n",
      "Iter 5100, Loss: 1.10592e-03, Loss_res: 3.36722e-04, Loss_ic1: 2.34688e-04, Loss_ic2: 5.03343e-04, Loss_b1: 3.79922e-06, Loss_b2: 2.16705e-05, Loss_b3: 3.46021e-06, Loss_b4: 2.23710e-06\n",
      "Iter 5200, Loss: 6.29831e-04, Loss_res: 3.05366e-04, Loss_ic1: 9.94032e-05, Loss_ic2: 1.93103e-04, Loss_b1: 2.54429e-05, Loss_b2: 8.30392e-07, Loss_b3: 3.39278e-06, Loss_b4: 2.29249e-06\n",
      "Iter 5300, Loss: 1.19806e-03, Loss_res: 3.67342e-04, Loss_ic1: 2.38877e-04, Loss_ic2: 3.22010e-04, Loss_b1: 7.37886e-05, Loss_b2: 1.90644e-04, Loss_b3: 3.00127e-06, Loss_b4: 2.39786e-06\n",
      "Iter 5400, Loss: 6.92604e-04, Loss_res: 3.28621e-04, Loss_ic1: 1.21508e-04, Loss_ic2: 2.23602e-04, Loss_b1: 6.55102e-06, Loss_b2: 7.42854e-06, Loss_b3: 2.68377e-06, Loss_b4: 2.20969e-06\n",
      "Iter 5500, Loss: 4.88374e-04, Loss_res: 2.54849e-04, Loss_ic1: 7.01195e-05, Loss_ic2: 1.45778e-04, Loss_b1: 1.40810e-06, Loss_b2: 1.12818e-05, Loss_b3: 2.86626e-06, Loss_b4: 2.07112e-06\n",
      "Iter 5600, Loss: 9.09508e-04, Loss_res: 2.98114e-04, Loss_ic1: 1.93371e-04, Loss_ic2: 3.93732e-04, Loss_b1: 1.68657e-05, Loss_b2: 2.65849e-06, Loss_b3: 2.57413e-06, Loss_b4: 2.19221e-06\n",
      "Iter 5700, Loss: 2.95525e-04, Loss_res: 2.31199e-04, Loss_ic1: 2.64989e-05, Loss_ic2: 3.10749e-05, Loss_b1: 5.14312e-07, Loss_b2: 1.90896e-06, Loss_b3: 2.23830e-06, Loss_b4: 2.09147e-06\n",
      "Iter 5800, Loss: 2.85148e-04, Loss_res: 2.28229e-04, Loss_ic1: 2.38113e-05, Loss_ic2: 2.60213e-05, Loss_b1: 4.93943e-07, Loss_b2: 2.44316e-06, Loss_b3: 2.27223e-06, Loss_b4: 1.87657e-06\n",
      "Iter 5900, Loss: 3.65756e-04, Loss_res: 2.28977e-04, Loss_ic1: 4.34034e-05, Loss_ic2: 7.20786e-05, Loss_b1: 1.42817e-05, Loss_b2: 2.76057e-06, Loss_b3: 2.32547e-06, Loss_b4: 1.92940e-06\n",
      "Iter 6000, Loss: 2.75836e-04, Loss_res: 2.18819e-04, Loss_ic1: 2.22945e-05, Loss_ic2: 2.78117e-05, Loss_b1: 3.96613e-07, Loss_b2: 2.56069e-06, Loss_b3: 2.13049e-06, Loss_b4: 1.82255e-06\n",
      "Iter 6100, Loss: 9.10146e-04, Loss_res: 2.52522e-04, Loss_ic1: 1.70275e-04, Loss_ic2: 3.23662e-04, Loss_b1: 3.73581e-05, Loss_b2: 1.22204e-04, Loss_b3: 2.15083e-06, Loss_b4: 1.97468e-06\n",
      "Iter 6200, Loss: 9.89550e-04, Loss_res: 3.43888e-04, Loss_ic1: 2.05188e-04, Loss_ic2: 4.11916e-04, Loss_b1: 1.62579e-05, Loss_b2: 8.85101e-06, Loss_b3: 1.67226e-06, Loss_b4: 1.77800e-06\n",
      "Iter 6300, Loss: 4.52971e-04, Loss_res: 2.19469e-04, Loss_ic1: 7.48444e-05, Loss_ic2: 1.48294e-04, Loss_b1: 4.85334e-06, Loss_b2: 1.86010e-06, Loss_b3: 1.90104e-06, Loss_b4: 1.74978e-06\n",
      "Iter 6400, Loss: 3.96281e-04, Loss_res: 2.06381e-04, Loss_ic1: 5.91183e-05, Loss_ic2: 1.18867e-04, Loss_b1: 7.22448e-06, Loss_b2: 1.03995e-06, Loss_b3: 1.80883e-06, Loss_b4: 1.84134e-06\n",
      "Iter 6500, Loss: 6.18433e-04, Loss_res: 2.17646e-04, Loss_ic1: 1.22694e-04, Loss_ic2: 2.60687e-04, Loss_b1: 1.39176e-06, Loss_b2: 1.24545e-05, Loss_b3: 1.66451e-06, Loss_b4: 1.89493e-06\n",
      "Iter 6600, Loss: 2.65021e-04, Loss_res: 1.93022e-04, Loss_ic1: 2.32466e-05, Loss_ic2: 2.40215e-05, Loss_b1: 1.25115e-05, Loss_b2: 8.76583e-06, Loss_b3: 1.77982e-06, Loss_b4: 1.67392e-06\n",
      "Iter 6700, Loss: 4.17001e-04, Loss_res: 2.19073e-04, Loss_ic1: 6.73994e-05, Loss_ic2: 1.20168e-04, Loss_b1: 2.62257e-06, Loss_b2: 4.53004e-06, Loss_b3: 1.49423e-06, Loss_b4: 1.71469e-06\n",
      "Iter 6800, Loss: 2.39276e-04, Loss_res: 1.80956e-04, Loss_ic1: 2.18439e-05, Loss_ic2: 2.07481e-05, Loss_b1: 3.91313e-06, Loss_b2: 8.57526e-06, Loss_b3: 1.58365e-06, Loss_b4: 1.65575e-06\n",
      "Iter 6900, Loss: 4.77168e-04, Loss_res: 1.98565e-04, Loss_ic1: 8.68140e-05, Loss_ic2: 1.76792e-04, Loss_b1: 5.63184e-07, Loss_b2: 1.09757e-05, Loss_b3: 1.66729e-06, Loss_b4: 1.79011e-06\n",
      "Iter 7000, Loss: 4.79722e-04, Loss_res: 2.10666e-04, Loss_ic1: 9.41455e-05, Loss_ic2: 1.48295e-04, Loss_b1: 1.35064e-06, Loss_b2: 2.23795e-05, Loss_b3: 1.33353e-06, Loss_b4: 1.55117e-06\n",
      "Iter 7100, Loss: 4.05456e-04, Loss_res: 2.10680e-04, Loss_ic1: 6.25196e-05, Loss_ic2: 1.24068e-04, Loss_b1: 2.91793e-06, Loss_b2: 2.30515e-06, Loss_b3: 1.30387e-06, Loss_b4: 1.66113e-06\n",
      "Iter 7200, Loss: 3.34509e-04, Loss_res: 1.86300e-04, Loss_ic1: 5.17956e-05, Loss_ic2: 8.84976e-05, Loss_b1: 5.78725e-07, Loss_b2: 4.51108e-06, Loss_b3: 1.18407e-06, Loss_b4: 1.64193e-06\n",
      "Iter 7300, Loss: 3.29130e-04, Loss_res: 1.79118e-04, Loss_ic1: 5.03717e-05, Loss_ic2: 8.34866e-05, Loss_b1: 5.40884e-07, Loss_b2: 1.28895e-05, Loss_b3: 1.15755e-06, Loss_b4: 1.56523e-06\n",
      "Iter 7400, Loss: 1.53548e-03, Loss_res: 2.86038e-04, Loss_ic1: 3.10878e-04, Loss_ic2: 5.64023e-04, Loss_b1: 9.49454e-05, Loss_b2: 2.76286e-04, Loss_b3: 1.16972e-06, Loss_b4: 2.14154e-06\n",
      "Iter 7500, Loss: 3.40960e-04, Loss_res: 1.79864e-04, Loss_ic1: 5.31915e-05, Loss_ic2: 1.02757e-04, Loss_b1: 1.51891e-06, Loss_b2: 9.98710e-07, Loss_b3: 9.53136e-07, Loss_b4: 1.67641e-06\n",
      "Iter 7600, Loss: 5.67822e-04, Loss_res: 2.43289e-04, Loss_ic1: 1.00161e-04, Loss_ic2: 2.02904e-04, Loss_b1: 1.74948e-05, Loss_b2: 1.25497e-06, Loss_b3: 1.08324e-06, Loss_b4: 1.63480e-06\n",
      "Iter 7700, Loss: 1.68844e-04, Loss_res: 1.46218e-04, Loss_ic1: 7.18275e-06, Loss_ic2: 1.14075e-05, Loss_b1: 3.19963e-07, Loss_b2: 9.18282e-07, Loss_b3: 1.13410e-06, Loss_b4: 1.66349e-06\n",
      "Iter 7800, Loss: 2.35694e-04, Loss_res: 1.57230e-04, Loss_ic1: 2.89095e-05, Loss_ic2: 4.53692e-05, Loss_b1: 6.34428e-07, Loss_b2: 8.74979e-07, Loss_b3: 1.05684e-06, Loss_b4: 1.61931e-06\n",
      "Iter 7900, Loss: 2.73245e-04, Loss_res: 1.67098e-04, Loss_ic1: 3.34958e-05, Loss_ic2: 6.67406e-05, Loss_b1: 2.73070e-06, Loss_b2: 5.78628e-07, Loss_b3: 9.90927e-07, Loss_b4: 1.61016e-06\n",
      "Iter 8000, Loss: 6.48336e-04, Loss_res: 2.21950e-04, Loss_ic1: 1.36469e-04, Loss_ic2: 2.65634e-04, Loss_b1: 9.74797e-07, Loss_b2: 2.08864e-05, Loss_b3: 9.42027e-07, Loss_b4: 1.48010e-06\n",
      "Iter 8100, Loss: 3.76137e-04, Loss_res: 1.64547e-04, Loss_ic1: 6.30410e-05, Loss_ic2: 1.39135e-04, Loss_b1: 2.24635e-06, Loss_b2: 4.36812e-06, Loss_b3: 1.11639e-06, Loss_b4: 1.68307e-06\n",
      "Iter 8200, Loss: 8.36542e-04, Loss_res: 2.22952e-04, Loss_ic1: 1.91749e-04, Loss_ic2: 4.05305e-04, Loss_b1: 3.09539e-06, Loss_b2: 1.05679e-05, Loss_b3: 1.14794e-06, Loss_b4: 1.72426e-06\n",
      "Iter 8300, Loss: 4.93333e-04, Loss_res: 1.86831e-04, Loss_ic1: 9.06499e-05, Loss_ic2: 1.98981e-04, Loss_b1: 1.04668e-05, Loss_b2: 3.72963e-06, Loss_b3: 1.01714e-06, Loss_b4: 1.65700e-06\n",
      "Iter 8400, Loss: 1.96337e-04, Loss_res: 1.45849e-04, Loss_ic1: 1.31864e-05, Loss_ic2: 2.39293e-05, Loss_b1: 6.56657e-06, Loss_b2: 4.27534e-06, Loss_b3: 9.53570e-07, Loss_b4: 1.57708e-06\n",
      "Iter 8500, Loss: 7.78479e-04, Loss_res: 2.36219e-04, Loss_ic1: 1.77798e-04, Loss_ic2: 3.43240e-04, Loss_b1: 1.49389e-06, Loss_b2: 1.75427e-05, Loss_b3: 7.59673e-07, Loss_b4: 1.42527e-06\n",
      "Iter 8600, Loss: 2.73569e-04, Loss_res: 1.58413e-04, Loss_ic1: 4.90749e-05, Loss_ic2: 5.22717e-05, Loss_b1: 6.07932e-06, Loss_b2: 5.38144e-06, Loss_b3: 8.65414e-07, Loss_b4: 1.48372e-06\n",
      "Iter 8700, Loss: 4.94620e-04, Loss_res: 2.05928e-04, Loss_ic1: 8.60867e-05, Loss_ic2: 1.87550e-04, Loss_b1: 1.22220e-05, Loss_b2: 5.58771e-07, Loss_b3: 8.03094e-07, Loss_b4: 1.47158e-06\n",
      "Iter 8800, Loss: 1.77304e-04, Loss_res: 1.24205e-04, Loss_ic1: 1.74896e-05, Loss_ic2: 3.00963e-05, Loss_b1: 4.47890e-07, Loss_b2: 2.67861e-06, Loss_b3: 8.54964e-07, Loss_b4: 1.53196e-06\n",
      "Iter 8900, Loss: 1.76802e-03, Loss_res: 3.54670e-04, Loss_ic1: 4.35010e-04, Loss_ic2: 9.42569e-04, Loss_b1: 1.16185e-05, Loss_b2: 2.13895e-05, Loss_b3: 1.06275e-06, Loss_b4: 1.70480e-06\n",
      "Iter 9000, Loss: 1.31036e-04, Loss_res: 1.18191e-04, Loss_ic1: 4.85539e-06, Loss_ic2: 5.00158e-06, Loss_b1: 3.06749e-07, Loss_b2: 4.45441e-07, Loss_b3: 9.04908e-07, Loss_b4: 1.33112e-06\n",
      "Iter 9100, Loss: 3.80466e-04, Loss_res: 1.48758e-04, Loss_ic1: 7.11303e-05, Loss_ic2: 1.52898e-04, Loss_b1: 1.08928e-06, Loss_b2: 4.23795e-06, Loss_b3: 9.05756e-07, Loss_b4: 1.44628e-06\n",
      "Iter 9200, Loss: 1.88401e-04, Loss_res: 1.24583e-04, Loss_ic1: 2.11798e-05, Loss_ic2: 3.91425e-05, Loss_b1: 6.04995e-07, Loss_b2: 7.22426e-07, Loss_b3: 7.67491e-07, Loss_b4: 1.40076e-06\n",
      "Iter 9300, Loss: 5.47252e-04, Loss_res: 2.04395e-04, Loss_ic1: 9.79831e-05, Loss_ic2: 2.27230e-04, Loss_b1: 7.28502e-06, Loss_b2: 8.44342e-06, Loss_b3: 6.66380e-07, Loss_b4: 1.24971e-06\n",
      "Iter 9400, Loss: 3.42499e-04, Loss_res: 1.55783e-04, Loss_ic1: 5.86038e-05, Loss_ic2: 1.21393e-04, Loss_b1: 1.90641e-06, Loss_b2: 2.75971e-06, Loss_b3: 7.36050e-07, Loss_b4: 1.31709e-06\n",
      "Iter 9500, Loss: 1.99795e-04, Loss_res: 1.22517e-04, Loss_ic1: 2.77737e-05, Loss_ic2: 4.67625e-05, Loss_b1: 3.39979e-07, Loss_b2: 4.91242e-07, Loss_b3: 5.88546e-07, Loss_b4: 1.32213e-06\n",
      "Iter 9600, Loss: 3.33729e-04, Loss_res: 1.33149e-04, Loss_ic1: 6.06904e-05, Loss_ic2: 1.30666e-04, Loss_b1: 7.38640e-07, Loss_b2: 6.21116e-06, Loss_b3: 8.61053e-07, Loss_b4: 1.41232e-06\n",
      "Iter 9700, Loss: 1.75309e-04, Loss_res: 1.13347e-04, Loss_ic1: 1.78660e-05, Loss_ic2: 3.73569e-05, Loss_b1: 4.02003e-06, Loss_b2: 6.66653e-07, Loss_b3: 7.04940e-07, Loss_b4: 1.34816e-06\n",
      "Iter 9800, Loss: 1.42845e-04, Loss_res: 1.12311e-04, Loss_ic1: 8.61433e-06, Loss_ic2: 1.70092e-05, Loss_b1: 1.54205e-06, Loss_b2: 1.35399e-06, Loss_b3: 7.36501e-07, Loss_b4: 1.27773e-06\n",
      "Iter 9900, Loss: 3.15301e-04, Loss_res: 1.38560e-04, Loss_ic1: 6.81456e-05, Loss_ic2: 1.02894e-04, Loss_b1: 5.44463e-07, Loss_b2: 3.19849e-06, Loss_b3: 7.02262e-07, Loss_b4: 1.25517e-06\n",
      "Iter 10000, Loss: 3.16103e-04, Loss_res: 1.25215e-04, Loss_ic1: 5.82524e-05, Loss_ic2: 1.24188e-04, Loss_b1: 8.11330e-07, Loss_b2: 5.56481e-06, Loss_b3: 7.64515e-07, Loss_b4: 1.30755e-06\n",
      "Iter 10100, Loss: 1.30408e-04, Loss_res: 1.01101e-04, Loss_ic1: 1.15016e-05, Loss_ic2: 1.49396e-05, Loss_b1: 3.00515e-07, Loss_b2: 6.43554e-07, Loss_b3: 6.76868e-07, Loss_b4: 1.24473e-06\n",
      "Iter 10200, Loss: 3.71097e-04, Loss_res: 1.50134e-04, Loss_ic1: 6.48560e-05, Loss_ic2: 1.42897e-04, Loss_b1: 1.58281e-06, Loss_b2: 9.88389e-06, Loss_b3: 6.24463e-07, Loss_b4: 1.11924e-06\n",
      "Iter 10300, Loss: 1.24823e-04, Loss_res: 9.74491e-05, Loss_ic1: 8.52394e-06, Loss_ic2: 1.59343e-05, Loss_b1: 4.27679e-07, Loss_b2: 4.95932e-07, Loss_b3: 7.75165e-07, Loss_b4: 1.21710e-06\n",
      "Iter 10400, Loss: 1.44414e-04, Loss_res: 1.00977e-04, Loss_ic1: 1.68283e-05, Loss_ic2: 2.38715e-05, Loss_b1: 3.51863e-07, Loss_b2: 5.57365e-07, Loss_b3: 6.40910e-07, Loss_b4: 1.18716e-06\n",
      "Iter 10500, Loss: 1.19640e-04, Loss_res: 9.56230e-05, Loss_ic1: 8.57616e-06, Loss_ic2: 1.02618e-05, Loss_b1: 2.22383e-06, Loss_b2: 1.08430e-06, Loss_b3: 7.19702e-07, Loss_b4: 1.15134e-06\n",
      "Iter 10600, Loss: 4.37512e-04, Loss_res: 1.49914e-04, Loss_ic1: 8.63311e-05, Loss_ic2: 1.89245e-04, Loss_b1: 9.80305e-06, Loss_b2: 3.99908e-07, Loss_b3: 6.86931e-07, Loss_b4: 1.13088e-06\n",
      "Iter 10700, Loss: 1.22177e-04, Loss_res: 9.24907e-05, Loss_ic1: 8.17774e-06, Loss_ic2: 1.40512e-05, Loss_b1: 2.13615e-06, Loss_b2: 3.56361e-06, Loss_b3: 6.83502e-07, Loss_b4: 1.07451e-06\n",
      "Iter 10800, Loss: 2.81828e-04, Loss_res: 1.18060e-04, Loss_ic1: 4.94377e-05, Loss_ic2: 1.07780e-04, Loss_b1: 4.40254e-06, Loss_b2: 4.03086e-07, Loss_b3: 6.53450e-07, Loss_b4: 1.08999e-06\n",
      "Iter 10900, Loss: 1.13213e-04, Loss_res: 8.70161e-05, Loss_ic1: 5.27992e-06, Loss_ic2: 1.23332e-05, Loss_b1: 7.42920e-07, Loss_b2: 6.10584e-06, Loss_b3: 6.74832e-07, Loss_b4: 1.05995e-06\n",
      "Iter 11000, Loss: 1.25371e-04, Loss_res: 9.27715e-05, Loss_ic1: 9.82841e-06, Loss_ic2: 1.97099e-05, Loss_b1: 9.07476e-07, Loss_b2: 4.36521e-07, Loss_b3: 6.57799e-07, Loss_b4: 1.05959e-06\n",
      "Iter 11100, Loss: 3.40265e-04, Loss_res: 1.41300e-04, Loss_ic1: 5.65151e-05, Loss_ic2: 1.31519e-04, Loss_b1: 2.19671e-06, Loss_b2: 7.21088e-06, Loss_b3: 5.37093e-07, Loss_b4: 9.86819e-07\n",
      "Iter 11200, Loss: 3.08286e-04, Loss_res: 1.28236e-04, Loss_ic1: 5.41805e-05, Loss_ic2: 1.15638e-04, Loss_b1: 8.20574e-06, Loss_b2: 3.52204e-07, Loss_b3: 6.65191e-07, Loss_b4: 1.00811e-06\n",
      "Iter 11300, Loss: 1.12844e-04, Loss_res: 8.36760e-05, Loss_ic1: 9.60225e-06, Loss_ic2: 1.72098e-05, Loss_b1: 3.50918e-07, Loss_b2: 3.16247e-07, Loss_b3: 7.10716e-07, Loss_b4: 9.78343e-07\n",
      "Iter 11400, Loss: 2.22007e-04, Loss_res: 1.15103e-04, Loss_ic1: 3.08073e-05, Loss_ic2: 7.05568e-05, Loss_b1: 3.32870e-06, Loss_b2: 6.43660e-07, Loss_b3: 6.05817e-07, Loss_b4: 9.61129e-07\n",
      "Iter 11500, Loss: 3.99064e-04, Loss_res: 1.21413e-04, Loss_ic1: 8.77544e-05, Loss_ic2: 1.79648e-04, Loss_b1: 9.50750e-07, Loss_b2: 7.71035e-06, Loss_b3: 5.38099e-07, Loss_b4: 1.04926e-06\n",
      "Iter 11600, Loss: 8.61664e-05, Loss_res: 7.66793e-05, Loss_ic1: 3.42043e-06, Loss_ic2: 3.94815e-06, Loss_b1: 1.72911e-07, Loss_b2: 4.00234e-07, Loss_b3: 6.01026e-07, Loss_b4: 9.44330e-07\n",
      "Iter 11700, Loss: 1.73089e-04, Loss_res: 8.89303e-05, Loss_ic1: 3.19123e-05, Loss_ic2: 4.30067e-05, Loss_b1: 1.37408e-06, Loss_b2: 6.31136e-06, Loss_b3: 6.44872e-07, Loss_b4: 9.08958e-07\n",
      "Iter 11800, Loss: 3.41105e-04, Loss_res: 1.31397e-04, Loss_ic1: 6.34635e-05, Loss_ic2: 1.40146e-04, Loss_b1: 3.80011e-06, Loss_b2: 8.00761e-07, Loss_b3: 4.99910e-07, Loss_b4: 9.98123e-07\n",
      "Iter 11900, Loss: 1.39060e-04, Loss_res: 7.86924e-05, Loss_ic1: 1.70245e-05, Loss_ic2: 2.82385e-05, Loss_b1: 1.65446e-06, Loss_b2: 1.20293e-05, Loss_b3: 6.20284e-07, Loss_b4: 8.00965e-07\n",
      "Iter 12000, Loss: 3.18971e-04, Loss_res: 1.11517e-04, Loss_ic1: 6.38968e-05, Loss_ic2: 1.38404e-04, Loss_b1: 2.48477e-06, Loss_b2: 1.10420e-06, Loss_b3: 6.50028e-07, Loss_b4: 9.13721e-07\n",
      "Iter 12100, Loss: 1.08887e-04, Loss_res: 7.77651e-05, Loss_ic1: 1.08114e-05, Loss_ic2: 1.53042e-05, Loss_b1: 2.72030e-06, Loss_b2: 8.47327e-07, Loss_b3: 5.79754e-07, Loss_b4: 8.58517e-07\n",
      "Iter 12200, Loss: 8.39249e-05, Loss_res: 7.03644e-05, Loss_ic1: 5.23220e-06, Loss_ic2: 5.36001e-06, Loss_b1: 9.50429e-07, Loss_b2: 6.57167e-07, Loss_b3: 4.97800e-07, Loss_b4: 8.62948e-07\n",
      "Iter 12300, Loss: 3.52572e-04, Loss_res: 1.06662e-04, Loss_ic1: 9.20160e-05, Loss_ic2: 1.14113e-04, Loss_b1: 8.90457e-06, Loss_b2: 2.94488e-05, Loss_b3: 5.88283e-07, Loss_b4: 8.39632e-07\n",
      "Iter 12400, Loss: 9.66891e-05, Loss_res: 7.02525e-05, Loss_ic1: 5.63861e-06, Loss_ic2: 1.48311e-05, Loss_b1: 5.20966e-07, Loss_b2: 4.07650e-06, Loss_b3: 5.05062e-07, Loss_b4: 8.64376e-07\n",
      "Iter 12500, Loss: 8.12500e-05, Loss_res: 6.81197e-05, Loss_ic1: 2.29396e-06, Loss_ic2: 7.50710e-06, Loss_b1: 2.04208e-07, Loss_b2: 1.90075e-06, Loss_b3: 5.17658e-07, Loss_b4: 7.06638e-07\n",
      "Iter 12600, Loss: 1.26128e-04, Loss_res: 7.37793e-05, Loss_ic1: 1.75714e-05, Loss_ic2: 3.15997e-05, Loss_b1: 1.83446e-07, Loss_b2: 1.65091e-06, Loss_b3: 5.37277e-07, Loss_b4: 8.05636e-07\n",
      "Iter 12700, Loss: 3.08231e-04, Loss_res: 1.06069e-04, Loss_ic1: 6.19876e-05, Loss_ic2: 1.33319e-04, Loss_b1: 4.28994e-07, Loss_b2: 5.13165e-06, Loss_b3: 4.25907e-07, Loss_b4: 8.69583e-07\n",
      "Iter 12800, Loss: 3.94827e-04, Loss_res: 1.76131e-04, Loss_ic1: 1.01897e-04, Loss_ic2: 4.96218e-05, Loss_b1: 4.24051e-05, Loss_b2: 2.34786e-05, Loss_b3: 5.86650e-07, Loss_b4: 7.07024e-07\n",
      "Iter 12900, Loss: 1.65156e-04, Loss_res: 7.43185e-05, Loss_ic1: 2.09741e-05, Loss_ic2: 6.27681e-05, Loss_b1: 9.00697e-07, Loss_b2: 4.89980e-06, Loss_b3: 3.76020e-07, Loss_b4: 9.18343e-07\n",
      "Iter 13000, Loss: 7.02081e-05, Loss_res: 6.01439e-05, Loss_ic1: 3.44046e-06, Loss_ic2: 4.89494e-06, Loss_b1: 2.44111e-07, Loss_b2: 2.95205e-07, Loss_b3: 4.44608e-07, Loss_b4: 7.44912e-07\n",
      "Iter 13100, Loss: 2.70629e-04, Loss_res: 1.00148e-04, Loss_ic1: 5.66494e-05, Loss_ic2: 1.11641e-04, Loss_b1: 4.05809e-07, Loss_b2: 5.58854e-07, Loss_b3: 4.89122e-07, Loss_b4: 7.36714e-07\n",
      "Iter 13200, Loss: 5.30770e-04, Loss_res: 1.85318e-04, Loss_ic1: 9.52474e-05, Loss_ic2: 2.30717e-04, Loss_b1: 1.44272e-05, Loss_b2: 3.91779e-06, Loss_b3: 3.46336e-07, Loss_b4: 7.95705e-07\n",
      "Iter 13300, Loss: 2.50722e-04, Loss_res: 8.30023e-05, Loss_ic1: 5.56794e-05, Loss_ic2: 1.07514e-04, Loss_b1: 1.31979e-07, Loss_b2: 3.31677e-06, Loss_b3: 4.46877e-07, Loss_b4: 6.31136e-07\n",
      "Iter 13400, Loss: 9.78706e-05, Loss_res: 6.01779e-05, Loss_ic1: 1.06353e-05, Loss_ic2: 2.15763e-05, Loss_b1: 4.68031e-07, Loss_b2: 3.83855e-06, Loss_b3: 4.57171e-07, Loss_b4: 7.17301e-07\n",
      "Iter 13500, Loss: 1.93583e-04, Loss_res: 8.69616e-05, Loss_ic1: 3.16919e-05, Loss_ic2: 7.21851e-05, Loss_b1: 1.23115e-06, Loss_b2: 4.28483e-07, Loss_b3: 4.49057e-07, Loss_b4: 6.35504e-07\n",
      "Iter 13600, Loss: 1.67813e-04, Loss_res: 7.23599e-05, Loss_ic1: 3.07189e-05, Loss_ic2: 6.23362e-05, Loss_b1: 7.10407e-07, Loss_b2: 6.09953e-07, Loss_b3: 4.20125e-07, Loss_b4: 6.57725e-07\n",
      "Iter 13700, Loss: 3.39998e-04, Loss_res: 1.20322e-04, Loss_ic1: 1.05056e-04, Loss_ic2: 9.60842e-05, Loss_b1: 1.05753e-05, Loss_b2: 6.94772e-06, Loss_b3: 3.79132e-07, Loss_b4: 6.33958e-07\n",
      "Iter 13800, Loss: 1.11915e-04, Loss_res: 6.14725e-05, Loss_ic1: 1.63051e-05, Loss_ic2: 3.23586e-05, Loss_b1: 3.41332e-07, Loss_b2: 3.71825e-07, Loss_b3: 4.94297e-07, Loss_b4: 5.71493e-07\n",
      "Iter 13900, Loss: 3.70119e-04, Loss_res: 9.41186e-05, Loss_ic1: 8.62719e-05, Loss_ic2: 1.81239e-04, Loss_b1: 1.77615e-07, Loss_b2: 7.33819e-06, Loss_b3: 4.16365e-07, Loss_b4: 5.56772e-07\n",
      "Iter 14000, Loss: 7.71639e-05, Loss_res: 5.75046e-05, Loss_ic1: 9.80581e-06, Loss_ic2: 5.82156e-06, Loss_b1: 1.93668e-06, Loss_b2: 1.03860e-06, Loss_b3: 4.57878e-07, Loss_b4: 5.98702e-07\n",
      "Iter 14100, Loss: 1.82902e-04, Loss_res: 7.62690e-05, Loss_ic1: 3.26938e-05, Loss_ic2: 6.97230e-05, Loss_b1: 2.91280e-06, Loss_b2: 2.97420e-07, Loss_b3: 4.44823e-07, Loss_b4: 5.61010e-07\n",
      "Iter 14200, Loss: 8.70241e-05, Loss_res: 5.83652e-05, Loss_ic1: 7.76725e-06, Loss_ic2: 1.84770e-05, Loss_b1: 7.23061e-07, Loss_b2: 6.96246e-07, Loss_b3: 4.42585e-07, Loss_b4: 5.52757e-07\n",
      "Iter 14300, Loss: 4.24933e-04, Loss_res: 1.14736e-04, Loss_ic1: 1.03919e-04, Loss_ic2: 1.99035e-04, Loss_b1: 2.05226e-07, Loss_b2: 6.11686e-06, Loss_b3: 2.92142e-07, Loss_b4: 6.28876e-07\n",
      "Iter 14400, Loss: 1.96843e-04, Loss_res: 7.22797e-05, Loss_ic1: 4.05018e-05, Loss_ic2: 8.21952e-05, Loss_b1: 2.98969e-07, Loss_b2: 5.83920e-07, Loss_b3: 4.71545e-07, Loss_b4: 5.12302e-07\n",
      "Iter 14500, Loss: 3.78649e-04, Loss_res: 1.08353e-04, Loss_ic1: 8.28272e-05, Loss_ic2: 1.82743e-04, Loss_b1: 3.61124e-06, Loss_b2: 2.07217e-07, Loss_b3: 4.10533e-07, Loss_b4: 4.96759e-07\n",
      "Iter 14600, Loss: 1.77936e-04, Loss_res: 7.34257e-05, Loss_ic1: 2.40589e-05, Loss_ic2: 6.20821e-05, Loss_b1: 3.64152e-06, Loss_b2: 1.38578e-05, Loss_b3: 2.85017e-07, Loss_b4: 5.85452e-07\n",
      "Iter 14700, Loss: 4.17932e-04, Loss_res: 1.79101e-04, Loss_ic1: 1.22214e-04, Loss_ic2: 7.89712e-05, Loss_b1: 2.55402e-05, Loss_b2: 1.12242e-05, Loss_b3: 4.03225e-07, Loss_b4: 4.77981e-07\n",
      "Iter 14800, Loss: 4.69633e-04, Loss_res: 1.23547e-04, Loss_ic1: 1.06693e-04, Loss_ic2: 2.34823e-04, Loss_b1: 3.29050e-06, Loss_b2: 4.03712e-07, Loss_b3: 4.16651e-07, Loss_b4: 4.58674e-07\n",
      "Iter 14900, Loss: 2.37868e-04, Loss_res: 8.18811e-05, Loss_ic1: 4.56768e-05, Loss_ic2: 1.03154e-04, Loss_b1: 4.83699e-06, Loss_b2: 1.49540e-06, Loss_b3: 3.33310e-07, Loss_b4: 4.89761e-07\n",
      "Iter 15000, Loss: 1.05179e-04, Loss_res: 6.96667e-05, Loss_ic1: 1.90535e-05, Loss_ic2: 6.56429e-06, Loss_b1: 6.94388e-06, Loss_b2: 2.10801e-06, Loss_b3: 4.02534e-07, Loss_b4: 4.39754e-07\n",
      "Iter 15100, Loss: 1.14910e-04, Loss_res: 6.24097e-05, Loss_ic1: 1.96446e-05, Loss_ic2: 1.94310e-05, Loss_b1: 5.58234e-06, Loss_b2: 7.01988e-06, Loss_b3: 3.45676e-07, Loss_b4: 4.76898e-07\n",
      "Iter 15200, Loss: 1.48716e-04, Loss_res: 6.43701e-05, Loss_ic1: 2.56379e-05, Loss_ic2: 5.61057e-05, Loss_b1: 1.28737e-06, Loss_b2: 4.78802e-07, Loss_b3: 4.08434e-07, Loss_b4: 4.27532e-07\n",
      "Iter 15300, Loss: 2.63821e-04, Loss_res: 7.22012e-05, Loss_ic1: 6.25663e-05, Loss_ic2: 1.21476e-04, Loss_b1: 5.97967e-07, Loss_b2: 6.20242e-06, Loss_b3: 3.34110e-07, Loss_b4: 4.42979e-07\n",
      "Iter 15400, Loss: 1.11716e-04, Loss_res: 7.22277e-05, Loss_ic1: 1.48574e-05, Loss_ic2: 1.52957e-05, Loss_b1: 6.05393e-06, Loss_b2: 2.51972e-06, Loss_b3: 3.31914e-07, Loss_b4: 4.29617e-07\n",
      "Iter 15500, Loss: 2.60479e-04, Loss_res: 7.05393e-05, Loss_ic1: 5.91712e-05, Loss_ic2: 1.21698e-04, Loss_b1: 4.78695e-07, Loss_b2: 7.85435e-06, Loss_b3: 3.49075e-07, Loss_b4: 3.88581e-07\n",
      "Iter 15600, Loss: 3.17902e-04, Loss_res: 8.72334e-05, Loss_ic1: 8.22773e-05, Loss_ic2: 1.46262e-04, Loss_b1: 3.22273e-07, Loss_b2: 1.06621e-06, Loss_b3: 3.51470e-07, Loss_b4: 3.89683e-07\n",
      "Iter 15700, Loss: 1.55998e-04, Loss_res: 5.67090e-05, Loss_ic1: 3.09388e-05, Loss_ic2: 6.46990e-05, Loss_b1: 9.44981e-08, Loss_b2: 2.81429e-06, Loss_b3: 3.54145e-07, Loss_b4: 3.88079e-07\n",
      "Iter 15800, Loss: 1.63803e-04, Loss_res: 6.93343e-05, Loss_ic1: 2.83578e-05, Loss_ic2: 5.65274e-05, Loss_b1: 5.33386e-06, Loss_b2: 3.55431e-06, Loss_b3: 3.32871e-07, Loss_b4: 3.62936e-07\n",
      "Iter 15900, Loss: 3.26700e-04, Loss_res: 9.08109e-05, Loss_ic1: 9.04511e-05, Loss_ic2: 1.40026e-04, Loss_b1: 2.18274e-06, Loss_b2: 2.52765e-06, Loss_b3: 3.30640e-07, Loss_b4: 3.71396e-07\n",
      "Iter 16000, Loss: 2.17476e-04, Loss_res: 7.42738e-05, Loss_ic1: 4.32694e-05, Loss_ic2: 9.51745e-05, Loss_b1: 1.88779e-06, Loss_b2: 2.17638e-06, Loss_b3: 3.49941e-07, Loss_b4: 3.44245e-07\n",
      "Iter 16100, Loss: 6.72997e-05, Loss_res: 4.19595e-05, Loss_ic1: 7.95110e-06, Loss_ic2: 1.41647e-05, Loss_b1: 5.12247e-07, Loss_b2: 2.04484e-06, Loss_b3: 3.22776e-07, Loss_b4: 3.44611e-07\n",
      "Iter 16200, Loss: 1.19261e-04, Loss_res: 5.42700e-05, Loss_ic1: 2.00162e-05, Loss_ic2: 4.29692e-05, Loss_b1: 1.77201e-07, Loss_b2: 1.14220e-06, Loss_b3: 2.99564e-07, Loss_b4: 3.86405e-07\n",
      "Iter 16300, Loss: 9.18560e-05, Loss_res: 4.74716e-05, Loss_ic1: 1.32621e-05, Loss_ic2: 2.79380e-05, Loss_b1: 1.58447e-07, Loss_b2: 2.39761e-06, Loss_b3: 2.85339e-07, Loss_b4: 3.42893e-07\n",
      "Iter 16400, Loss: 7.45323e-05, Loss_res: 4.54465e-05, Loss_ic1: 9.01236e-06, Loss_ic2: 1.90638e-05, Loss_b1: 1.39177e-07, Loss_b2: 2.22975e-07, Loss_b3: 3.02505e-07, Loss_b4: 3.44906e-07\n",
      "Iter 16500, Loss: 7.93182e-05, Loss_res: 4.95553e-05, Loss_ic1: 8.50360e-06, Loss_ic2: 1.86745e-05, Loss_b1: 1.02015e-06, Loss_b2: 9.56932e-07, Loss_b3: 1.96625e-07, Loss_b4: 4.11191e-07\n",
      "Iter 16600, Loss: 4.78247e-05, Loss_res: 3.88170e-05, Loss_ic1: 2.46851e-06, Loss_ic2: 4.49575e-06, Loss_b1: 1.65903e-07, Loss_b2: 1.26053e-06, Loss_b3: 3.07558e-07, Loss_b4: 3.09504e-07\n",
      "Iter 16700, Loss: 1.04430e-04, Loss_res: 4.62734e-05, Loss_ic1: 1.89070e-05, Loss_ic2: 3.75172e-05, Loss_b1: 8.72639e-08, Loss_b2: 1.04022e-06, Loss_b3: 2.91160e-07, Loss_b4: 3.13751e-07\n",
      "Iter 16800, Loss: 1.73085e-04, Loss_res: 7.32867e-05, Loss_ic1: 3.20641e-05, Loss_ic2: 5.76392e-05, Loss_b1: 6.33293e-06, Loss_b2: 3.17204e-06, Loss_b3: 2.73294e-07, Loss_b4: 3.16363e-07\n",
      "Iter 16900, Loss: 1.42263e-04, Loss_res: 5.88969e-05, Loss_ic1: 2.37303e-05, Loss_ic2: 3.80696e-05, Loss_b1: 7.57879e-06, Loss_b2: 1.34170e-05, Loss_b3: 2.55200e-07, Loss_b4: 3.14939e-07\n",
      "Iter 17000, Loss: 8.94879e-05, Loss_res: 4.71736e-05, Loss_ic1: 1.69639e-05, Loss_ic2: 2.41401e-05, Loss_b1: 5.01531e-07, Loss_b2: 1.49256e-07, Loss_b3: 2.80130e-07, Loss_b4: 2.79297e-07\n",
      "Iter 17100, Loss: 1.24948e-04, Loss_res: 5.58897e-05, Loss_ic1: 2.08775e-05, Loss_ic2: 4.51240e-05, Loss_b1: 2.34432e-06, Loss_b2: 1.68064e-07, Loss_b3: 2.52264e-07, Loss_b4: 2.92612e-07\n",
      "Iter 17200, Loss: 1.71478e-04, Loss_res: 7.48024e-05, Loss_ic1: 2.49940e-05, Loss_ic2: 6.29592e-05, Loss_b1: 5.03181e-06, Loss_b2: 3.17932e-06, Loss_b3: 2.29657e-07, Loss_b4: 2.81641e-07\n",
      "Iter 17300, Loss: 1.12807e-04, Loss_res: 4.75723e-05, Loss_ic1: 2.13563e-05, Loss_ic2: 4.27464e-05, Loss_b1: 9.76251e-08, Loss_b2: 4.74162e-07, Loss_b3: 2.89079e-07, Loss_b4: 2.70759e-07\n",
      "Iter 17400, Loss: 9.17810e-05, Loss_res: 4.85191e-05, Loss_ic1: 1.25114e-05, Loss_ic2: 2.95921e-05, Loss_b1: 3.39765e-07, Loss_b2: 3.12797e-07, Loss_b3: 2.29135e-07, Loss_b4: 2.76657e-07\n",
      "Iter 17500, Loss: 1.22665e-04, Loss_res: 5.42454e-05, Loss_ic1: 1.95570e-05, Loss_ic2: 4.73808e-05, Loss_b1: 4.63046e-07, Loss_b2: 4.96739e-07, Loss_b3: 2.37508e-07, Loss_b4: 2.84082e-07\n",
      "Iter 17600, Loss: 1.56418e-04, Loss_res: 5.65698e-05, Loss_ic1: 3.63468e-05, Loss_ic2: 6.23681e-05, Loss_b1: 3.76782e-07, Loss_b2: 2.77411e-07, Loss_b3: 2.24820e-07, Loss_b4: 2.54049e-07\n",
      "Iter 17700, Loss: 9.17480e-05, Loss_res: 4.67764e-05, Loss_ic1: 1.23214e-05, Loss_ic2: 3.11273e-05, Loss_b1: 4.82480e-07, Loss_b2: 5.58844e-07, Loss_b3: 2.09412e-07, Loss_b4: 2.72092e-07\n",
      "Iter 17800, Loss: 1.61433e-04, Loss_res: 6.42775e-05, Loss_ic1: 2.87864e-05, Loss_ic2: 6.49482e-05, Loss_b1: 2.65938e-06, Loss_b2: 2.64538e-07, Loss_b3: 2.57746e-07, Loss_b4: 2.39182e-07\n",
      "Iter 17900, Loss: 1.19069e-04, Loss_res: 4.84561e-05, Loss_ic1: 2.29806e-05, Loss_ic2: 4.68235e-05, Loss_b1: 1.67393e-07, Loss_b2: 1.53549e-07, Loss_b3: 2.56489e-07, Loss_b4: 2.31783e-07\n",
      "Iter 18000, Loss: 3.82850e-05, Loss_res: 3.36519e-05, Loss_ic1: 1.16164e-06, Loss_ic2: 2.30022e-06, Loss_b1: 1.89767e-07, Loss_b2: 5.26641e-07, Loss_b3: 2.12293e-07, Loss_b4: 2.42535e-07\n",
      "Iter 18100, Loss: 3.32641e-04, Loss_res: 7.84193e-05, Loss_ic1: 8.26505e-05, Loss_ic2: 1.67506e-04, Loss_b1: 1.22281e-07, Loss_b2: 3.50161e-06, Loss_b3: 1.96684e-07, Loss_b4: 2.44419e-07\n",
      "Iter 18200, Loss: 1.06300e-04, Loss_res: 4.57704e-05, Loss_ic1: 1.84825e-05, Loss_ic2: 4.10182e-05, Loss_b1: 3.04588e-07, Loss_b2: 2.75143e-07, Loss_b3: 2.26155e-07, Loss_b4: 2.22806e-07\n",
      "Iter 18300, Loss: 2.20009e-04, Loss_res: 6.29779e-05, Loss_ic1: 4.95172e-05, Loss_ic2: 1.05604e-04, Loss_b1: 1.00002e-07, Loss_b2: 1.37760e-06, Loss_b3: 2.17009e-07, Loss_b4: 2.14912e-07\n",
      "Iter 18400, Loss: 4.41591e-05, Loss_res: 3.27355e-05, Loss_ic1: 2.52016e-06, Loss_ic2: 6.30008e-06, Loss_b1: 1.95660e-07, Loss_b2: 1.98283e-06, Loss_b3: 1.90811e-07, Loss_b4: 2.34079e-07\n",
      "Iter 18500, Loss: 1.04497e-04, Loss_res: 4.75206e-05, Loss_ic1: 1.62289e-05, Loss_ic2: 3.96248e-05, Loss_b1: 2.75602e-07, Loss_b2: 4.29643e-07, Loss_b3: 1.79952e-07, Loss_b4: 2.37355e-07\n",
      "Iter 18600, Loss: 6.69351e-05, Loss_res: 3.54277e-05, Loss_ic1: 1.00921e-05, Loss_ic2: 1.66902e-05, Loss_b1: 1.20083e-06, Loss_b2: 3.12329e-06, Loss_b3: 1.98519e-07, Loss_b4: 2.02426e-07\n",
      "Iter 18700, Loss: 3.95847e-04, Loss_res: 1.08007e-04, Loss_ic1: 8.28193e-05, Loss_ic2: 2.00740e-04, Loss_b1: 8.00236e-07, Loss_b2: 3.08808e-06, Loss_b3: 1.40967e-07, Loss_b4: 2.52783e-07\n",
      "Iter 18800, Loss: 7.29125e-05, Loss_res: 4.74009e-05, Loss_ic1: 7.88646e-06, Loss_ic2: 1.43464e-05, Loss_b1: 4.08754e-07, Loss_b2: 2.46719e-06, Loss_b3: 1.96828e-07, Loss_b4: 2.05993e-07\n",
      "Iter 18900, Loss: 8.10314e-05, Loss_res: 3.94481e-05, Loss_ic1: 1.29848e-05, Loss_ic2: 2.73544e-05, Loss_b1: 1.02666e-07, Loss_b2: 7.49229e-07, Loss_b3: 1.73261e-07, Loss_b4: 2.18908e-07\n",
      "Iter 19000, Loss: 5.64589e-05, Loss_res: 3.46048e-05, Loss_ic1: 8.22002e-06, Loss_ic2: 1.02146e-05, Loss_b1: 1.09716e-06, Loss_b2: 1.95899e-06, Loss_b3: 1.64917e-07, Loss_b4: 1.98394e-07\n",
      "Iter 19100, Loss: 5.28320e-05, Loss_res: 3.87508e-05, Loss_ic1: 7.05832e-06, Loss_ic2: 3.75430e-06, Loss_b1: 1.97712e-06, Loss_b2: 9.26023e-07, Loss_b3: 1.86525e-07, Loss_b4: 1.78893e-07\n",
      "Iter 19200, Loss: 8.61208e-05, Loss_res: 5.07440e-05, Loss_ic1: 9.91867e-06, Loss_ic2: 2.20440e-05, Loss_b1: 2.61801e-06, Loss_b2: 4.17249e-07, Loss_b3: 1.74813e-07, Loss_b4: 2.04056e-07\n",
      "Iter 19300, Loss: 1.10073e-04, Loss_res: 6.50655e-05, Loss_ic1: 2.02837e-05, Loss_ic2: 1.53121e-05, Loss_b1: 7.39320e-06, Loss_b2: 1.63211e-06, Loss_b3: 1.96970e-07, Loss_b4: 1.89403e-07\n",
      "Iter 19400, Loss: 2.20548e-04, Loss_res: 7.05353e-05, Loss_ic1: 4.03080e-05, Loss_ic2: 1.00966e-04, Loss_b1: 1.13180e-06, Loss_b2: 7.24254e-06, Loss_b3: 1.59509e-07, Loss_b4: 2.04386e-07\n",
      "Iter 19500, Loss: 4.61035e-05, Loss_res: 3.78883e-05, Loss_ic1: 5.34213e-06, Loss_ic2: 1.22538e-06, Loss_b1: 1.18943e-06, Loss_b2: 1.02049e-07, Loss_b3: 1.74948e-07, Loss_b4: 1.81266e-07\n",
      "Iter 19600, Loss: 1.66151e-04, Loss_res: 6.93217e-05, Loss_ic1: 2.89642e-05, Loss_ic2: 6.14473e-05, Loss_b1: 4.76165e-06, Loss_b2: 1.31332e-06, Loss_b3: 1.86014e-07, Loss_b4: 1.57184e-07\n",
      "Iter 19700, Loss: 8.25846e-05, Loss_res: 4.00817e-05, Loss_ic1: 1.30588e-05, Loss_ic2: 2.82076e-05, Loss_b1: 3.36326e-07, Loss_b2: 5.39224e-07, Loss_b3: 1.94528e-07, Loss_b4: 1.66383e-07\n",
      "Iter 19800, Loss: 4.92373e-05, Loss_res: 3.32080e-05, Loss_ic1: 5.57810e-06, Loss_ic2: 9.83875e-06, Loss_b1: 1.31133e-07, Loss_b2: 1.56245e-07, Loss_b3: 1.34362e-07, Loss_b4: 1.90708e-07\n",
      "Iter 19900, Loss: 4.23638e-04, Loss_res: 9.27525e-05, Loss_ic1: 1.08720e-04, Loss_ic2: 2.19683e-04, Loss_b1: 2.25146e-07, Loss_b2: 1.94852e-06, Loss_b3: 1.51444e-07, Loss_b4: 1.57674e-07\n",
      "Iter 20000, Loss: 1.04699e-04, Loss_res: 4.34758e-05, Loss_ic1: 2.01719e-05, Loss_ic2: 4.01973e-05, Loss_b1: 1.48372e-07, Loss_b2: 3.85863e-07, Loss_b3: 1.24800e-07, Loss_b4: 1.95068e-07\n",
      "采用L-BFGS优化器\n",
      "Iter 20100, Loss: 2.69831e-05, Loss_res: 2.47546e-05, Loss_ic1: 8.10574e-07, Loss_ic2: 8.82000e-07, Loss_b1: 5.34374e-08, Loss_b2: 8.42340e-08, Loss_b3: 1.98649e-07, Loss_b4: 1.99625e-07\n",
      "Iter 20200, Loss: 2.26549e-05, Loss_res: 2.04254e-05, Loss_ic1: 6.76075e-07, Loss_ic2: 9.96494e-07, Loss_b1: 2.87864e-08, Loss_b2: 8.33263e-08, Loss_b3: 2.28400e-07, Loss_b4: 2.16346e-07\n",
      "Iter 20300, Loss: 2.02923e-05, Loss_res: 1.79866e-05, Loss_ic1: 5.26862e-07, Loss_ic2: 1.08664e-06, Loss_b1: 7.38903e-08, Loss_b2: 1.90871e-07, Loss_b3: 2.17927e-07, Loss_b4: 2.09555e-07\n",
      "Iter 20400, Loss: 1.78642e-05, Loss_res: 1.60344e-05, Loss_ic1: 5.11579e-07, Loss_ic2: 8.12551e-07, Loss_b1: 5.91232e-08, Loss_b2: 1.44601e-07, Loss_b3: 1.38579e-07, Loss_b4: 1.63336e-07\n",
      "Iter 20500, Loss: 1.61796e-05, Loss_res: 1.45020e-05, Loss_ic1: 4.81291e-07, Loss_ic2: 6.22698e-07, Loss_b1: 8.12760e-08, Loss_b2: 1.90530e-07, Loss_b3: 1.44433e-07, Loss_b4: 1.57397e-07\n",
      "Iter 20600, Loss: 1.42943e-05, Loss_res: 1.30003e-05, Loss_ic1: 4.10186e-07, Loss_ic2: 5.26701e-07, Loss_b1: 1.03147e-08, Loss_b2: 8.88631e-08, Loss_b3: 1.05335e-07, Loss_b4: 1.52652e-07\n",
      "Iter 20700, Loss: 1.28127e-05, Loss_res: 1.15973e-05, Loss_ic1: 3.49606e-07, Loss_ic2: 4.85326e-07, Loss_b1: 1.76868e-08, Loss_b2: 9.15473e-08, Loss_b3: 1.27878e-07, Loss_b4: 1.43344e-07\n",
      "Iter 20800, Loss: 1.14156e-05, Loss_res: 1.02754e-05, Loss_ic1: 2.92550e-07, Loss_ic2: 4.35318e-07, Loss_b1: 2.74948e-08, Loss_b2: 1.16204e-07, Loss_b3: 1.17204e-07, Loss_b4: 1.51453e-07\n",
      "Iter 20900, Loss: 1.03990e-05, Loss_res: 9.36545e-06, Loss_ic1: 1.93223e-07, Loss_ic2: 3.32364e-07, Loss_b1: 4.47270e-08, Loss_b2: 1.74405e-07, Loss_b3: 1.59567e-07, Loss_b4: 1.29260e-07\n",
      "Iter 21000, Loss: 9.27399e-06, Loss_res: 8.31177e-06, Loss_ic1: 1.92034e-07, Loss_ic2: 3.11492e-07, Loss_b1: 3.81342e-08, Loss_b2: 2.09597e-07, Loss_b3: 9.77370e-08, Loss_b4: 1.13232e-07\n",
      "Iter 21100, Loss: 8.49094e-06, Loss_res: 7.53588e-06, Loss_ic1: 2.55261e-07, Loss_ic2: 2.50987e-07, Loss_b1: 3.00967e-08, Loss_b2: 2.28236e-07, Loss_b3: 9.13003e-08, Loss_b4: 9.91753e-08\n",
      "Iter 21200, Loss: 7.67179e-06, Loss_res: 6.79921e-06, Loss_ic1: 2.66302e-07, Loss_ic2: 2.56007e-07, Loss_b1: 1.35404e-08, Loss_b2: 1.49358e-07, Loss_b3: 6.43225e-08, Loss_b4: 1.23049e-07\n",
      "Iter 21300, Loss: 7.16249e-06, Loss_res: 6.33423e-06, Loss_ic1: 2.26424e-07, Loss_ic2: 2.76444e-07, Loss_b1: 1.48635e-08, Loss_b2: 9.87360e-08, Loss_b3: 8.63683e-08, Loss_b4: 1.25433e-07\n",
      "Iter 21400, Loss: 6.54207e-06, Loss_res: 5.73192e-06, Loss_ic1: 2.00235e-07, Loss_ic2: 2.91681e-07, Loss_b1: 8.85033e-09, Loss_b2: 8.65926e-08, Loss_b3: 9.41701e-08, Loss_b4: 1.28614e-07\n",
      "Iter 21500, Loss: 6.00868e-06, Loss_res: 5.28715e-06, Loss_ic1: 1.45973e-07, Loss_ic2: 3.24159e-07, Loss_b1: 6.54365e-09, Loss_b2: 6.88657e-08, Loss_b3: 6.42779e-08, Loss_b4: 1.11712e-07\n",
      "Iter 21600, Loss: 5.53385e-06, Loss_res: 4.89336e-06, Loss_ic1: 1.12945e-07, Loss_ic2: 3.12505e-07, Loss_b1: 9.39205e-09, Loss_b2: 4.93794e-08, Loss_b3: 3.29563e-08, Loss_b4: 1.23309e-07\n",
      "Iter 21700, Loss: 5.20602e-06, Loss_res: 4.62936e-06, Loss_ic1: 9.39962e-08, Loss_ic2: 2.87964e-07, Loss_b1: 1.24176e-08, Loss_b2: 3.92411e-08, Loss_b3: 2.76393e-08, Loss_b4: 1.15407e-07\n",
      "Iter 21800, Loss: 4.94533e-06, Loss_res: 4.39612e-06, Loss_ic1: 9.99074e-08, Loss_ic2: 2.58754e-07, Loss_b1: 1.65914e-08, Loss_b2: 4.27656e-08, Loss_b3: 1.97268e-08, Loss_b4: 1.11465e-07\n",
      "Iter 21900, Loss: 4.68923e-06, Loss_res: 4.16761e-06, Loss_ic1: 7.85887e-08, Loss_ic2: 2.76946e-07, Loss_b1: 8.93651e-09, Loss_b2: 4.21181e-08, Loss_b3: 1.91073e-08, Loss_b4: 9.59213e-08\n",
      "Iter 22000, Loss: 4.41288e-06, Loss_res: 3.91718e-06, Loss_ic1: 8.92099e-08, Loss_ic2: 2.48273e-07, Loss_b1: 8.26059e-09, Loss_b2: 4.60841e-08, Loss_b3: 2.22916e-08, Loss_b4: 8.15785e-08\n",
      "Iter 22100, Loss: 4.21609e-06, Loss_res: 3.72934e-06, Loss_ic1: 8.43300e-08, Loss_ic2: 2.47940e-07, Loss_b1: 9.14946e-09, Loss_b2: 5.70069e-08, Loss_b3: 1.22011e-08, Loss_b4: 7.61219e-08\n",
      "Iter 22200, Loss: 3.98320e-06, Loss_res: 3.52463e-06, Loss_ic1: 8.19875e-08, Loss_ic2: 2.40713e-07, Loss_b1: 7.25195e-09, Loss_b2: 4.20181e-08, Loss_b3: 1.20169e-08, Loss_b4: 7.45743e-08\n",
      "Iter 22300, Loss: 3.80451e-06, Loss_res: 3.35518e-06, Loss_ic1: 7.53037e-08, Loss_ic2: 2.27742e-07, Loss_b1: 1.78423e-08, Loss_b2: 4.73262e-08, Loss_b3: 1.33098e-08, Loss_b4: 6.78101e-08\n",
      "Iter 22400, Loss: 3.64564e-06, Loss_res: 3.21744e-06, Loss_ic1: 7.79374e-08, Loss_ic2: 2.28776e-07, Loss_b1: 7.22236e-09, Loss_b2: 3.63233e-08, Loss_b3: 1.51774e-08, Loss_b4: 6.27567e-08\n",
      "Iter 22500, Loss: 3.46325e-06, Loss_res: 3.05529e-06, Loss_ic1: 7.74422e-08, Loss_ic2: 2.21339e-07, Loss_b1: 4.58966e-09, Loss_b2: 2.44055e-08, Loss_b3: 1.90832e-08, Loss_b4: 6.11034e-08\n",
      "Iter 22600, Loss: 3.27303e-06, Loss_res: 2.87264e-06, Loss_ic1: 8.16554e-08, Loss_ic2: 1.98072e-07, Loss_b1: 4.27861e-09, Loss_b2: 3.17743e-08, Loss_b3: 2.57314e-08, Loss_b4: 5.88799e-08\n",
      "Iter 22700, Loss: 3.10737e-06, Loss_res: 2.71707e-06, Loss_ic1: 7.67279e-08, Loss_ic2: 1.96435e-07, Loss_b1: 2.74746e-09, Loss_b2: 2.84227e-08, Loss_b3: 3.32562e-08, Loss_b4: 5.27132e-08\n",
      "Iter 22800, Loss: 2.98119e-06, Loss_res: 2.60273e-06, Loss_ic1: 6.74252e-08, Loss_ic2: 1.77893e-07, Loss_b1: 8.92093e-09, Loss_b2: 3.50976e-08, Loss_b3: 4.11243e-08, Loss_b4: 4.79972e-08\n",
      "Iter 22900, Loss: 2.83411e-06, Loss_res: 2.46962e-06, Loss_ic1: 5.89869e-08, Loss_ic2: 1.73030e-07, Loss_b1: 6.14594e-09, Loss_b2: 4.08400e-08, Loss_b3: 4.14813e-08, Loss_b4: 4.40046e-08\n",
      "Iter 23000, Loss: 2.68711e-06, Loss_res: 2.35616e-06, Loss_ic1: 5.55225e-08, Loss_ic2: 1.57236e-07, Loss_b1: 6.30987e-09, Loss_b2: 3.88403e-08, Loss_b3: 3.72609e-08, Loss_b4: 3.57773e-08\n",
      "Iter 23100, Loss: 2.56305e-06, Loss_res: 2.24720e-06, Loss_ic1: 5.19471e-08, Loss_ic2: 1.47480e-07, Loss_b1: 5.73576e-09, Loss_b2: 4.45417e-08, Loss_b3: 3.54411e-08, Loss_b4: 3.07030e-08\n",
      "Iter 23200, Loss: 2.45843e-06, Loss_res: 2.15374e-06, Loss_ic1: 6.29964e-08, Loss_ic2: 1.42992e-07, Loss_b1: 3.20217e-09, Loss_b2: 4.38276e-08, Loss_b3: 2.81801e-08, Loss_b4: 2.34894e-08\n",
      "Iter 23300, Loss: 2.37881e-06, Loss_res: 2.08646e-06, Loss_ic1: 6.42040e-08, Loss_ic2: 1.33592e-07, Loss_b1: 6.33482e-09, Loss_b2: 4.55452e-08, Loss_b3: 2.45737e-08, Loss_b4: 1.81033e-08\n",
      "Iter 23400, Loss: 2.28618e-06, Loss_res: 1.99682e-06, Loss_ic1: 6.20205e-08, Loss_ic2: 1.30535e-07, Loss_b1: 5.49782e-09, Loss_b2: 4.07829e-08, Loss_b3: 3.24424e-08, Loss_b4: 1.80831e-08\n",
      "Iter 23500, Loss: 2.21428e-06, Loss_res: 1.94061e-06, Loss_ic1: 6.14640e-08, Loss_ic2: 1.15427e-07, Loss_b1: 9.87079e-09, Loss_b2: 4.26361e-08, Loss_b3: 2.60819e-08, Loss_b4: 1.81874e-08\n",
      "Iter 23600, Loss: 2.11282e-06, Loss_res: 1.84938e-06, Loss_ic1: 6.02012e-08, Loss_ic2: 1.21320e-07, Loss_b1: 1.69565e-08, Loss_b2: 2.62447e-08, Loss_b3: 1.63235e-08, Loss_b4: 2.23961e-08\n",
      "Iter 23700, Loss: 2.04410e-06, Loss_res: 1.78552e-06, Loss_ic1: 6.64527e-08, Loss_ic2: 1.12598e-07, Loss_b1: 1.79308e-08, Loss_b2: 2.87411e-08, Loss_b3: 1.08619e-08, Loss_b4: 2.19989e-08\n",
      "Iter 23800, Loss: 1.97986e-06, Loss_res: 1.71032e-06, Loss_ic1: 6.55947e-08, Loss_ic2: 1.15173e-07, Loss_b1: 1.80072e-08, Loss_b2: 3.43413e-08, Loss_b3: 1.14473e-08, Loss_b4: 2.49817e-08\n",
      "Iter 23900, Loss: 1.92430e-06, Loss_res: 1.67199e-06, Loss_ic1: 5.81650e-08, Loss_ic2: 1.06876e-07, Loss_b1: 1.48634e-08, Loss_b2: 3.50160e-08, Loss_b3: 1.33796e-08, Loss_b4: 2.40066e-08\n",
      "Iter 24000, Loss: 1.86321e-06, Loss_res: 1.61577e-06, Loss_ic1: 5.64301e-08, Loss_ic2: 1.05222e-07, Loss_b1: 1.42848e-08, Loss_b2: 3.45714e-08, Loss_b3: 1.06102e-08, Loss_b4: 2.63174e-08\n",
      "Iter 24100, Loss: 1.81037e-06, Loss_res: 1.56432e-06, Loss_ic1: 5.82484e-08, Loss_ic2: 1.04311e-07, Loss_b1: 1.45203e-08, Loss_b2: 2.96969e-08, Loss_b3: 1.32046e-08, Loss_b4: 2.60771e-08\n",
      "Iter 24200, Loss: 1.76089e-06, Loss_res: 1.51980e-06, Loss_ic1: 5.97786e-08, Loss_ic2: 9.61544e-08, Loss_b1: 1.61280e-08, Loss_b2: 3.76605e-08, Loss_b3: 8.12157e-09, Loss_b4: 2.32531e-08\n",
      "Iter 24300, Loss: 1.70838e-06, Loss_res: 1.47349e-06, Loss_ic1: 6.02360e-08, Loss_ic2: 9.59033e-08, Loss_b1: 1.48427e-08, Loss_b2: 3.86128e-08, Loss_b3: 5.23623e-09, Loss_b4: 2.00644e-08\n",
      "Iter 24400, Loss: 1.65554e-06, Loss_res: 1.41924e-06, Loss_ic1: 6.01869e-08, Loss_ic2: 9.60466e-08, Loss_b1: 1.50142e-08, Loss_b2: 3.71036e-08, Loss_b3: 8.47376e-09, Loss_b4: 1.94700e-08\n",
      "Iter 24500, Loss: 1.60871e-06, Loss_res: 1.38148e-06, Loss_ic1: 5.74479e-08, Loss_ic2: 9.31129e-08, Loss_b1: 1.69136e-08, Loss_b2: 2.86315e-08, Loss_b3: 9.25782e-09, Loss_b4: 2.18675e-08\n",
      "Iter 24600, Loss: 1.56824e-06, Loss_res: 1.35359e-06, Loss_ic1: 5.53078e-08, Loss_ic2: 8.07644e-08, Loss_b1: 1.60741e-08, Loss_b2: 3.28861e-08, Loss_b3: 8.36181e-09, Loss_b4: 2.12551e-08\n",
      "Iter 24700, Loss: 1.52002e-06, Loss_res: 1.31390e-06, Loss_ic1: 5.80418e-08, Loss_ic2: 8.43139e-08, Loss_b1: 1.49726e-08, Loss_b2: 2.36375e-08, Loss_b3: 6.23466e-09, Loss_b4: 1.89239e-08\n",
      "Iter 24800, Loss: 1.47557e-06, Loss_res: 1.28061e-06, Loss_ic1: 5.19009e-08, Loss_ic2: 8.19259e-08, Loss_b1: 1.30259e-08, Loss_b2: 1.93295e-08, Loss_b3: 9.72744e-09, Loss_b4: 1.90436e-08\n",
      "Iter 24900, Loss: 1.43148e-06, Loss_res: 1.24012e-06, Loss_ic1: 5.05753e-08, Loss_ic2: 7.79322e-08, Loss_b1: 1.25864e-08, Loss_b2: 2.08175e-08, Loss_b3: 1.14322e-08, Loss_b4: 1.80203e-08\n",
      "Iter 25000, Loss: 1.39202e-06, Loss_res: 1.20868e-06, Loss_ic1: 5.23974e-08, Loss_ic2: 6.87041e-08, Loss_b1: 1.31216e-08, Loss_b2: 2.03699e-08, Loss_b3: 1.10059e-08, Loss_b4: 1.77344e-08\n",
      "Iter 25100, Loss: 1.36160e-06, Loss_res: 1.18392e-06, Loss_ic1: 5.28774e-08, Loss_ic2: 6.83275e-08, Loss_b1: 1.06828e-08, Loss_b2: 1.70809e-08, Loss_b3: 1.18981e-08, Loss_b4: 1.68146e-08\n",
      "Iter 25200, Loss: 1.32359e-06, Loss_res: 1.15605e-06, Loss_ic1: 4.89352e-08, Loss_ic2: 6.35932e-08, Loss_b1: 8.65242e-09, Loss_b2: 1.64673e-08, Loss_b3: 1.38620e-08, Loss_b4: 1.60348e-08\n",
      "Iter 25300, Loss: 1.28490e-06, Loss_res: 1.12864e-06, Loss_ic1: 4.44305e-08, Loss_ic2: 5.73153e-08, Loss_b1: 5.97552e-09, Loss_b2: 1.76577e-08, Loss_b3: 1.58619e-08, Loss_b4: 1.50170e-08\n",
      "Iter 25400, Loss: 1.25302e-06, Loss_res: 1.09929e-06, Loss_ic1: 4.65029e-08, Loss_ic2: 5.23706e-08, Loss_b1: 5.90319e-09, Loss_b2: 2.01634e-08, Loss_b3: 1.45744e-08, Loss_b4: 1.42156e-08\n",
      "Iter 25500, Loss: 1.22212e-06, Loss_res: 1.06994e-06, Loss_ic1: 4.68475e-08, Loss_ic2: 5.08851e-08, Loss_b1: 6.83003e-09, Loss_b2: 1.90729e-08, Loss_b3: 1.37128e-08, Loss_b4: 1.48336e-08\n",
      "Iter 25600, Loss: 1.18562e-06, Loss_res: 1.03738e-06, Loss_ic1: 5.13046e-08, Loss_ic2: 4.91324e-08, Loss_b1: 6.54533e-09, Loss_b2: 1.46809e-08, Loss_b3: 1.12567e-08, Loss_b4: 1.53182e-08\n",
      "Iter 25700, Loss: 1.15505e-06, Loss_res: 1.01297e-06, Loss_ic1: 4.74005e-08, Loss_ic2: 4.39220e-08, Loss_b1: 7.38927e-09, Loss_b2: 1.36161e-08, Loss_b3: 1.34965e-08, Loss_b4: 1.62534e-08\n",
      "Iter 25800, Loss: 1.12590e-06, Loss_res: 9.84174e-07, Loss_ic1: 4.60036e-08, Loss_ic2: 4.44871e-08, Loss_b1: 8.59644e-09, Loss_b2: 1.08342e-08, Loss_b3: 1.34655e-08, Loss_b4: 1.83435e-08\n",
      "Iter 25900, Loss: 1.09671e-06, Loss_res: 9.58827e-07, Loss_ic1: 5.02220e-08, Loss_ic2: 3.83047e-08, Loss_b1: 8.82642e-09, Loss_b2: 1.03312e-08, Loss_b3: 1.10223e-08, Loss_b4: 1.91772e-08\n",
      "Iter 26000, Loss: 1.06521e-06, Loss_res: 9.29549e-07, Loss_ic1: 4.83860e-08, Loss_ic2: 3.74016e-08, Loss_b1: 8.88858e-09, Loss_b2: 1.05864e-08, Loss_b3: 1.11511e-08, Loss_b4: 1.92487e-08\n",
      "Iter 26100, Loss: 1.04172e-06, Loss_res: 9.07095e-07, Loss_ic1: 4.85340e-08, Loss_ic2: 3.71704e-08, Loss_b1: 8.08219e-09, Loss_b2: 9.47283e-09, Loss_b3: 1.20382e-08, Loss_b4: 1.93241e-08\n",
      "Iter 26200, Loss: 1.01969e-06, Loss_res: 8.87043e-07, Loss_ic1: 4.91707e-08, Loss_ic2: 3.49897e-08, Loss_b1: 6.94249e-09, Loss_b2: 9.92303e-09, Loss_b3: 1.35886e-08, Loss_b4: 1.80284e-08\n",
      "Iter 26300, Loss: 1.00561e-06, Loss_res: 8.70611e-07, Loss_ic1: 5.02298e-08, Loss_ic2: 3.48561e-08, Loss_b1: 7.00620e-09, Loss_b2: 9.70967e-09, Loss_b3: 1.47830e-08, Loss_b4: 1.84112e-08\n",
      "Iter 26400, Loss: 9.81378e-07, Loss_res: 8.44417e-07, Loss_ic1: 5.22532e-08, Loss_ic2: 3.55845e-08, Loss_b1: 6.30884e-09, Loss_b2: 8.42837e-09, Loss_b3: 1.47739e-08, Loss_b4: 1.96119e-08\n",
      "Iter 26500, Loss: 9.60093e-07, Loss_res: 8.32260e-07, Loss_ic1: 4.70711e-08, Loss_ic2: 3.30779e-08, Loss_b1: 4.43130e-09, Loss_b2: 9.26098e-09, Loss_b3: 1.68107e-08, Loss_b4: 1.71813e-08\n",
      "Iter 26600, Loss: 9.41741e-07, Loss_res: 8.17756e-07, Loss_ic1: 4.53751e-08, Loss_ic2: 3.21140e-08, Loss_b1: 5.87595e-09, Loss_b2: 9.24047e-09, Loss_b3: 1.56533e-08, Loss_b4: 1.57267e-08\n",
      "Iter 26700, Loss: 9.10137e-07, Loss_res: 7.89321e-07, Loss_ic1: 4.90695e-08, Loss_ic2: 2.95102e-08, Loss_b1: 4.61653e-09, Loss_b2: 7.76023e-09, Loss_b3: 1.39435e-08, Loss_b4: 1.59156e-08\n",
      "Iter 26800, Loss: 8.85497e-07, Loss_res: 7.66916e-07, Loss_ic1: 4.86286e-08, Loss_ic2: 2.71118e-08, Loss_b1: 4.33022e-09, Loss_b2: 8.14141e-09, Loss_b3: 1.49392e-08, Loss_b4: 1.54298e-08\n",
      "Iter 26900, Loss: 8.62946e-07, Loss_res: 7.49621e-07, Loss_ic1: 4.57332e-08, Loss_ic2: 2.67788e-08, Loss_b1: 2.89233e-09, Loss_b2: 8.81602e-09, Loss_b3: 1.49490e-08, Loss_b4: 1.41553e-08\n",
      "Iter 27000, Loss: 8.44961e-07, Loss_res: 7.32258e-07, Loss_ic1: 4.50113e-08, Loss_ic2: 2.71492e-08, Loss_b1: 2.39549e-09, Loss_b2: 9.32250e-09, Loss_b3: 1.52166e-08, Loss_b4: 1.36085e-08\n",
      "Iter 27100, Loss: 8.24902e-07, Loss_res: 7.11986e-07, Loss_ic1: 4.41792e-08, Loss_ic2: 2.69029e-08, Loss_b1: 2.85540e-09, Loss_b2: 1.00421e-08, Loss_b3: 1.48516e-08, Loss_b4: 1.40855e-08\n",
      "Iter 27200, Loss: 8.06770e-07, Loss_res: 6.98536e-07, Loss_ic1: 3.98254e-08, Loss_ic2: 2.67323e-08, Loss_b1: 3.39599e-09, Loss_b2: 9.24611e-09, Loss_b3: 1.53579e-08, Loss_b4: 1.36761e-08\n",
      "Iter 27300, Loss: 7.93670e-07, Loss_res: 6.85657e-07, Loss_ic1: 3.74291e-08, Loss_ic2: 2.75232e-08, Loss_b1: 3.31917e-09, Loss_b2: 8.94487e-09, Loss_b3: 1.61392e-08, Loss_b4: 1.46575e-08\n",
      "Iter 27400, Loss: 7.71652e-07, Loss_res: 6.60924e-07, Loss_ic1: 3.81841e-08, Loss_ic2: 2.80399e-08, Loss_b1: 3.69192e-09, Loss_b2: 8.23636e-09, Loss_b3: 1.66878e-08, Loss_b4: 1.58879e-08\n",
      "Iter 27500, Loss: 7.63215e-07, Loss_res: 6.51402e-07, Loss_ic1: 4.03906e-08, Loss_ic2: 2.66319e-08, Loss_b1: 3.48140e-09, Loss_b2: 8.37502e-09, Loss_b3: 1.65966e-08, Loss_b4: 1.63375e-08\n",
      "Iter 27600, Loss: 7.62657e-07, Loss_res: 6.51014e-07, Loss_ic1: 4.01603e-08, Loss_ic2: 2.66003e-08, Loss_b1: 3.51609e-09, Loss_b2: 8.35406e-09, Loss_b3: 1.66408e-08, Loss_b4: 1.63714e-08\n",
      "Iter 27700, Loss: 7.62234e-07, Loss_res: 6.50655e-07, Loss_ic1: 4.00590e-08, Loss_ic2: 2.65574e-08, Loss_b1: 3.53957e-09, Loss_b2: 8.36649e-09, Loss_b3: 1.66657e-08, Loss_b4: 1.63910e-08\n",
      "Iter 27800, Loss: 7.61880e-07, Loss_res: 6.50336e-07, Loss_ic1: 3.99946e-08, Loss_ic2: 2.65159e-08, Loss_b1: 3.55639e-09, Loss_b2: 8.38815e-09, Loss_b3: 1.66839e-08, Loss_b4: 1.64050e-08\n",
      "Iter 27900, Loss: 7.61569e-07, Loss_res: 6.50048e-07, Loss_ic1: 3.99460e-08, Loss_ic2: 2.64786e-08, Loss_b1: 3.56972e-09, Loss_b2: 8.41108e-09, Loss_b3: 1.66991e-08, Loss_b4: 1.64161e-08\n",
      "Iter 28000, Loss: 7.61287e-07, Loss_res: 6.49783e-07, Loss_ic1: 3.99066e-08, Loss_ic2: 2.64460e-08, Loss_b1: 3.58067e-09, Loss_b2: 8.43239e-09, Loss_b3: 1.67126e-08, Loss_b4: 1.64253e-08\n",
      "Iter 28100, Loss: 7.61026e-07, Loss_res: 6.49536e-07, Loss_ic1: 3.98735e-08, Loss_ic2: 2.64177e-08, Loss_b1: 3.58970e-09, Loss_b2: 8.45114e-09, Loss_b3: 1.67252e-08, Loss_b4: 1.64331e-08\n",
      "Iter 28200, Loss: 7.60783e-07, Loss_res: 6.49303e-07, Loss_ic1: 3.98451e-08, Loss_ic2: 2.63932e-08, Loss_b1: 3.59714e-09, Loss_b2: 8.46716e-09, Loss_b3: 1.67372e-08, Loss_b4: 1.64399e-08\n",
      "Iter 28300, Loss: 7.60553e-07, Loss_res: 6.49082e-07, Loss_ic1: 3.98205e-08, Loss_ic2: 2.63719e-08, Loss_b1: 3.60321e-09, Loss_b2: 8.48060e-09, Loss_b3: 1.67487e-08, Loss_b4: 1.64459e-08\n",
      "Iter 28400, Loss: 7.60334e-07, Loss_res: 6.48871e-07, Loss_ic1: 3.97987e-08, Loss_ic2: 2.63532e-08, Loss_b1: 3.60814e-09, Loss_b2: 8.49173e-09, Loss_b3: 1.67598e-08, Loss_b4: 1.64514e-08\n",
      "Iter 28500, Loss: 7.60125e-07, Loss_res: 6.48669e-07, Loss_ic1: 3.97792e-08, Loss_ic2: 2.63369e-08, Loss_b1: 3.61210e-09, Loss_b2: 8.50088e-09, Loss_b3: 1.67706e-08, Loss_b4: 1.64564e-08\n",
      "Iter 28600, Loss: 7.59924e-07, Loss_res: 6.48474e-07, Loss_ic1: 3.97615e-08, Loss_ic2: 2.63224e-08, Loss_b1: 3.61527e-09, Loss_b2: 8.50833e-09, Loss_b3: 1.67812e-08, Loss_b4: 1.64610e-08\n",
      "Iter 28700, Loss: 7.59730e-07, Loss_res: 6.48287e-07, Loss_ic1: 3.97453e-08, Loss_ic2: 2.63096e-08, Loss_b1: 3.61777e-09, Loss_b2: 8.51434e-09, Loss_b3: 1.67915e-08, Loss_b4: 1.64653e-08\n",
      "Iter 28800, Loss: 7.59543e-07, Loss_res: 6.48105e-07, Loss_ic1: 3.97302e-08, Loss_ic2: 2.62981e-08, Loss_b1: 3.61973e-09, Loss_b2: 8.51914e-09, Loss_b3: 1.68016e-08, Loss_b4: 1.64694e-08\n",
      "Iter 28900, Loss: 7.59362e-07, Loss_res: 6.47929e-07, Loss_ic1: 3.97161e-08, Loss_ic2: 2.62878e-08, Loss_b1: 3.62125e-09, Loss_b2: 8.52292e-09, Loss_b3: 1.68114e-08, Loss_b4: 1.64733e-08\n",
      "Iter 29000, Loss: 7.59185e-07, Loss_res: 6.47758e-07, Loss_ic1: 3.97028e-08, Loss_ic2: 2.62785e-08, Loss_b1: 3.62241e-09, Loss_b2: 8.52584e-09, Loss_b3: 1.68210e-08, Loss_b4: 1.64770e-08\n",
      "Iter 29100, Loss: 7.59013e-07, Loss_res: 6.47591e-07, Loss_ic1: 3.96902e-08, Loss_ic2: 2.62700e-08, Loss_b1: 3.62327e-09, Loss_b2: 8.52803e-09, Loss_b3: 1.68304e-08, Loss_b4: 1.64805e-08\n",
      "Iter 29200, Loss: 7.58846e-07, Loss_res: 6.47429e-07, Loss_ic1: 3.96780e-08, Loss_ic2: 2.62622e-08, Loss_b1: 3.62390e-09, Loss_b2: 8.52961e-09, Loss_b3: 1.68395e-08, Loss_b4: 1.64839e-08\n",
      "Iter 29300, Loss: 7.58682e-07, Loss_res: 6.47270e-07, Loss_ic1: 3.96663e-08, Loss_ic2: 2.62551e-08, Loss_b1: 3.62434e-09, Loss_b2: 8.53067e-09, Loss_b3: 1.68484e-08, Loss_b4: 1.64871e-08\n",
      "Iter 29400, Loss: 7.58522e-07, Loss_res: 6.47115e-07, Loss_ic1: 3.96550e-08, Loss_ic2: 2.62485e-08, Loss_b1: 3.62463e-09, Loss_b2: 8.53127e-09, Loss_b3: 1.68571e-08, Loss_b4: 1.64901e-08\n",
      "Iter 29500, Loss: 7.58365e-07, Loss_res: 6.46964e-07, Loss_ic1: 3.96440e-08, Loss_ic2: 2.62424e-08, Loss_b1: 3.62480e-09, Loss_b2: 8.53149e-09, Loss_b3: 1.68656e-08, Loss_b4: 1.64931e-08\n",
      "Iter 29600, Loss: 7.58211e-07, Loss_res: 6.46815e-07, Loss_ic1: 3.96333e-08, Loss_ic2: 2.62367e-08, Loss_b1: 3.62487e-09, Loss_b2: 8.53137e-09, Loss_b3: 1.68739e-08, Loss_b4: 1.64959e-08\n",
      "Iter 29700, Loss: 7.58060e-07, Loss_res: 6.46669e-07, Loss_ic1: 3.96228e-08, Loss_ic2: 2.62314e-08, Loss_b1: 3.62486e-09, Loss_b2: 8.53096e-09, Loss_b3: 1.68820e-08, Loss_b4: 1.64986e-08\n",
      "Iter 29800, Loss: 7.57911e-07, Loss_res: 6.46526e-07, Loss_ic1: 3.96125e-08, Loss_ic2: 2.62264e-08, Loss_b1: 3.62479e-09, Loss_b2: 8.53030e-09, Loss_b3: 1.68899e-08, Loss_b4: 1.65011e-08\n",
      "Iter 29900, Loss: 7.57765e-07, Loss_res: 6.46386e-07, Loss_ic1: 3.96024e-08, Loss_ic2: 2.62217e-08, Loss_b1: 3.62467e-09, Loss_b2: 8.52941e-09, Loss_b3: 1.68975e-08, Loss_b4: 1.65036e-08\n",
      "Iter 30000, Loss: 7.57621e-07, Loss_res: 6.46248e-07, Loss_ic1: 3.95925e-08, Loss_ic2: 2.62172e-08, Loss_b1: 3.62451e-09, Loss_b2: 8.52833e-09, Loss_b3: 1.69050e-08, Loss_b4: 1.65060e-08\n",
      "Iter 30100, Loss: 7.57480e-07, Loss_res: 6.46112e-07, Loss_ic1: 3.95828e-08, Loss_ic2: 2.62130e-08, Loss_b1: 3.62432e-09, Loss_b2: 8.52708e-09, Loss_b3: 1.69124e-08, Loss_b4: 1.65083e-08\n",
      "Iter 30200, Loss: 7.57340e-07, Loss_res: 6.45978e-07, Loss_ic1: 3.95732e-08, Loss_ic2: 2.62089e-08, Loss_b1: 3.62410e-09, Loss_b2: 8.52568e-09, Loss_b3: 1.69195e-08, Loss_b4: 1.65105e-08\n",
      "Iter 30300, Loss: 7.57202e-07, Loss_res: 6.45847e-07, Loss_ic1: 3.95637e-08, Loss_ic2: 2.62051e-08, Loss_b1: 3.62386e-09, Loss_b2: 8.52413e-09, Loss_b3: 1.69264e-08, Loss_b4: 1.65125e-08\n",
      "Iter 30400, Loss: 7.57066e-07, Loss_res: 6.45717e-07, Loss_ic1: 3.95543e-08, Loss_ic2: 2.62014e-08, Loss_b1: 3.62361e-09, Loss_b2: 8.52247e-09, Loss_b3: 1.69332e-08, Loss_b4: 1.65146e-08\n",
      "Iter 30500, Loss: 7.56932e-07, Loss_res: 6.45589e-07, Loss_ic1: 3.95451e-08, Loss_ic2: 2.61978e-08, Loss_b1: 3.62333e-09, Loss_b2: 8.52071e-09, Loss_b3: 1.69398e-08, Loss_b4: 1.65165e-08\n",
      "Iter 30600, Loss: 7.56800e-07, Loss_res: 6.45463e-07, Loss_ic1: 3.95360e-08, Loss_ic2: 2.61943e-08, Loss_b1: 3.62305e-09, Loss_b2: 8.51884e-09, Loss_b3: 1.69463e-08, Loss_b4: 1.65183e-08\n",
      "Iter 30700, Loss: 7.56669e-07, Loss_res: 6.45339e-07, Loss_ic1: 3.95269e-08, Loss_ic2: 2.61910e-08, Loss_b1: 3.62276e-09, Loss_b2: 8.51690e-09, Loss_b3: 1.69526e-08, Loss_b4: 1.65201e-08\n",
      "Iter 30800, Loss: 7.56539e-07, Loss_res: 6.45216e-07, Loss_ic1: 3.95180e-08, Loss_ic2: 2.61877e-08, Loss_b1: 3.62245e-09, Loss_b2: 8.51487e-09, Loss_b3: 1.69588e-08, Loss_b4: 1.65218e-08\n",
      "Iter 30900, Loss: 7.56411e-07, Loss_res: 6.45095e-07, Loss_ic1: 3.95092e-08, Loss_ic2: 2.61846e-08, Loss_b1: 3.62214e-09, Loss_b2: 8.51279e-09, Loss_b3: 1.69648e-08, Loss_b4: 1.65235e-08\n",
      "Iter 31000, Loss: 7.56285e-07, Loss_res: 6.44975e-07, Loss_ic1: 3.95004e-08, Loss_ic2: 2.61815e-08, Loss_b1: 3.62182e-09, Loss_b2: 8.51064e-09, Loss_b3: 1.69706e-08, Loss_b4: 1.65250e-08\n",
      "Iter 31100, Loss: 7.56160e-07, Loss_res: 6.44857e-07, Loss_ic1: 3.94918e-08, Loss_ic2: 2.61784e-08, Loss_b1: 3.62149e-09, Loss_b2: 8.50844e-09, Loss_b3: 1.69763e-08, Loss_b4: 1.65266e-08\n",
      "Iter 31200, Loss: 7.56036e-07, Loss_res: 6.44740e-07, Loss_ic1: 3.94832e-08, Loss_ic2: 2.61754e-08, Loss_b1: 3.62115e-09, Loss_b2: 8.50619e-09, Loss_b3: 1.69819e-08, Loss_b4: 1.65280e-08\n",
      "Iter 31300, Loss: 7.55913e-07, Loss_res: 6.44624e-07, Loss_ic1: 3.94747e-08, Loss_ic2: 2.61725e-08, Loss_b1: 3.62080e-09, Loss_b2: 8.50390e-09, Loss_b3: 1.69874e-08, Loss_b4: 1.65294e-08\n",
      "Iter 31400, Loss: 7.55791e-07, Loss_res: 6.44510e-07, Loss_ic1: 3.94662e-08, Loss_ic2: 2.61696e-08, Loss_b1: 3.62045e-09, Loss_b2: 8.50158e-09, Loss_b3: 1.69927e-08, Loss_b4: 1.65308e-08\n",
      "Iter 31500, Loss: 7.55671e-07, Loss_res: 6.44397e-07, Loss_ic1: 3.94579e-08, Loss_ic2: 2.61667e-08, Loss_b1: 3.62010e-09, Loss_b2: 8.49922e-09, Loss_b3: 1.69979e-08, Loss_b4: 1.65321e-08\n",
      "Iter 31600, Loss: 7.55552e-07, Loss_res: 6.44285e-07, Loss_ic1: 3.94496e-08, Loss_ic2: 2.61639e-08, Loss_b1: 3.61973e-09, Loss_b2: 8.49684e-09, Loss_b3: 1.70030e-08, Loss_b4: 1.65333e-08\n",
      "Iter 31700, Loss: 7.55434e-07, Loss_res: 6.44175e-07, Loss_ic1: 3.94413e-08, Loss_ic2: 2.61611e-08, Loss_b1: 3.61936e-09, Loss_b2: 8.49444e-09, Loss_b3: 1.70079e-08, Loss_b4: 1.65345e-08\n",
      "Iter 31800, Loss: 7.55316e-07, Loss_res: 6.44066e-07, Loss_ic1: 3.94331e-08, Loss_ic2: 2.61583e-08, Loss_b1: 3.61898e-09, Loss_b2: 8.49202e-09, Loss_b3: 1.70128e-08, Loss_b4: 1.65356e-08\n",
      "Iter 31900, Loss: 7.55200e-07, Loss_res: 6.43957e-07, Loss_ic1: 3.94250e-08, Loss_ic2: 2.61556e-08, Loss_b1: 3.61860e-09, Loss_b2: 8.48958e-09, Loss_b3: 1.70175e-08, Loss_b4: 1.65367e-08\n",
      "Iter 32000, Loss: 7.55085e-07, Loss_res: 6.43850e-07, Loss_ic1: 3.94170e-08, Loss_ic2: 2.61528e-08, Loss_b1: 3.61821e-09, Loss_b2: 8.48713e-09, Loss_b3: 1.70221e-08, Loss_b4: 1.65378e-08\n",
      "Iter 32100, Loss: 7.54971e-07, Loss_res: 6.43744e-07, Loss_ic1: 3.94090e-08, Loss_ic2: 2.61501e-08, Loss_b1: 3.61781e-09, Loss_b2: 8.48467e-09, Loss_b3: 1.70266e-08, Loss_b4: 1.65388e-08\n",
      "Iter 32200, Loss: 7.54858e-07, Loss_res: 6.43639e-07, Loss_ic1: 3.94011e-08, Loss_ic2: 2.61474e-08, Loss_b1: 3.61741e-09, Loss_b2: 8.48220e-09, Loss_b3: 1.70310e-08, Loss_b4: 1.65398e-08\n",
      "Iter 32300, Loss: 7.54746e-07, Loss_res: 6.43535e-07, Loss_ic1: 3.93932e-08, Loss_ic2: 2.61446e-08, Loss_b1: 3.61700e-09, Loss_b2: 8.47972e-09, Loss_b3: 1.70353e-08, Loss_b4: 1.65407e-08\n",
      "Iter 32400, Loss: 7.54634e-07, Loss_res: 6.43432e-07, Loss_ic1: 3.93853e-08, Loss_ic2: 2.61419e-08, Loss_b1: 3.61659e-09, Loss_b2: 8.47724e-09, Loss_b3: 1.70395e-08, Loss_b4: 1.65416e-08\n",
      "Iter 32500, Loss: 7.54524e-07, Loss_res: 6.43330e-07, Loss_ic1: 3.93775e-08, Loss_ic2: 2.61392e-08, Loss_b1: 3.61616e-09, Loss_b2: 8.47477e-09, Loss_b3: 1.70436e-08, Loss_b4: 1.65425e-08\n",
      "Iter 32600, Loss: 7.54414e-07, Loss_res: 6.43229e-07, Loss_ic1: 3.93698e-08, Loss_ic2: 2.61365e-08, Loss_b1: 3.61574e-09, Loss_b2: 8.47229e-09, Loss_b3: 1.70476e-08, Loss_b4: 1.65433e-08\n",
      "Iter 32700, Loss: 7.54305e-07, Loss_res: 6.43128e-07, Loss_ic1: 3.93621e-08, Loss_ic2: 2.61338e-08, Loss_b1: 3.61531e-09, Loss_b2: 8.46981e-09, Loss_b3: 1.70515e-08, Loss_b4: 1.65441e-08\n",
      "Iter 32800, Loss: 7.54197e-07, Loss_res: 6.43029e-07, Loss_ic1: 3.93545e-08, Loss_ic2: 2.61311e-08, Loss_b1: 3.61487e-09, Loss_b2: 8.46734e-09, Loss_b3: 1.70553e-08, Loss_b4: 1.65449e-08\n",
      "Iter 32900, Loss: 7.54090e-07, Loss_res: 6.42930e-07, Loss_ic1: 3.93469e-08, Loss_ic2: 2.61284e-08, Loss_b1: 3.61443e-09, Loss_b2: 8.46488e-09, Loss_b3: 1.70590e-08, Loss_b4: 1.65456e-08\n",
      "Iter 33000, Loss: 7.53983e-07, Loss_res: 6.42833e-07, Loss_ic1: 3.93393e-08, Loss_ic2: 2.61256e-08, Loss_b1: 3.61398e-09, Loss_b2: 8.46242e-09, Loss_b3: 1.70627e-08, Loss_b4: 1.65463e-08\n",
      "Iter 33100, Loss: 7.53877e-07, Loss_res: 6.42736e-07, Loss_ic1: 3.93318e-08, Loss_ic2: 2.61229e-08, Loss_b1: 3.61353e-09, Loss_b2: 8.45997e-09, Loss_b3: 1.70662e-08, Loss_b4: 1.65470e-08\n",
      "Iter 33200, Loss: 7.53772e-07, Loss_res: 6.42640e-07, Loss_ic1: 3.93244e-08, Loss_ic2: 2.61202e-08, Loss_b1: 3.61307e-09, Loss_b2: 8.45752e-09, Loss_b3: 1.70697e-08, Loss_b4: 1.65476e-08\n",
      "Iter 33300, Loss: 7.53668e-07, Loss_res: 6.42544e-07, Loss_ic1: 3.93169e-08, Loss_ic2: 2.61174e-08, Loss_b1: 3.61261e-09, Loss_b2: 8.45509e-09, Loss_b3: 1.70731e-08, Loss_b4: 1.65483e-08\n",
      "Iter 33400, Loss: 7.53564e-07, Loss_res: 6.42450e-07, Loss_ic1: 3.93095e-08, Loss_ic2: 2.61147e-08, Loss_b1: 3.61214e-09, Loss_b2: 8.45267e-09, Loss_b3: 1.70764e-08, Loss_b4: 1.65488e-08\n",
      "Iter 33500, Loss: 7.53461e-07, Loss_res: 6.42356e-07, Loss_ic1: 3.93022e-08, Loss_ic2: 2.61119e-08, Loss_b1: 3.61167e-09, Loss_b2: 8.45026e-09, Loss_b3: 1.70796e-08, Loss_b4: 1.65494e-08\n",
      "Iter 33600, Loss: 7.53359e-07, Loss_res: 6.42263e-07, Loss_ic1: 3.92949e-08, Loss_ic2: 2.61091e-08, Loss_b1: 3.61120e-09, Loss_b2: 8.44787e-09, Loss_b3: 1.70828e-08, Loss_b4: 1.65499e-08\n",
      "Iter 33700, Loss: 7.53257e-07, Loss_res: 6.42171e-07, Loss_ic1: 3.92876e-08, Loss_ic2: 2.61063e-08, Loss_b1: 3.61072e-09, Loss_b2: 8.44548e-09, Loss_b3: 1.70858e-08, Loss_b4: 1.65504e-08\n",
      "Iter 33800, Loss: 7.53156e-07, Loss_res: 6.42079e-07, Loss_ic1: 3.92804e-08, Loss_ic2: 2.61035e-08, Loss_b1: 3.61024e-09, Loss_b2: 8.44311e-09, Loss_b3: 1.70888e-08, Loss_b4: 1.65509e-08\n",
      "Iter 33900, Loss: 7.53056e-07, Loss_res: 6.41989e-07, Loss_ic1: 3.92732e-08, Loss_ic2: 2.61007e-08, Loss_b1: 3.60975e-09, Loss_b2: 8.44076e-09, Loss_b3: 1.70918e-08, Loss_b4: 1.65514e-08\n",
      "Iter 34000, Loss: 7.52956e-07, Loss_res: 6.41898e-07, Loss_ic1: 3.92660e-08, Loss_ic2: 2.60979e-08, Loss_b1: 3.60926e-09, Loss_b2: 8.43842e-09, Loss_b3: 1.70946e-08, Loss_b4: 1.65518e-08\n",
      "Iter 34100, Loss: 7.52857e-07, Loss_res: 6.41809e-07, Loss_ic1: 3.92589e-08, Loss_ic2: 2.60951e-08, Loss_b1: 3.60877e-09, Loss_b2: 8.43609e-09, Loss_b3: 1.70974e-08, Loss_b4: 1.65522e-08\n",
      "Iter 34200, Loss: 7.52759e-07, Loss_res: 6.41720e-07, Loss_ic1: 3.92518e-08, Loss_ic2: 2.60923e-08, Loss_b1: 3.60828e-09, Loss_b2: 8.43378e-09, Loss_b3: 1.71001e-08, Loss_b4: 1.65526e-08\n",
      "Iter 34300, Loss: 7.52661e-07, Loss_res: 6.41632e-07, Loss_ic1: 3.92447e-08, Loss_ic2: 2.60894e-08, Loss_b1: 3.60778e-09, Loss_b2: 8.43149e-09, Loss_b3: 1.71028e-08, Loss_b4: 1.65530e-08\n",
      "Iter 34400, Loss: 7.52564e-07, Loss_res: 6.41544e-07, Loss_ic1: 3.92377e-08, Loss_ic2: 2.60866e-08, Loss_b1: 3.60728e-09, Loss_b2: 8.42922e-09, Loss_b3: 1.71054e-08, Loss_b4: 1.65533e-08\n",
      "Iter 34500, Loss: 7.52467e-07, Loss_res: 6.41457e-07, Loss_ic1: 3.92307e-08, Loss_ic2: 2.60837e-08, Loss_b1: 3.60678e-09, Loss_b2: 8.42696e-09, Loss_b3: 1.71079e-08, Loss_b4: 1.65537e-08\n",
      "Iter 34600, Loss: 7.52371e-07, Loss_res: 6.41371e-07, Loss_ic1: 3.92237e-08, Loss_ic2: 2.60808e-08, Loss_b1: 3.60627e-09, Loss_b2: 8.42471e-09, Loss_b3: 1.71104e-08, Loss_b4: 1.65540e-08\n",
      "Iter 34700, Loss: 7.52275e-07, Loss_res: 6.41285e-07, Loss_ic1: 3.92168e-08, Loss_ic2: 2.60779e-08, Loss_b1: 3.60577e-09, Loss_b2: 8.42249e-09, Loss_b3: 1.71128e-08, Loss_b4: 1.65543e-08\n",
      "Iter 34800, Loss: 7.52180e-07, Loss_res: 6.41200e-07, Loss_ic1: 3.92099e-08, Loss_ic2: 2.60750e-08, Loss_b1: 3.60526e-09, Loss_b2: 8.42028e-09, Loss_b3: 1.71151e-08, Loss_b4: 1.65545e-08\n",
      "Iter 34900, Loss: 7.52086e-07, Loss_res: 6.41116e-07, Loss_ic1: 3.92030e-08, Loss_ic2: 2.60721e-08, Loss_b1: 3.60475e-09, Loss_b2: 8.41809e-09, Loss_b3: 1.71174e-08, Loss_b4: 1.65548e-08\n",
      "Iter 35000, Loss: 7.51992e-07, Loss_res: 6.41032e-07, Loss_ic1: 3.91962e-08, Loss_ic2: 2.60692e-08, Loss_b1: 3.60424e-09, Loss_b2: 8.41592e-09, Loss_b3: 1.71196e-08, Loss_b4: 1.65550e-08\n",
      "Iter 35100, Loss: 7.51898e-07, Loss_res: 6.40948e-07, Loss_ic1: 3.91894e-08, Loss_ic2: 2.60662e-08, Loss_b1: 3.60373e-09, Loss_b2: 8.41377e-09, Loss_b3: 1.71218e-08, Loss_b4: 1.65552e-08\n",
      "Iter 35200, Loss: 7.51805e-07, Loss_res: 6.40865e-07, Loss_ic1: 3.91826e-08, Loss_ic2: 2.60633e-08, Loss_b1: 3.60321e-09, Loss_b2: 8.41163e-09, Loss_b3: 1.71239e-08, Loss_b4: 1.65554e-08\n",
      "Iter 35300, Loss: 7.51713e-07, Loss_res: 6.40783e-07, Loss_ic1: 3.91758e-08, Loss_ic2: 2.60603e-08, Loss_b1: 3.60270e-09, Loss_b2: 8.40951e-09, Loss_b3: 1.71260e-08, Loss_b4: 1.65556e-08\n",
      "Iter 35400, Loss: 7.51621e-07, Loss_res: 6.40701e-07, Loss_ic1: 3.91691e-08, Loss_ic2: 2.60573e-08, Loss_b1: 3.60218e-09, Loss_b2: 8.40741e-09, Loss_b3: 1.71280e-08, Loss_b4: 1.65558e-08\n",
      "Iter 35500, Loss: 7.51529e-07, Loss_res: 6.40620e-07, Loss_ic1: 3.91624e-08, Loss_ic2: 2.60544e-08, Loss_b1: 3.60166e-09, Loss_b2: 8.40533e-09, Loss_b3: 1.71300e-08, Loss_b4: 1.65559e-08\n",
      "Iter 35600, Loss: 7.51438e-07, Loss_res: 6.40539e-07, Loss_ic1: 3.91557e-08, Loss_ic2: 2.60514e-08, Loss_b1: 3.60115e-09, Loss_b2: 8.40326e-09, Loss_b3: 1.71319e-08, Loss_b4: 1.65561e-08\n",
      "Iter 35700, Loss: 7.51348e-07, Loss_res: 6.40459e-07, Loss_ic1: 3.91491e-08, Loss_ic2: 2.60484e-08, Loss_b1: 3.60063e-09, Loss_b2: 8.40122e-09, Loss_b3: 1.71338e-08, Loss_b4: 1.65562e-08\n",
      "Iter 35800, Loss: 7.51258e-07, Loss_res: 6.40379e-07, Loss_ic1: 3.91424e-08, Loss_ic2: 2.60453e-08, Loss_b1: 3.60011e-09, Loss_b2: 8.39919e-09, Loss_b3: 1.71356e-08, Loss_b4: 1.65563e-08\n",
      "Iter 35900, Loss: 7.51168e-07, Loss_res: 6.40300e-07, Loss_ic1: 3.91359e-08, Loss_ic2: 2.60423e-08, Loss_b1: 3.59959e-09, Loss_b2: 8.39718e-09, Loss_b3: 1.71373e-08, Loss_b4: 1.65564e-08\n",
      "Iter 36000, Loss: 7.51079e-07, Loss_res: 6.40221e-07, Loss_ic1: 3.91293e-08, Loss_ic2: 2.60393e-08, Loss_b1: 3.59907e-09, Loss_b2: 8.39518e-09, Loss_b3: 1.71391e-08, Loss_b4: 1.65565e-08\n",
      "Iter 36100, Loss: 7.50991e-07, Loss_res: 6.40143e-07, Loss_ic1: 3.91228e-08, Loss_ic2: 2.60362e-08, Loss_b1: 3.59855e-09, Loss_b2: 8.39321e-09, Loss_b3: 1.71407e-08, Loss_b4: 1.65565e-08\n",
      "Iter 36200, Loss: 7.50902e-07, Loss_res: 6.40065e-07, Loss_ic1: 3.91162e-08, Loss_ic2: 2.60332e-08, Loss_b1: 3.59804e-09, Loss_b2: 8.39125e-09, Loss_b3: 1.71424e-08, Loss_b4: 1.65566e-08\n",
      "Iter 36300, Loss: 7.50815e-07, Loss_res: 6.39987e-07, Loss_ic1: 3.91098e-08, Loss_ic2: 2.60301e-08, Loss_b1: 3.59752e-09, Loss_b2: 8.38931e-09, Loss_b3: 1.71439e-08, Loss_b4: 1.65566e-08\n",
      "Iter 36400, Loss: 7.50727e-07, Loss_res: 6.39910e-07, Loss_ic1: 3.91033e-08, Loss_ic2: 2.60271e-08, Loss_b1: 3.59700e-09, Loss_b2: 8.38739e-09, Loss_b3: 1.71455e-08, Loss_b4: 1.65566e-08\n",
      "Iter 36500, Loss: 7.50640e-07, Loss_res: 6.39834e-07, Loss_ic1: 3.90969e-08, Loss_ic2: 2.60240e-08, Loss_b1: 3.59648e-09, Loss_b2: 8.38548e-09, Loss_b3: 1.71470e-08, Loss_b4: 1.65566e-08\n",
      "Iter 36600, Loss: 7.50554e-07, Loss_res: 6.39758e-07, Loss_ic1: 3.90904e-08, Loss_ic2: 2.60209e-08, Loss_b1: 3.59597e-09, Loss_b2: 8.38359e-09, Loss_b3: 1.71484e-08, Loss_b4: 1.65566e-08\n",
      "Iter 36700, Loss: 7.50468e-07, Loss_res: 6.39682e-07, Loss_ic1: 3.90841e-08, Loss_ic2: 2.60178e-08, Loss_b1: 3.59545e-09, Loss_b2: 8.38172e-09, Loss_b3: 1.71499e-08, Loss_b4: 1.65566e-08\n",
      "Iter 36800, Loss: 7.50382e-07, Loss_res: 6.39607e-07, Loss_ic1: 3.90777e-08, Loss_ic2: 2.60147e-08, Loss_b1: 3.59493e-09, Loss_b2: 8.37987e-09, Loss_b3: 1.71512e-08, Loss_b4: 1.65566e-08\n",
      "Iter 36900, Loss: 7.50297e-07, Loss_res: 6.39532e-07, Loss_ic1: 3.90714e-08, Loss_ic2: 2.60116e-08, Loss_b1: 3.59442e-09, Loss_b2: 8.37803e-09, Loss_b3: 1.71526e-08, Loss_b4: 1.65566e-08\n",
      "Iter 37000, Loss: 7.50212e-07, Loss_res: 6.39458e-07, Loss_ic1: 3.90650e-08, Loss_ic2: 2.60085e-08, Loss_b1: 3.59391e-09, Loss_b2: 8.37621e-09, Loss_b3: 1.71539e-08, Loss_b4: 1.65565e-08\n",
      "Iter 37100, Loss: 7.50127e-07, Loss_res: 6.39384e-07, Loss_ic1: 3.90587e-08, Loss_ic2: 2.60054e-08, Loss_b1: 3.59339e-09, Loss_b2: 8.37441e-09, Loss_b3: 1.71552e-08, Loss_b4: 1.65564e-08\n",
      "Iter 37200, Loss: 7.50043e-07, Loss_res: 6.39310e-07, Loss_ic1: 3.90525e-08, Loss_ic2: 2.60022e-08, Loss_b1: 3.59288e-09, Loss_b2: 8.37262e-09, Loss_b3: 1.71564e-08, Loss_b4: 1.65564e-08\n",
      "Iter 37300, Loss: 7.49959e-07, Loss_res: 6.39237e-07, Loss_ic1: 3.90462e-08, Loss_ic2: 2.59991e-08, Loss_b1: 3.59237e-09, Loss_b2: 8.37085e-09, Loss_b3: 1.71576e-08, Loss_b4: 1.65563e-08\n",
      "Iter 37400, Loss: 7.49876e-07, Loss_res: 6.39164e-07, Loss_ic1: 3.90400e-08, Loss_ic2: 2.59959e-08, Loss_b1: 3.59186e-09, Loss_b2: 8.36909e-09, Loss_b3: 1.71587e-08, Loss_b4: 1.65562e-08\n",
      "Iter 37500, Loss: 7.49793e-07, Loss_res: 6.39092e-07, Loss_ic1: 3.90338e-08, Loss_ic2: 2.59928e-08, Loss_b1: 3.59136e-09, Loss_b2: 8.36735e-09, Loss_b3: 1.71599e-08, Loss_b4: 1.65561e-08\n",
      "Iter 37600, Loss: 7.49710e-07, Loss_res: 6.39020e-07, Loss_ic1: 3.90276e-08, Loss_ic2: 2.59896e-08, Loss_b1: 3.59085e-09, Loss_b2: 8.36563e-09, Loss_b3: 1.71610e-08, Loss_b4: 1.65560e-08\n",
      "Iter 37700, Loss: 7.49628e-07, Loss_res: 6.38948e-07, Loss_ic1: 3.90215e-08, Loss_ic2: 2.59865e-08, Loss_b1: 3.59034e-09, Loss_b2: 8.36392e-09, Loss_b3: 1.71620e-08, Loss_b4: 1.65559e-08\n",
      "Iter 37800, Loss: 7.49546e-07, Loss_res: 6.38877e-07, Loss_ic1: 3.90154e-08, Loss_ic2: 2.59833e-08, Loss_b1: 3.58984e-09, Loss_b2: 8.36223e-09, Loss_b3: 1.71630e-08, Loss_b4: 1.65557e-08\n",
      "Iter 37900, Loss: 7.49465e-07, Loss_res: 6.38806e-07, Loss_ic1: 3.90093e-08, Loss_ic2: 2.59801e-08, Loss_b1: 3.58934e-09, Loss_b2: 8.36055e-09, Loss_b3: 1.71640e-08, Loss_b4: 1.65556e-08\n",
      "Iter 38000, Loss: 7.49383e-07, Loss_res: 6.38735e-07, Loss_ic1: 3.90032e-08, Loss_ic2: 2.59770e-08, Loss_b1: 3.58884e-09, Loss_b2: 8.35889e-09, Loss_b3: 1.71650e-08, Loss_b4: 1.65555e-08\n",
      "Iter 38100, Loss: 7.49303e-07, Loss_res: 6.38665e-07, Loss_ic1: 3.89971e-08, Loss_ic2: 2.59738e-08, Loss_b1: 3.58834e-09, Loss_b2: 8.35724e-09, Loss_b3: 1.71659e-08, Loss_b4: 1.65553e-08\n",
      "Iter 38200, Loss: 7.49222e-07, Loss_res: 6.38595e-07, Loss_ic1: 3.89911e-08, Loss_ic2: 2.59706e-08, Loss_b1: 3.58784e-09, Loss_b2: 8.35560e-09, Loss_b3: 1.71668e-08, Loss_b4: 1.65551e-08\n",
      "Iter 38300, Loss: 7.49142e-07, Loss_res: 6.38526e-07, Loss_ic1: 3.89851e-08, Loss_ic2: 2.59674e-08, Loss_b1: 3.58735e-09, Loss_b2: 8.35399e-09, Loss_b3: 1.71677e-08, Loss_b4: 1.65550e-08\n",
      "Iter 38400, Loss: 7.49062e-07, Loss_res: 6.38456e-07, Loss_ic1: 3.89791e-08, Loss_ic2: 2.59642e-08, Loss_b1: 3.58686e-09, Loss_b2: 8.35238e-09, Loss_b3: 1.71685e-08, Loss_b4: 1.65548e-08\n",
      "Iter 38500, Loss: 7.48983e-07, Loss_res: 6.38388e-07, Loss_ic1: 3.89731e-08, Loss_ic2: 2.59610e-08, Loss_b1: 3.58637e-09, Loss_b2: 8.35079e-09, Loss_b3: 1.71694e-08, Loss_b4: 1.65546e-08\n",
      "Iter 38600, Loss: 7.48904e-07, Loss_res: 6.38319e-07, Loss_ic1: 3.89671e-08, Loss_ic2: 2.59578e-08, Loss_b1: 3.58588e-09, Loss_b2: 8.34921e-09, Loss_b3: 1.71702e-08, Loss_b4: 1.65544e-08\n",
      "Iter 38700, Loss: 7.48825e-07, Loss_res: 6.38251e-07, Loss_ic1: 3.89612e-08, Loss_ic2: 2.59546e-08, Loss_b1: 3.58539e-09, Loss_b2: 8.34765e-09, Loss_b3: 1.71709e-08, Loss_b4: 1.65542e-08\n",
      "Iter 38800, Loss: 7.48746e-07, Loss_res: 6.38183e-07, Loss_ic1: 3.89553e-08, Loss_ic2: 2.59514e-08, Loss_b1: 3.58490e-09, Loss_b2: 8.34610e-09, Loss_b3: 1.71717e-08, Loss_b4: 1.65540e-08\n",
      "Iter 38900, Loss: 7.48668e-07, Loss_res: 6.38115e-07, Loss_ic1: 3.89494e-08, Loss_ic2: 2.59482e-08, Loss_b1: 3.58442e-09, Loss_b2: 8.34457e-09, Loss_b3: 1.71724e-08, Loss_b4: 1.65537e-08\n",
      "Iter 39000, Loss: 7.48590e-07, Loss_res: 6.38048e-07, Loss_ic1: 3.89435e-08, Loss_ic2: 2.59450e-08, Loss_b1: 3.58394e-09, Loss_b2: 8.34304e-09, Loss_b3: 1.71730e-08, Loss_b4: 1.65535e-08\n",
      "Iter 39100, Loss: 7.48513e-07, Loss_res: 6.37981e-07, Loss_ic1: 3.89377e-08, Loss_ic2: 2.59417e-08, Loss_b1: 3.58346e-09, Loss_b2: 8.34154e-09, Loss_b3: 1.71737e-08, Loss_b4: 1.65533e-08\n",
      "Iter 39200, Loss: 7.48435e-07, Loss_res: 6.37915e-07, Loss_ic1: 3.89318e-08, Loss_ic2: 2.59385e-08, Loss_b1: 3.58299e-09, Loss_b2: 8.34004e-09, Loss_b3: 1.71743e-08, Loss_b4: 1.65530e-08\n",
      "Iter 39300, Loss: 7.48358e-07, Loss_res: 6.37848e-07, Loss_ic1: 3.89260e-08, Loss_ic2: 2.59353e-08, Loss_b1: 3.58251e-09, Loss_b2: 8.33856e-09, Loss_b3: 1.71750e-08, Loss_b4: 1.65528e-08\n",
      "Iter 39400, Loss: 7.48282e-07, Loss_res: 6.37782e-07, Loss_ic1: 3.89202e-08, Loss_ic2: 2.59321e-08, Loss_b1: 3.58204e-09, Loss_b2: 8.33709e-09, Loss_b3: 1.71755e-08, Loss_b4: 1.65525e-08\n",
      "Iter 39500, Loss: 7.48206e-07, Loss_res: 6.37717e-07, Loss_ic1: 3.89145e-08, Loss_ic2: 2.59288e-08, Loss_b1: 3.58157e-09, Loss_b2: 8.33563e-09, Loss_b3: 1.71761e-08, Loss_b4: 1.65523e-08\n",
      "Iter 39600, Loss: 7.48129e-07, Loss_res: 6.37651e-07, Loss_ic1: 3.89087e-08, Loss_ic2: 2.59256e-08, Loss_b1: 3.58110e-09, Loss_b2: 8.33418e-09, Loss_b3: 1.71766e-08, Loss_b4: 1.65520e-08\n",
      "Iter 39700, Loss: 7.48054e-07, Loss_res: 6.37586e-07, Loss_ic1: 3.89030e-08, Loss_ic2: 2.59224e-08, Loss_b1: 3.58064e-09, Loss_b2: 8.33275e-09, Loss_b3: 1.71772e-08, Loss_b4: 1.65517e-08\n",
      "Iter 39800, Loss: 7.47978e-07, Loss_res: 6.37521e-07, Loss_ic1: 3.88973e-08, Loss_ic2: 2.59192e-08, Loss_b1: 3.58017e-09, Loss_b2: 8.33133e-09, Loss_b3: 1.71777e-08, Loss_b4: 1.65515e-08\n",
      "Iter 39900, Loss: 7.47903e-07, Loss_res: 6.37457e-07, Loss_ic1: 3.88916e-08, Loss_ic2: 2.59159e-08, Loss_b1: 3.57971e-09, Loss_b2: 8.32992e-09, Loss_b3: 1.71781e-08, Loss_b4: 1.65512e-08\n",
      "Iter 40000, Loss: 7.47828e-07, Loss_res: 6.37392e-07, Loss_ic1: 3.88859e-08, Loss_ic2: 2.59127e-08, Loss_b1: 3.57925e-09, Loss_b2: 8.32852e-09, Loss_b3: 1.71786e-08, Loss_b4: 1.65509e-08\n",
      "Iter 40100, Loss: 7.47754e-07, Loss_res: 6.37328e-07, Loss_ic1: 3.88802e-08, Loss_ic2: 2.59095e-08, Loss_b1: 3.57880e-09, Loss_b2: 8.32713e-09, Loss_b3: 1.71790e-08, Loss_b4: 1.65506e-08\n",
      "Iter 40200, Loss: 7.47679e-07, Loss_res: 6.37265e-07, Loss_ic1: 3.88746e-08, Loss_ic2: 2.59062e-08, Loss_b1: 3.57834e-09, Loss_b2: 8.32576e-09, Loss_b3: 1.71795e-08, Loss_b4: 1.65503e-08\n",
      "Iter 40300, Loss: 7.47605e-07, Loss_res: 6.37201e-07, Loss_ic1: 3.88690e-08, Loss_ic2: 2.59030e-08, Loss_b1: 3.57789e-09, Loss_b2: 8.32439e-09, Loss_b3: 1.71799e-08, Loss_b4: 1.65500e-08\n",
      "Iter 40400, Loss: 7.47532e-07, Loss_res: 6.37138e-07, Loss_ic1: 3.88634e-08, Loss_ic2: 2.58998e-08, Loss_b1: 3.57744e-09, Loss_b2: 8.32304e-09, Loss_b3: 1.71802e-08, Loss_b4: 1.65497e-08\n",
      "Iter 40500, Loss: 7.47458e-07, Loss_res: 6.37075e-07, Loss_ic1: 3.88578e-08, Loss_ic2: 2.58965e-08, Loss_b1: 3.57700e-09, Loss_b2: 8.32170e-09, Loss_b3: 1.71806e-08, Loss_b4: 1.65493e-08\n",
      "Iter 40600, Loss: 7.47385e-07, Loss_res: 6.37012e-07, Loss_ic1: 3.88523e-08, Loss_ic2: 2.58933e-08, Loss_b1: 3.57655e-09, Loss_b2: 8.32036e-09, Loss_b3: 1.71809e-08, Loss_b4: 1.65490e-08\n",
      "Iter 40700, Loss: 7.47312e-07, Loss_res: 6.36950e-07, Loss_ic1: 3.88467e-08, Loss_ic2: 2.58901e-08, Loss_b1: 3.57611e-09, Loss_b2: 8.31904e-09, Loss_b3: 1.71813e-08, Loss_b4: 1.65487e-08\n",
      "Iter 40800, Loss: 7.47239e-07, Loss_res: 6.36888e-07, Loss_ic1: 3.88412e-08, Loss_ic2: 2.58868e-08, Loss_b1: 3.57567e-09, Loss_b2: 8.31773e-09, Loss_b3: 1.71816e-08, Loss_b4: 1.65483e-08\n",
      "Iter 40900, Loss: 7.47167e-07, Loss_res: 6.36826e-07, Loss_ic1: 3.88357e-08, Loss_ic2: 2.58836e-08, Loss_b1: 3.57523e-09, Loss_b2: 8.31643e-09, Loss_b3: 1.71819e-08, Loss_b4: 1.65480e-08\n",
      "Iter 41000, Loss: 7.47095e-07, Loss_res: 6.36764e-07, Loss_ic1: 3.88302e-08, Loss_ic2: 2.58804e-08, Loss_b1: 3.57480e-09, Loss_b2: 8.31514e-09, Loss_b3: 1.71821e-08, Loss_b4: 1.65477e-08\n",
      "Iter 41100, Loss: 7.47023e-07, Loss_res: 6.36703e-07, Loss_ic1: 3.88247e-08, Loss_ic2: 2.58771e-08, Loss_b1: 3.57437e-09, Loss_b2: 8.31386e-09, Loss_b3: 1.71824e-08, Loss_b4: 1.65473e-08\n",
      "Iter 41200, Loss: 7.46951e-07, Loss_res: 6.36642e-07, Loss_ic1: 3.88193e-08, Loss_ic2: 2.58739e-08, Loss_b1: 3.57394e-09, Loss_b2: 8.31259e-09, Loss_b3: 1.71826e-08, Loss_b4: 1.65470e-08\n",
      "Iter 41300, Loss: 7.46880e-07, Loss_res: 6.36581e-07, Loss_ic1: 3.88139e-08, Loss_ic2: 2.58707e-08, Loss_b1: 3.57351e-09, Loss_b2: 8.31133e-09, Loss_b3: 1.71828e-08, Loss_b4: 1.65466e-08\n",
      "Iter 41400, Loss: 7.46808e-07, Loss_res: 6.36520e-07, Loss_ic1: 3.88084e-08, Loss_ic2: 2.58674e-08, Loss_b1: 3.57309e-09, Loss_b2: 8.31008e-09, Loss_b3: 1.71830e-08, Loss_b4: 1.65462e-08\n",
      "Iter 41500, Loss: 7.46738e-07, Loss_res: 6.36460e-07, Loss_ic1: 3.88031e-08, Loss_ic2: 2.58642e-08, Loss_b1: 3.57267e-09, Loss_b2: 8.30884e-09, Loss_b3: 1.71832e-08, Loss_b4: 1.65459e-08\n",
      "Iter 41600, Loss: 7.46667e-07, Loss_res: 6.36399e-07, Loss_ic1: 3.87977e-08, Loss_ic2: 2.58610e-08, Loss_b1: 3.57225e-09, Loss_b2: 8.30761e-09, Loss_b3: 1.71834e-08, Loss_b4: 1.65455e-08\n",
      "Iter 41700, Loss: 7.46596e-07, Loss_res: 6.36339e-07, Loss_ic1: 3.87923e-08, Loss_ic2: 2.58578e-08, Loss_b1: 3.57183e-09, Loss_b2: 8.30638e-09, Loss_b3: 1.71836e-08, Loss_b4: 1.65451e-08\n",
      "Iter 41800, Loss: 7.46526e-07, Loss_res: 6.36280e-07, Loss_ic1: 3.87870e-08, Loss_ic2: 2.58546e-08, Loss_b1: 3.57142e-09, Loss_b2: 8.30517e-09, Loss_b3: 1.71837e-08, Loss_b4: 1.65448e-08\n",
      "Iter 41900, Loss: 7.46456e-07, Loss_res: 6.36220e-07, Loss_ic1: 3.87816e-08, Loss_ic2: 2.58513e-08, Loss_b1: 3.57101e-09, Loss_b2: 8.30396e-09, Loss_b3: 1.71839e-08, Loss_b4: 1.65444e-08\n",
      "Iter 42000, Loss: 7.46387e-07, Loss_res: 6.36161e-07, Loss_ic1: 3.87763e-08, Loss_ic2: 2.58481e-08, Loss_b1: 3.57060e-09, Loss_b2: 8.30277e-09, Loss_b3: 1.71840e-08, Loss_b4: 1.65440e-08\n",
      "Iter 42100, Loss: 7.46317e-07, Loss_res: 6.36102e-07, Loss_ic1: 3.87710e-08, Loss_ic2: 2.58449e-08, Loss_b1: 3.57019e-09, Loss_b2: 8.30158e-09, Loss_b3: 1.71841e-08, Loss_b4: 1.65436e-08\n",
      "Iter 42200, Loss: 7.46248e-07, Loss_res: 6.36043e-07, Loss_ic1: 3.87658e-08, Loss_ic2: 2.58417e-08, Loss_b1: 3.56979e-09, Loss_b2: 8.30040e-09, Loss_b3: 1.71842e-08, Loss_b4: 1.65432e-08\n",
      "Iter 42300, Loss: 7.46179e-07, Loss_res: 6.35984e-07, Loss_ic1: 3.87605e-08, Loss_ic2: 2.58385e-08, Loss_b1: 3.56939e-09, Loss_b2: 8.29923e-09, Loss_b3: 1.71843e-08, Loss_b4: 1.65428e-08\n",
      "Iter 42400, Loss: 7.46110e-07, Loss_res: 6.35926e-07, Loss_ic1: 3.87553e-08, Loss_ic2: 2.58353e-08, Loss_b1: 3.56899e-09, Loss_b2: 8.29807e-09, Loss_b3: 1.71843e-08, Loss_b4: 1.65424e-08\n",
      "Iter 42500, Loss: 7.46042e-07, Loss_res: 6.35868e-07, Loss_ic1: 3.87500e-08, Loss_ic2: 2.58321e-08, Loss_b1: 3.56859e-09, Loss_b2: 8.29691e-09, Loss_b3: 1.71844e-08, Loss_b4: 1.65420e-08\n",
      "Iter 42600, Loss: 7.45973e-07, Loss_res: 6.35810e-07, Loss_ic1: 3.87448e-08, Loss_ic2: 2.58289e-08, Loss_b1: 3.56820e-09, Loss_b2: 8.29577e-09, Loss_b3: 1.71844e-08, Loss_b4: 1.65416e-08\n",
      "Iter 42700, Loss: 7.45905e-07, Loss_res: 6.35752e-07, Loss_ic1: 3.87396e-08, Loss_ic2: 2.58257e-08, Loss_b1: 3.56780e-09, Loss_b2: 8.29463e-09, Loss_b3: 1.71845e-08, Loss_b4: 1.65412e-08\n",
      "Iter 42800, Loss: 7.45837e-07, Loss_res: 6.35694e-07, Loss_ic1: 3.87345e-08, Loss_ic2: 2.58225e-08, Loss_b1: 3.56742e-09, Loss_b2: 8.29350e-09, Loss_b3: 1.71845e-08, Loss_b4: 1.65408e-08\n",
      "Iter 42900, Loss: 7.45770e-07, Loss_res: 6.35637e-07, Loss_ic1: 3.87293e-08, Loss_ic2: 2.58193e-08, Loss_b1: 3.56703e-09, Loss_b2: 8.29238e-09, Loss_b3: 1.71845e-08, Loss_b4: 1.65403e-08\n",
      "Iter 43000, Loss: 7.45702e-07, Loss_res: 6.35580e-07, Loss_ic1: 3.87241e-08, Loss_ic2: 2.58161e-08, Loss_b1: 3.56665e-09, Loss_b2: 8.29126e-09, Loss_b3: 1.71845e-08, Loss_b4: 1.65399e-08\n",
      "Iter 43100, Loss: 7.45635e-07, Loss_res: 6.35523e-07, Loss_ic1: 3.87190e-08, Loss_ic2: 2.58129e-08, Loss_b1: 3.56626e-09, Loss_b2: 8.29016e-09, Loss_b3: 1.71845e-08, Loss_b4: 1.65395e-08\n",
      "Iter 43200, Loss: 7.45568e-07, Loss_res: 6.35466e-07, Loss_ic1: 3.87139e-08, Loss_ic2: 2.58097e-08, Loss_b1: 3.56589e-09, Loss_b2: 8.28906e-09, Loss_b3: 1.71845e-08, Loss_b4: 1.65391e-08\n",
      "Iter 43300, Loss: 7.45501e-07, Loss_res: 6.35410e-07, Loss_ic1: 3.87088e-08, Loss_ic2: 2.58065e-08, Loss_b1: 3.56551e-09, Loss_b2: 8.28797e-09, Loss_b3: 1.71845e-08, Loss_b4: 1.65386e-08\n",
      "Iter 43400, Loss: 7.45435e-07, Loss_res: 6.35353e-07, Loss_ic1: 3.87037e-08, Loss_ic2: 2.58033e-08, Loss_b1: 3.56514e-09, Loss_b2: 8.28688e-09, Loss_b3: 1.71844e-08, Loss_b4: 1.65382e-08\n",
      "Iter 43500, Loss: 7.45369e-07, Loss_res: 6.35297e-07, Loss_ic1: 3.86987e-08, Loss_ic2: 2.58002e-08, Loss_b1: 3.56476e-09, Loss_b2: 8.28580e-09, Loss_b3: 1.71844e-08, Loss_b4: 1.65378e-08\n",
      "Iter 43600, Loss: 7.45302e-07, Loss_res: 6.35241e-07, Loss_ic1: 3.86936e-08, Loss_ic2: 2.57970e-08, Loss_b1: 3.56440e-09, Loss_b2: 8.28473e-09, Loss_b3: 1.71843e-08, Loss_b4: 1.65373e-08\n",
      "Iter 43700, Loss: 7.45236e-07, Loss_res: 6.35185e-07, Loss_ic1: 3.86886e-08, Loss_ic2: 2.57938e-08, Loss_b1: 3.56403e-09, Loss_b2: 8.28367e-09, Loss_b3: 1.71842e-08, Loss_b4: 1.65369e-08\n",
      "Iter 43800, Loss: 7.45171e-07, Loss_res: 6.35130e-07, Loss_ic1: 3.86836e-08, Loss_ic2: 2.57907e-08, Loss_b1: 3.56367e-09, Loss_b2: 8.28261e-09, Loss_b3: 1.71842e-08, Loss_b4: 1.65364e-08\n",
      "Iter 43900, Loss: 7.45105e-07, Loss_res: 6.35074e-07, Loss_ic1: 3.86785e-08, Loss_ic2: 2.57875e-08, Loss_b1: 3.56330e-09, Loss_b2: 8.28156e-09, Loss_b3: 1.71841e-08, Loss_b4: 1.65360e-08\n",
      "Iter 44000, Loss: 7.45040e-07, Loss_res: 6.35019e-07, Loss_ic1: 3.86736e-08, Loss_ic2: 2.57843e-08, Loss_b1: 3.56294e-09, Loss_b2: 8.28052e-09, Loss_b3: 1.71840e-08, Loss_b4: 1.65355e-08\n",
      "Iter 44100, Loss: 7.44975e-07, Loss_res: 6.34964e-07, Loss_ic1: 3.86686e-08, Loss_ic2: 2.57812e-08, Loss_b1: 3.56259e-09, Loss_b2: 8.27948e-09, Loss_b3: 1.71839e-08, Loss_b4: 1.65351e-08\n",
      "Iter 44200, Loss: 7.44910e-07, Loss_res: 6.34909e-07, Loss_ic1: 3.86636e-08, Loss_ic2: 2.57780e-08, Loss_b1: 3.56223e-09, Loss_b2: 8.27845e-09, Loss_b3: 1.71837e-08, Loss_b4: 1.65346e-08\n",
      "Iter 44300, Loss: 7.44845e-07, Loss_res: 6.34854e-07, Loss_ic1: 3.86587e-08, Loss_ic2: 2.57749e-08, Loss_b1: 3.56188e-09, Loss_b2: 8.27743e-09, Loss_b3: 1.71836e-08, Loss_b4: 1.65342e-08\n",
      "Iter 44400, Loss: 7.44781e-07, Loss_res: 6.34800e-07, Loss_ic1: 3.86537e-08, Loss_ic2: 2.57718e-08, Loss_b1: 3.56153e-09, Loss_b2: 8.27641e-09, Loss_b3: 1.71835e-08, Loss_b4: 1.65337e-08\n",
      "Iter 44500, Loss: 7.44716e-07, Loss_res: 6.34746e-07, Loss_ic1: 3.86488e-08, Loss_ic2: 2.57686e-08, Loss_b1: 3.56119e-09, Loss_b2: 8.27540e-09, Loss_b3: 1.71834e-08, Loss_b4: 1.65333e-08\n",
      "Iter 44600, Loss: 7.44652e-07, Loss_res: 6.34691e-07, Loss_ic1: 3.86439e-08, Loss_ic2: 2.57655e-08, Loss_b1: 3.56084e-09, Loss_b2: 8.27440e-09, Loss_b3: 1.71832e-08, Loss_b4: 1.65328e-08\n",
      "Iter 44700, Loss: 7.44588e-07, Loss_res: 6.34637e-07, Loss_ic1: 3.86390e-08, Loss_ic2: 2.57624e-08, Loss_b1: 3.56050e-09, Loss_b2: 8.27340e-09, Loss_b3: 1.71831e-08, Loss_b4: 1.65323e-08\n",
      "Iter 44800, Loss: 7.44524e-07, Loss_res: 6.34584e-07, Loss_ic1: 3.86342e-08, Loss_ic2: 2.57592e-08, Loss_b1: 3.56016e-09, Loss_b2: 8.27240e-09, Loss_b3: 1.71829e-08, Loss_b4: 1.65319e-08\n",
      "Iter 44900, Loss: 7.44461e-07, Loss_res: 6.34530e-07, Loss_ic1: 3.86293e-08, Loss_ic2: 2.57561e-08, Loss_b1: 3.55982e-09, Loss_b2: 8.27142e-09, Loss_b3: 1.71827e-08, Loss_b4: 1.65314e-08\n",
      "Iter 45000, Loss: 7.44397e-07, Loss_res: 6.34477e-07, Loss_ic1: 3.86245e-08, Loss_ic2: 2.57530e-08, Loss_b1: 3.55949e-09, Loss_b2: 8.27044e-09, Loss_b3: 1.71826e-08, Loss_b4: 1.65309e-08\n",
      "Iter 45100, Loss: 7.44334e-07, Loss_res: 6.34423e-07, Loss_ic1: 3.86196e-08, Loss_ic2: 2.57499e-08, Loss_b1: 3.55916e-09, Loss_b2: 8.26946e-09, Loss_b3: 1.71824e-08, Loss_b4: 1.65304e-08\n",
      "Iter 45200, Loss: 7.44271e-07, Loss_res: 6.34370e-07, Loss_ic1: 3.86148e-08, Loss_ic2: 2.57468e-08, Loss_b1: 3.55883e-09, Loss_b2: 8.26849e-09, Loss_b3: 1.71822e-08, Loss_b4: 1.65300e-08\n",
      "Iter 45300, Loss: 7.44208e-07, Loss_res: 6.34317e-07, Loss_ic1: 3.86100e-08, Loss_ic2: 2.57437e-08, Loss_b1: 3.55850e-09, Loss_b2: 8.26753e-09, Loss_b3: 1.71820e-08, Loss_b4: 1.65295e-08\n",
      "Iter 45400, Loss: 7.44146e-07, Loss_res: 6.34264e-07, Loss_ic1: 3.86052e-08, Loss_ic2: 2.57406e-08, Loss_b1: 3.55817e-09, Loss_b2: 8.26657e-09, Loss_b3: 1.71818e-08, Loss_b4: 1.65290e-08\n",
      "Iter 45500, Loss: 7.44083e-07, Loss_res: 6.34212e-07, Loss_ic1: 3.86005e-08, Loss_ic2: 2.57375e-08, Loss_b1: 3.55785e-09, Loss_b2: 8.26562e-09, Loss_b3: 1.71816e-08, Loss_b4: 1.65285e-08\n",
      "Iter 45600, Loss: 7.44021e-07, Loss_res: 6.34159e-07, Loss_ic1: 3.85957e-08, Loss_ic2: 2.57344e-08, Loss_b1: 3.55753e-09, Loss_b2: 8.26467e-09, Loss_b3: 1.71814e-08, Loss_b4: 1.65280e-08\n",
      "Iter 45700, Loss: 7.43959e-07, Loss_res: 6.34107e-07, Loss_ic1: 3.85910e-08, Loss_ic2: 2.57313e-08, Loss_b1: 3.55721e-09, Loss_b2: 8.26373e-09, Loss_b3: 1.71812e-08, Loss_b4: 1.65275e-08\n",
      "Iter 45800, Loss: 7.43897e-07, Loss_res: 6.34055e-07, Loss_ic1: 3.85862e-08, Loss_ic2: 2.57282e-08, Loss_b1: 3.55689e-09, Loss_b2: 8.26279e-09, Loss_b3: 1.71809e-08, Loss_b4: 1.65271e-08\n",
      "Iter 45900, Loss: 7.43835e-07, Loss_res: 6.34003e-07, Loss_ic1: 3.85815e-08, Loss_ic2: 2.57252e-08, Loss_b1: 3.55658e-09, Loss_b2: 8.26186e-09, Loss_b3: 1.71807e-08, Loss_b4: 1.65266e-08\n",
      "Iter 46000, Loss: 7.43774e-07, Loss_res: 6.33951e-07, Loss_ic1: 3.85768e-08, Loss_ic2: 2.57221e-08, Loss_b1: 3.55627e-09, Loss_b2: 8.26093e-09, Loss_b3: 1.71805e-08, Loss_b4: 1.65261e-08\n",
      "Iter 46100, Loss: 7.43712e-07, Loss_res: 6.33899e-07, Loss_ic1: 3.85721e-08, Loss_ic2: 2.57190e-08, Loss_b1: 3.55596e-09, Loss_b2: 8.26001e-09, Loss_b3: 1.71802e-08, Loss_b4: 1.65256e-08\n",
      "Iter 46200, Loss: 7.43651e-07, Loss_res: 6.33848e-07, Loss_ic1: 3.85674e-08, Loss_ic2: 2.57160e-08, Loss_b1: 3.55565e-09, Loss_b2: 8.25909e-09, Loss_b3: 1.71800e-08, Loss_b4: 1.65251e-08\n",
      "Iter 46300, Loss: 7.43590e-07, Loss_res: 6.33797e-07, Loss_ic1: 3.85628e-08, Loss_ic2: 2.57129e-08, Loss_b1: 3.55535e-09, Loss_b2: 8.25818e-09, Loss_b3: 1.71797e-08, Loss_b4: 1.65246e-08\n",
      "Iter 46400, Loss: 7.43529e-07, Loss_res: 6.33745e-07, Loss_ic1: 3.85581e-08, Loss_ic2: 2.57099e-08, Loss_b1: 3.55504e-09, Loss_b2: 8.25727e-09, Loss_b3: 1.71795e-08, Loss_b4: 1.65241e-08\n",
      "Iter 46500, Loss: 7.43469e-07, Loss_res: 6.33694e-07, Loss_ic1: 3.85535e-08, Loss_ic2: 2.57068e-08, Loss_b1: 3.55474e-09, Loss_b2: 8.25637e-09, Loss_b3: 1.71792e-08, Loss_b4: 1.65236e-08\n",
      "Iter 46600, Loss: 7.43408e-07, Loss_res: 6.33643e-07, Loss_ic1: 3.85488e-08, Loss_ic2: 2.57038e-08, Loss_b1: 3.55444e-09, Loss_b2: 8.25548e-09, Loss_b3: 1.71790e-08, Loss_b4: 1.65231e-08\n",
      "Iter 46700, Loss: 7.43348e-07, Loss_res: 6.33593e-07, Loss_ic1: 3.85442e-08, Loss_ic2: 2.57007e-08, Loss_b1: 3.55415e-09, Loss_b2: 8.25458e-09, Loss_b3: 1.71787e-08, Loss_b4: 1.65226e-08\n",
      "Iter 46800, Loss: 7.43287e-07, Loss_res: 6.33542e-07, Loss_ic1: 3.85396e-08, Loss_ic2: 2.56977e-08, Loss_b1: 3.55385e-09, Loss_b2: 8.25369e-09, Loss_b3: 1.71784e-08, Loss_b4: 1.65221e-08\n",
      "Iter 46900, Loss: 7.43227e-07, Loss_res: 6.33492e-07, Loss_ic1: 3.85350e-08, Loss_ic2: 2.56947e-08, Loss_b1: 3.55356e-09, Loss_b2: 8.25281e-09, Loss_b3: 1.71782e-08, Loss_b4: 1.65216e-08\n",
      "Iter 47000, Loss: 7.43167e-07, Loss_res: 6.33441e-07, Loss_ic1: 3.85305e-08, Loss_ic2: 2.56917e-08, Loss_b1: 3.55327e-09, Loss_b2: 8.25193e-09, Loss_b3: 1.71779e-08, Loss_b4: 1.65211e-08\n",
      "Iter 47100, Loss: 7.43108e-07, Loss_res: 6.33391e-07, Loss_ic1: 3.85259e-08, Loss_ic2: 2.56886e-08, Loss_b1: 3.55299e-09, Loss_b2: 8.25106e-09, Loss_b3: 1.71776e-08, Loss_b4: 1.65206e-08\n",
      "Iter 47200, Loss: 7.43048e-07, Loss_res: 6.33341e-07, Loss_ic1: 3.85213e-08, Loss_ic2: 2.56856e-08, Loss_b1: 3.55270e-09, Loss_b2: 8.25019e-09, Loss_b3: 1.71773e-08, Loss_b4: 1.65200e-08\n",
      "Iter 47300, Loss: 7.42989e-07, Loss_res: 6.33291e-07, Loss_ic1: 3.85168e-08, Loss_ic2: 2.56826e-08, Loss_b1: 3.55242e-09, Loss_b2: 8.24932e-09, Loss_b3: 1.71770e-08, Loss_b4: 1.65195e-08\n",
      "Iter 47400, Loss: 7.42930e-07, Loss_res: 6.33241e-07, Loss_ic1: 3.85123e-08, Loss_ic2: 2.56796e-08, Loss_b1: 3.55214e-09, Loss_b2: 8.24846e-09, Loss_b3: 1.71767e-08, Loss_b4: 1.65190e-08\n",
      "Iter 47500, Loss: 7.42871e-07, Loss_res: 6.33192e-07, Loss_ic1: 3.85078e-08, Loss_ic2: 2.56766e-08, Loss_b1: 3.55186e-09, Loss_b2: 8.24760e-09, Loss_b3: 1.71764e-08, Loss_b4: 1.65185e-08\n",
      "Iter 47600, Loss: 7.42812e-07, Loss_res: 6.33142e-07, Loss_ic1: 3.85033e-08, Loss_ic2: 2.56736e-08, Loss_b1: 3.55158e-09, Loss_b2: 8.24675e-09, Loss_b3: 1.71761e-08, Loss_b4: 1.65180e-08\n",
      "Iter 47700, Loss: 7.42753e-07, Loss_res: 6.33093e-07, Loss_ic1: 3.84988e-08, Loss_ic2: 2.56707e-08, Loss_b1: 3.55131e-09, Loss_b2: 8.24590e-09, Loss_b3: 1.71758e-08, Loss_b4: 1.65175e-08\n",
      "Iter 47800, Loss: 7.42694e-07, Loss_res: 6.33044e-07, Loss_ic1: 3.84943e-08, Loss_ic2: 2.56677e-08, Loss_b1: 3.55103e-09, Loss_b2: 8.24506e-09, Loss_b3: 1.71755e-08, Loss_b4: 1.65170e-08\n",
      "Iter 47900, Loss: 7.42636e-07, Loss_res: 6.32995e-07, Loss_ic1: 3.84898e-08, Loss_ic2: 2.56647e-08, Loss_b1: 3.55076e-09, Loss_b2: 8.24422e-09, Loss_b3: 1.71752e-08, Loss_b4: 1.65164e-08\n",
      "Iter 48000, Loss: 7.42578e-07, Loss_res: 6.32946e-07, Loss_ic1: 3.84854e-08, Loss_ic2: 2.56617e-08, Loss_b1: 3.55049e-09, Loss_b2: 8.24338e-09, Loss_b3: 1.71749e-08, Loss_b4: 1.65159e-08\n",
      "Iter 48100, Loss: 7.42519e-07, Loss_res: 6.32897e-07, Loss_ic1: 3.84809e-08, Loss_ic2: 2.56588e-08, Loss_b1: 3.55023e-09, Loss_b2: 8.24255e-09, Loss_b3: 1.71746e-08, Loss_b4: 1.65154e-08\n",
      "Iter 48200, Loss: 7.42461e-07, Loss_res: 6.32848e-07, Loss_ic1: 3.84765e-08, Loss_ic2: 2.56558e-08, Loss_b1: 3.54996e-09, Loss_b2: 8.24172e-09, Loss_b3: 1.71742e-08, Loss_b4: 1.65149e-08\n",
      "Iter 48300, Loss: 7.42404e-07, Loss_res: 6.32800e-07, Loss_ic1: 3.84721e-08, Loss_ic2: 2.56529e-08, Loss_b1: 3.54970e-09, Loss_b2: 8.24089e-09, Loss_b3: 1.71739e-08, Loss_b4: 1.65143e-08\n",
      "Iter 48400, Loss: 7.42346e-07, Loss_res: 6.32751e-07, Loss_ic1: 3.84677e-08, Loss_ic2: 2.56499e-08, Loss_b1: 3.54944e-09, Loss_b2: 8.24007e-09, Loss_b3: 1.71736e-08, Loss_b4: 1.65138e-08\n",
      "Iter 48500, Loss: 7.42288e-07, Loss_res: 6.32703e-07, Loss_ic1: 3.84633e-08, Loss_ic2: 2.56470e-08, Loss_b1: 3.54918e-09, Loss_b2: 8.23925e-09, Loss_b3: 1.71733e-08, Loss_b4: 1.65133e-08\n",
      "Iter 48600, Loss: 7.42231e-07, Loss_res: 6.32655e-07, Loss_ic1: 3.84589e-08, Loss_ic2: 2.56440e-08, Loss_b1: 3.54893e-09, Loss_b2: 8.23844e-09, Loss_b3: 1.71729e-08, Loss_b4: 1.65128e-08\n",
      "Iter 48700, Loss: 7.42174e-07, Loss_res: 6.32607e-07, Loss_ic1: 3.84545e-08, Loss_ic2: 2.56411e-08, Loss_b1: 3.54867e-09, Loss_b2: 8.23763e-09, Loss_b3: 1.71726e-08, Loss_b4: 1.65122e-08\n",
      "Iter 48800, Loss: 7.42117e-07, Loss_res: 6.32559e-07, Loss_ic1: 3.84502e-08, Loss_ic2: 2.56382e-08, Loss_b1: 3.54842e-09, Loss_b2: 8.23682e-09, Loss_b3: 1.71723e-08, Loss_b4: 1.65117e-08\n",
      "Iter 48900, Loss: 7.42060e-07, Loss_res: 6.32511e-07, Loss_ic1: 3.84458e-08, Loss_ic2: 2.56353e-08, Loss_b1: 3.54817e-09, Loss_b2: 8.23602e-09, Loss_b3: 1.71719e-08, Loss_b4: 1.65112e-08\n",
      "Iter 49000, Loss: 7.42003e-07, Loss_res: 6.32464e-07, Loss_ic1: 3.84415e-08, Loss_ic2: 2.56324e-08, Loss_b1: 3.54792e-09, Loss_b2: 8.23522e-09, Loss_b3: 1.71716e-08, Loss_b4: 1.65106e-08\n",
      "Iter 49100, Loss: 7.41946e-07, Loss_res: 6.32416e-07, Loss_ic1: 3.84371e-08, Loss_ic2: 2.56295e-08, Loss_b1: 3.54767e-09, Loss_b2: 8.23442e-09, Loss_b3: 1.71712e-08, Loss_b4: 1.65101e-08\n",
      "Iter 49200, Loss: 7.41890e-07, Loss_res: 6.32369e-07, Loss_ic1: 3.84328e-08, Loss_ic2: 2.56265e-08, Loss_b1: 3.54743e-09, Loss_b2: 8.23363e-09, Loss_b3: 1.71709e-08, Loss_b4: 1.65096e-08\n",
      "Iter 49300, Loss: 7.41833e-07, Loss_res: 6.32322e-07, Loss_ic1: 3.84285e-08, Loss_ic2: 2.56236e-08, Loss_b1: 3.54719e-09, Loss_b2: 8.23284e-09, Loss_b3: 1.71705e-08, Loss_b4: 1.65090e-08\n",
      "Iter 49400, Loss: 7.41777e-07, Loss_res: 6.32274e-07, Loss_ic1: 3.84242e-08, Loss_ic2: 2.56208e-08, Loss_b1: 3.54695e-09, Loss_b2: 8.23206e-09, Loss_b3: 1.71702e-08, Loss_b4: 1.65085e-08\n",
      "Iter 49500, Loss: 7.41721e-07, Loss_res: 6.32227e-07, Loss_ic1: 3.84199e-08, Loss_ic2: 2.56179e-08, Loss_b1: 3.54671e-09, Loss_b2: 8.23127e-09, Loss_b3: 1.71699e-08, Loss_b4: 1.65080e-08\n",
      "Iter 49600, Loss: 7.41665e-07, Loss_res: 6.32181e-07, Loss_ic1: 3.84157e-08, Loss_ic2: 2.56150e-08, Loss_b1: 3.54647e-09, Loss_b2: 8.23049e-09, Loss_b3: 1.71695e-08, Loss_b4: 1.65074e-08\n",
      "Iter 49700, Loss: 7.41609e-07, Loss_res: 6.32134e-07, Loss_ic1: 3.84114e-08, Loss_ic2: 2.56121e-08, Loss_b1: 3.54624e-09, Loss_b2: 8.22972e-09, Loss_b3: 1.71692e-08, Loss_b4: 1.65069e-08\n",
      "Iter 49800, Loss: 7.41554e-07, Loss_res: 6.32087e-07, Loss_ic1: 3.84071e-08, Loss_ic2: 2.56092e-08, Loss_b1: 3.54600e-09, Loss_b2: 8.22895e-09, Loss_b3: 1.71688e-08, Loss_b4: 1.65064e-08\n",
      "Iter 49900, Loss: 7.41498e-07, Loss_res: 6.32041e-07, Loss_ic1: 3.84029e-08, Loss_ic2: 2.56064e-08, Loss_b1: 3.54577e-09, Loss_b2: 8.22818e-09, Loss_b3: 1.71684e-08, Loss_b4: 1.65058e-08\n",
      "Iter 50000, Loss: 7.41443e-07, Loss_res: 6.31994e-07, Loss_ic1: 3.83987e-08, Loss_ic2: 2.56035e-08, Loss_b1: 3.54554e-09, Loss_b2: 8.22741e-09, Loss_b3: 1.71681e-08, Loss_b4: 1.65053e-08\n",
      "Iter 50100, Loss: 7.41387e-07, Loss_res: 6.31948e-07, Loss_ic1: 3.83944e-08, Loss_ic2: 2.56007e-08, Loss_b1: 3.54531e-09, Loss_b2: 8.22665e-09, Loss_b3: 1.71677e-08, Loss_b4: 1.65047e-08\n",
      "Iter 50200, Loss: 7.41332e-07, Loss_res: 6.31902e-07, Loss_ic1: 3.83902e-08, Loss_ic2: 2.55978e-08, Loss_b1: 3.54509e-09, Loss_b2: 8.22589e-09, Loss_b3: 1.71674e-08, Loss_b4: 1.65042e-08\n",
      "Iter 50300, Loss: 7.41277e-07, Loss_res: 6.31856e-07, Loss_ic1: 3.83860e-08, Loss_ic2: 2.55950e-08, Loss_b1: 3.54486e-09, Loss_b2: 8.22513e-09, Loss_b3: 1.71670e-08, Loss_b4: 1.65037e-08\n",
      "Iter 50400, Loss: 7.41222e-07, Loss_res: 6.31810e-07, Loss_ic1: 3.83818e-08, Loss_ic2: 2.55921e-08, Loss_b1: 3.54464e-09, Loss_b2: 8.22438e-09, Loss_b3: 1.71667e-08, Loss_b4: 1.65031e-08\n",
      "Iter 50500, Loss: 7.41168e-07, Loss_res: 6.31764e-07, Loss_ic1: 3.83777e-08, Loss_ic2: 2.55893e-08, Loss_b1: 3.54442e-09, Loss_b2: 8.22362e-09, Loss_b3: 1.71663e-08, Loss_b4: 1.65026e-08\n",
      "Iter 50600, Loss: 7.41113e-07, Loss_res: 6.31718e-07, Loss_ic1: 3.83735e-08, Loss_ic2: 2.55865e-08, Loss_b1: 3.54420e-09, Loss_b2: 8.22288e-09, Loss_b3: 1.71659e-08, Loss_b4: 1.65020e-08\n",
      "Iter 50700, Loss: 7.41059e-07, Loss_res: 6.31672e-07, Loss_ic1: 3.83693e-08, Loss_ic2: 2.55837e-08, Loss_b1: 3.54398e-09, Loss_b2: 8.22213e-09, Loss_b3: 1.71656e-08, Loss_b4: 1.65015e-08\n",
      "Iter 50800, Loss: 7.41004e-07, Loss_res: 6.31627e-07, Loss_ic1: 3.83652e-08, Loss_ic2: 2.55808e-08, Loss_b1: 3.54377e-09, Loss_b2: 8.22139e-09, Loss_b3: 1.71652e-08, Loss_b4: 1.65009e-08\n",
      "Iter 50900, Loss: 7.40950e-07, Loss_res: 6.31582e-07, Loss_ic1: 3.83610e-08, Loss_ic2: 2.55780e-08, Loss_b1: 3.54356e-09, Loss_b2: 8.22065e-09, Loss_b3: 1.71648e-08, Loss_b4: 1.65004e-08\n",
      "Iter 51000, Loss: 7.40896e-07, Loss_res: 6.31536e-07, Loss_ic1: 3.83569e-08, Loss_ic2: 2.55752e-08, Loss_b1: 3.54334e-09, Loss_b2: 8.21991e-09, Loss_b3: 1.71645e-08, Loss_b4: 1.64999e-08\n",
      "Iter 51100, Loss: 7.40842e-07, Loss_res: 6.31491e-07, Loss_ic1: 3.83528e-08, Loss_ic2: 2.55724e-08, Loss_b1: 3.54313e-09, Loss_b2: 8.21918e-09, Loss_b3: 1.71641e-08, Loss_b4: 1.64993e-08\n",
      "Iter 51200, Loss: 7.40788e-07, Loss_res: 6.31446e-07, Loss_ic1: 3.83487e-08, Loss_ic2: 2.55696e-08, Loss_b1: 3.54293e-09, Loss_b2: 8.21845e-09, Loss_b3: 1.71637e-08, Loss_b4: 1.64988e-08\n",
      "Iter 51300, Loss: 7.40735e-07, Loss_res: 6.31401e-07, Loss_ic1: 3.83446e-08, Loss_ic2: 2.55668e-08, Loss_b1: 3.54272e-09, Loss_b2: 8.21772e-09, Loss_b3: 1.71634e-08, Loss_b4: 1.64982e-08\n",
      "Iter 51400, Loss: 7.40681e-07, Loss_res: 6.31356e-07, Loss_ic1: 3.83405e-08, Loss_ic2: 2.55641e-08, Loss_b1: 3.54252e-09, Loss_b2: 8.21699e-09, Loss_b3: 1.71630e-08, Loss_b4: 1.64977e-08\n",
      "Iter 51500, Loss: 7.40627e-07, Loss_res: 6.31311e-07, Loss_ic1: 3.83364e-08, Loss_ic2: 2.55613e-08, Loss_b1: 3.54231e-09, Loss_b2: 8.21627e-09, Loss_b3: 1.71626e-08, Loss_b4: 1.64971e-08\n",
      "Iter 51600, Loss: 7.40574e-07, Loss_res: 6.31267e-07, Loss_ic1: 3.83323e-08, Loss_ic2: 2.55585e-08, Loss_b1: 3.54211e-09, Loss_b2: 8.21555e-09, Loss_b3: 1.71623e-08, Loss_b4: 1.64966e-08\n",
      "Iter 51700, Loss: 7.40521e-07, Loss_res: 6.31222e-07, Loss_ic1: 3.83283e-08, Loss_ic2: 2.55558e-08, Loss_b1: 3.54191e-09, Loss_b2: 8.21483e-09, Loss_b3: 1.71619e-08, Loss_b4: 1.64960e-08\n",
      "Iter 51800, Loss: 7.40468e-07, Loss_res: 6.31178e-07, Loss_ic1: 3.83242e-08, Loss_ic2: 2.55530e-08, Loss_b1: 3.54171e-09, Loss_b2: 8.21411e-09, Loss_b3: 1.71615e-08, Loss_b4: 1.64955e-08\n",
      "Iter 51900, Loss: 7.40415e-07, Loss_res: 6.31134e-07, Loss_ic1: 3.83202e-08, Loss_ic2: 2.55502e-08, Loss_b1: 3.54152e-09, Loss_b2: 8.21340e-09, Loss_b3: 1.71612e-08, Loss_b4: 1.64949e-08\n",
      "Iter 52000, Loss: 7.40362e-07, Loss_res: 6.31089e-07, Loss_ic1: 3.83162e-08, Loss_ic2: 2.55475e-08, Loss_b1: 3.54132e-09, Loss_b2: 8.21269e-09, Loss_b3: 1.71608e-08, Loss_b4: 1.64944e-08\n",
      "Iter 52100, Loss: 7.40309e-07, Loss_res: 6.31045e-07, Loss_ic1: 3.83121e-08, Loss_ic2: 2.55447e-08, Loss_b1: 3.54113e-09, Loss_b2: 8.21198e-09, Loss_b3: 1.71604e-08, Loss_b4: 1.64938e-08\n",
      "Iter 52200, Loss: 7.40257e-07, Loss_res: 6.31001e-07, Loss_ic1: 3.83081e-08, Loss_ic2: 2.55420e-08, Loss_b1: 3.54094e-09, Loss_b2: 8.21128e-09, Loss_b3: 1.71600e-08, Loss_b4: 1.64933e-08\n",
      "Iter 52300, Loss: 7.40204e-07, Loss_res: 6.30957e-07, Loss_ic1: 3.83041e-08, Loss_ic2: 2.55393e-08, Loss_b1: 3.54075e-09, Loss_b2: 8.21058e-09, Loss_b3: 1.71597e-08, Loss_b4: 1.64927e-08\n",
      "Iter 52400, Loss: 7.40152e-07, Loss_res: 6.30913e-07, Loss_ic1: 3.83001e-08, Loss_ic2: 2.55365e-08, Loss_b1: 3.54056e-09, Loss_b2: 8.20987e-09, Loss_b3: 1.71593e-08, Loss_b4: 1.64922e-08\n",
      "Iter 52500, Loss: 7.40100e-07, Loss_res: 6.30870e-07, Loss_ic1: 3.82961e-08, Loss_ic2: 2.55338e-08, Loss_b1: 3.54037e-09, Loss_b2: 8.20918e-09, Loss_b3: 1.71589e-08, Loss_b4: 1.64916e-08\n",
      "Iter 52600, Loss: 7.40048e-07, Loss_res: 6.30826e-07, Loss_ic1: 3.82922e-08, Loss_ic2: 2.55311e-08, Loss_b1: 3.54019e-09, Loss_b2: 8.20848e-09, Loss_b3: 1.71586e-08, Loss_b4: 1.64911e-08\n",
      "Iter 52700, Loss: 7.39996e-07, Loss_res: 6.30783e-07, Loss_ic1: 3.82882e-08, Loss_ic2: 2.55284e-08, Loss_b1: 3.54000e-09, Loss_b2: 8.20779e-09, Loss_b3: 1.71582e-08, Loss_b4: 1.64905e-08\n",
      "Iter 52800, Loss: 7.39944e-07, Loss_res: 6.30739e-07, Loss_ic1: 3.82842e-08, Loss_ic2: 2.55257e-08, Loss_b1: 3.53982e-09, Loss_b2: 8.20710e-09, Loss_b3: 1.71578e-08, Loss_b4: 1.64899e-08\n",
      "Iter 52900, Loss: 7.39892e-07, Loss_res: 6.30696e-07, Loss_ic1: 3.82803e-08, Loss_ic2: 2.55230e-08, Loss_b1: 3.53964e-09, Loss_b2: 8.20641e-09, Loss_b3: 1.71575e-08, Loss_b4: 1.64894e-08\n",
      "Iter 53000, Loss: 7.39840e-07, Loss_res: 6.30653e-07, Loss_ic1: 3.82763e-08, Loss_ic2: 2.55203e-08, Loss_b1: 3.53946e-09, Loss_b2: 8.20572e-09, Loss_b3: 1.71571e-08, Loss_b4: 1.64888e-08\n",
      "Iter 53100, Loss: 7.39789e-07, Loss_res: 6.30610e-07, Loss_ic1: 3.82724e-08, Loss_ic2: 2.55176e-08, Loss_b1: 3.53928e-09, Loss_b2: 8.20504e-09, Loss_b3: 1.71567e-08, Loss_b4: 1.64883e-08\n",
      "Iter 53200, Loss: 7.39738e-07, Loss_res: 6.30567e-07, Loss_ic1: 3.82685e-08, Loss_ic2: 2.55149e-08, Loss_b1: 3.53911e-09, Loss_b2: 8.20436e-09, Loss_b3: 1.71564e-08, Loss_b4: 1.64877e-08\n",
      "Iter 53300, Loss: 7.39686e-07, Loss_res: 6.30524e-07, Loss_ic1: 3.82646e-08, Loss_ic2: 2.55122e-08, Loss_b1: 3.53893e-09, Loss_b2: 8.20368e-09, Loss_b3: 1.71560e-08, Loss_b4: 1.64872e-08\n",
      "Iter 53400, Loss: 7.39635e-07, Loss_res: 6.30481e-07, Loss_ic1: 3.82607e-08, Loss_ic2: 2.55096e-08, Loss_b1: 3.53876e-09, Loss_b2: 8.20300e-09, Loss_b3: 1.71556e-08, Loss_b4: 1.64866e-08\n",
      "Iter 53500, Loss: 7.39584e-07, Loss_res: 6.30438e-07, Loss_ic1: 3.82568e-08, Loss_ic2: 2.55069e-08, Loss_b1: 3.53859e-09, Loss_b2: 8.20232e-09, Loss_b3: 1.71553e-08, Loss_b4: 1.64861e-08\n",
      "Iter 53600, Loss: 7.39533e-07, Loss_res: 6.30395e-07, Loss_ic1: 3.82529e-08, Loss_ic2: 2.55042e-08, Loss_b1: 3.53842e-09, Loss_b2: 8.20165e-09, Loss_b3: 1.71549e-08, Loss_b4: 1.64855e-08\n",
      "Iter 53700, Loss: 7.39482e-07, Loss_res: 6.30353e-07, Loss_ic1: 3.82490e-08, Loss_ic2: 2.55016e-08, Loss_b1: 3.53825e-09, Loss_b2: 8.20098e-09, Loss_b3: 1.71545e-08, Loss_b4: 1.64850e-08\n",
      "Iter 53800, Loss: 7.39431e-07, Loss_res: 6.30310e-07, Loss_ic1: 3.82451e-08, Loss_ic2: 2.54989e-08, Loss_b1: 3.53808e-09, Loss_b2: 8.20031e-09, Loss_b3: 1.71542e-08, Loss_b4: 1.64844e-08\n",
      "Iter 53900, Loss: 7.39381e-07, Loss_res: 6.30268e-07, Loss_ic1: 3.82412e-08, Loss_ic2: 2.54963e-08, Loss_b1: 3.53792e-09, Loss_b2: 8.19964e-09, Loss_b3: 1.71538e-08, Loss_b4: 1.64838e-08\n",
      "Iter 54000, Loss: 7.39330e-07, Loss_res: 6.30226e-07, Loss_ic1: 3.82374e-08, Loss_ic2: 2.54936e-08, Loss_b1: 3.53776e-09, Loss_b2: 8.19898e-09, Loss_b3: 1.71534e-08, Loss_b4: 1.64833e-08\n",
      "Iter 54100, Loss: 7.39280e-07, Loss_res: 6.30184e-07, Loss_ic1: 3.82335e-08, Loss_ic2: 2.54910e-08, Loss_b1: 3.53759e-09, Loss_b2: 8.19831e-09, Loss_b3: 1.71531e-08, Loss_b4: 1.64827e-08\n",
      "Iter 54200, Loss: 7.39230e-07, Loss_res: 6.30142e-07, Loss_ic1: 3.82297e-08, Loss_ic2: 2.54884e-08, Loss_b1: 3.53743e-09, Loss_b2: 8.19765e-09, Loss_b3: 1.71527e-08, Loss_b4: 1.64822e-08\n",
      "Iter 54300, Loss: 7.39179e-07, Loss_res: 6.30100e-07, Loss_ic1: 3.82259e-08, Loss_ic2: 2.54857e-08, Loss_b1: 3.53727e-09, Loss_b2: 8.19699e-09, Loss_b3: 1.71523e-08, Loss_b4: 1.64816e-08\n",
      "Iter 54400, Loss: 7.39129e-07, Loss_res: 6.30058e-07, Loss_ic1: 3.82221e-08, Loss_ic2: 2.54831e-08, Loss_b1: 3.53711e-09, Loss_b2: 8.19634e-09, Loss_b3: 1.71520e-08, Loss_b4: 1.64811e-08\n",
      "Iter 54500, Loss: 7.39079e-07, Loss_res: 6.30016e-07, Loss_ic1: 3.82182e-08, Loss_ic2: 2.54805e-08, Loss_b1: 3.53696e-09, Loss_b2: 8.19568e-09, Loss_b3: 1.71516e-08, Loss_b4: 1.64805e-08\n",
      "Iter 54600, Loss: 7.39030e-07, Loss_res: 6.29974e-07, Loss_ic1: 3.82144e-08, Loss_ic2: 2.54779e-08, Loss_b1: 3.53680e-09, Loss_b2: 8.19503e-09, Loss_b3: 1.71513e-08, Loss_b4: 1.64799e-08\n",
      "Iter 54700, Loss: 7.38980e-07, Loss_res: 6.29933e-07, Loss_ic1: 3.82106e-08, Loss_ic2: 2.54753e-08, Loss_b1: 3.53665e-09, Loss_b2: 8.19438e-09, Loss_b3: 1.71509e-08, Loss_b4: 1.64794e-08\n",
      "Iter 54800, Loss: 7.38930e-07, Loss_res: 6.29891e-07, Loss_ic1: 3.82068e-08, Loss_ic2: 2.54727e-08, Loss_b1: 3.53649e-09, Loss_b2: 8.19373e-09, Loss_b3: 1.71505e-08, Loss_b4: 1.64788e-08\n",
      "Iter 54900, Loss: 7.38881e-07, Loss_res: 6.29850e-07, Loss_ic1: 3.82031e-08, Loss_ic2: 2.54701e-08, Loss_b1: 3.53634e-09, Loss_b2: 8.19308e-09, Loss_b3: 1.71502e-08, Loss_b4: 1.64783e-08\n",
      "Iter 55000, Loss: 7.38831e-07, Loss_res: 6.29808e-07, Loss_ic1: 3.81993e-08, Loss_ic2: 2.54675e-08, Loss_b1: 3.53619e-09, Loss_b2: 8.19244e-09, Loss_b3: 1.71498e-08, Loss_b4: 1.64777e-08\n",
      "Iter 55100, Loss: 7.38782e-07, Loss_res: 6.29767e-07, Loss_ic1: 3.81955e-08, Loss_ic2: 2.54649e-08, Loss_b1: 3.53604e-09, Loss_b2: 8.19179e-09, Loss_b3: 1.71495e-08, Loss_b4: 1.64772e-08\n",
      "Iter 55200, Loss: 7.38733e-07, Loss_res: 6.29726e-07, Loss_ic1: 3.81918e-08, Loss_ic2: 2.54624e-08, Loss_b1: 3.53590e-09, Loss_b2: 8.19115e-09, Loss_b3: 1.71491e-08, Loss_b4: 1.64766e-08\n",
      "Iter 55300, Loss: 7.38684e-07, Loss_res: 6.29685e-07, Loss_ic1: 3.81880e-08, Loss_ic2: 2.54598e-08, Loss_b1: 3.53575e-09, Loss_b2: 8.19051e-09, Loss_b3: 1.71488e-08, Loss_b4: 1.64760e-08\n",
      "Iter 55400, Loss: 7.38634e-07, Loss_res: 6.29644e-07, Loss_ic1: 3.81843e-08, Loss_ic2: 2.54572e-08, Loss_b1: 3.53561e-09, Loss_b2: 8.18987e-09, Loss_b3: 1.71484e-08, Loss_b4: 1.64755e-08\n",
      "Iter 55500, Loss: 7.38586e-07, Loss_res: 6.29603e-07, Loss_ic1: 3.81805e-08, Loss_ic2: 2.54547e-08, Loss_b1: 3.53546e-09, Loss_b2: 8.18924e-09, Loss_b3: 1.71481e-08, Loss_b4: 1.64749e-08\n",
      "Iter 55600, Loss: 7.38537e-07, Loss_res: 6.29562e-07, Loss_ic1: 3.81768e-08, Loss_ic2: 2.54521e-08, Loss_b1: 3.53532e-09, Loss_b2: 8.18860e-09, Loss_b3: 1.71477e-08, Loss_b4: 1.64744e-08\n",
      "Iter 55700, Loss: 7.38488e-07, Loss_res: 6.29521e-07, Loss_ic1: 3.81731e-08, Loss_ic2: 2.54495e-08, Loss_b1: 3.53518e-09, Loss_b2: 8.18797e-09, Loss_b3: 1.71474e-08, Loss_b4: 1.64738e-08\n",
      "Iter 55800, Loss: 7.38439e-07, Loss_res: 6.29480e-07, Loss_ic1: 3.81694e-08, Loss_ic2: 2.54470e-08, Loss_b1: 3.53504e-09, Loss_b2: 8.18734e-09, Loss_b3: 1.71470e-08, Loss_b4: 1.64732e-08\n",
      "Iter 55900, Loss: 7.38391e-07, Loss_res: 6.29440e-07, Loss_ic1: 3.81657e-08, Loss_ic2: 2.54445e-08, Loss_b1: 3.53490e-09, Loss_b2: 8.18671e-09, Loss_b3: 1.71467e-08, Loss_b4: 1.64727e-08\n",
      "Iter 56000, Loss: 7.38342e-07, Loss_res: 6.29399e-07, Loss_ic1: 3.81620e-08, Loss_ic2: 2.54419e-08, Loss_b1: 3.53477e-09, Loss_b2: 8.18608e-09, Loss_b3: 1.71463e-08, Loss_b4: 1.64721e-08\n",
      "Iter 56100, Loss: 7.38294e-07, Loss_res: 6.29359e-07, Loss_ic1: 3.81583e-08, Loss_ic2: 2.54394e-08, Loss_b1: 3.53463e-09, Loss_b2: 8.18545e-09, Loss_b3: 1.71460e-08, Loss_b4: 1.64716e-08\n",
      "Iter 56200, Loss: 7.38246e-07, Loss_res: 6.29319e-07, Loss_ic1: 3.81546e-08, Loss_ic2: 2.54369e-08, Loss_b1: 3.53450e-09, Loss_b2: 8.18483e-09, Loss_b3: 1.71456e-08, Loss_b4: 1.64710e-08\n",
      "Iter 56300, Loss: 7.38198e-07, Loss_res: 6.29278e-07, Loss_ic1: 3.81509e-08, Loss_ic2: 2.54343e-08, Loss_b1: 3.53436e-09, Loss_b2: 8.18421e-09, Loss_b3: 1.71453e-08, Loss_b4: 1.64705e-08\n",
      "Iter 56400, Loss: 7.38150e-07, Loss_res: 6.29238e-07, Loss_ic1: 3.81473e-08, Loss_ic2: 2.54318e-08, Loss_b1: 3.53423e-09, Loss_b2: 8.18359e-09, Loss_b3: 1.71450e-08, Loss_b4: 1.64699e-08\n",
      "Iter 56500, Loss: 7.38102e-07, Loss_res: 6.29198e-07, Loss_ic1: 3.81436e-08, Loss_ic2: 2.54293e-08, Loss_b1: 3.53410e-09, Loss_b2: 8.18297e-09, Loss_b3: 1.71446e-08, Loss_b4: 1.64693e-08\n",
      "Iter 56600, Loss: 7.38054e-07, Loss_res: 6.29158e-07, Loss_ic1: 3.81400e-08, Loss_ic2: 2.54268e-08, Loss_b1: 3.53397e-09, Loss_b2: 8.18235e-09, Loss_b3: 1.71443e-08, Loss_b4: 1.64688e-08\n",
      "Iter 56700, Loss: 7.38006e-07, Loss_res: 6.29118e-07, Loss_ic1: 3.81363e-08, Loss_ic2: 2.54243e-08, Loss_b1: 3.53385e-09, Loss_b2: 8.18173e-09, Loss_b3: 1.71439e-08, Loss_b4: 1.64682e-08\n",
      "Iter 56800, Loss: 7.37959e-07, Loss_res: 6.29078e-07, Loss_ic1: 3.81327e-08, Loss_ic2: 2.54218e-08, Loss_b1: 3.53372e-09, Loss_b2: 8.18112e-09, Loss_b3: 1.71436e-08, Loss_b4: 1.64677e-08\n",
      "Iter 56900, Loss: 7.37911e-07, Loss_res: 6.29038e-07, Loss_ic1: 3.81290e-08, Loss_ic2: 2.54193e-08, Loss_b1: 3.53359e-09, Loss_b2: 8.18051e-09, Loss_b3: 1.71433e-08, Loss_b4: 1.64671e-08\n",
      "Iter 57000, Loss: 7.37864e-07, Loss_res: 6.28999e-07, Loss_ic1: 3.81254e-08, Loss_ic2: 2.54168e-08, Loss_b1: 3.53347e-09, Loss_b2: 8.17989e-09, Loss_b3: 1.71429e-08, Loss_b4: 1.64666e-08\n",
      "Iter 57100, Loss: 7.37816e-07, Loss_res: 6.28959e-07, Loss_ic1: 3.81218e-08, Loss_ic2: 2.54143e-08, Loss_b1: 3.53335e-09, Loss_b2: 8.17929e-09, Loss_b3: 1.71426e-08, Loss_b4: 1.64660e-08\n",
      "Iter 57200, Loss: 7.37769e-07, Loss_res: 6.28920e-07, Loss_ic1: 3.81182e-08, Loss_ic2: 2.54119e-08, Loss_b1: 3.53322e-09, Loss_b2: 8.17868e-09, Loss_b3: 1.71423e-08, Loss_b4: 1.64654e-08\n",
      "Iter 57300, Loss: 7.37722e-07, Loss_res: 6.28880e-07, Loss_ic1: 3.81146e-08, Loss_ic2: 2.54094e-08, Loss_b1: 3.53310e-09, Loss_b2: 8.17807e-09, Loss_b3: 1.71420e-08, Loss_b4: 1.64649e-08\n",
      "Iter 57400, Loss: 7.37675e-07, Loss_res: 6.28841e-07, Loss_ic1: 3.81110e-08, Loss_ic2: 2.54069e-08, Loss_b1: 3.53298e-09, Loss_b2: 8.17746e-09, Loss_b3: 1.71416e-08, Loss_b4: 1.64643e-08\n",
      "Iter 57500, Loss: 7.37628e-07, Loss_res: 6.28801e-07, Loss_ic1: 3.81074e-08, Loss_ic2: 2.54045e-08, Loss_b1: 3.53287e-09, Loss_b2: 8.17686e-09, Loss_b3: 1.71413e-08, Loss_b4: 1.64638e-08\n",
      "Iter 57600, Loss: 7.37581e-07, Loss_res: 6.28762e-07, Loss_ic1: 3.81038e-08, Loss_ic2: 2.54020e-08, Loss_b1: 3.53275e-09, Loss_b2: 8.17626e-09, Loss_b3: 1.71410e-08, Loss_b4: 1.64632e-08\n",
      "Iter 57700, Loss: 7.37534e-07, Loss_res: 6.28723e-07, Loss_ic1: 3.81003e-08, Loss_ic2: 2.53996e-08, Loss_b1: 3.53263e-09, Loss_b2: 8.17566e-09, Loss_b3: 1.71407e-08, Loss_b4: 1.64627e-08\n",
      "Iter 57800, Loss: 7.37488e-07, Loss_res: 6.28684e-07, Loss_ic1: 3.80967e-08, Loss_ic2: 2.53971e-08, Loss_b1: 3.53252e-09, Loss_b2: 8.17506e-09, Loss_b3: 1.71403e-08, Loss_b4: 1.64621e-08\n",
      "Iter 57900, Loss: 7.37441e-07, Loss_res: 6.28645e-07, Loss_ic1: 3.80931e-08, Loss_ic2: 2.53947e-08, Loss_b1: 3.53240e-09, Loss_b2: 8.17446e-09, Loss_b3: 1.71400e-08, Loss_b4: 1.64615e-08\n",
      "Iter 58000, Loss: 7.37395e-07, Loss_res: 6.28606e-07, Loss_ic1: 3.80896e-08, Loss_ic2: 2.53922e-08, Loss_b1: 3.53229e-09, Loss_b2: 8.17386e-09, Loss_b3: 1.71397e-08, Loss_b4: 1.64610e-08\n",
      "Iter 58100, Loss: 7.37348e-07, Loss_res: 6.28567e-07, Loss_ic1: 3.80860e-08, Loss_ic2: 2.53898e-08, Loss_b1: 3.53218e-09, Loss_b2: 8.17327e-09, Loss_b3: 1.71394e-08, Loss_b4: 1.64604e-08\n",
      "Iter 58200, Loss: 7.37302e-07, Loss_res: 6.28528e-07, Loss_ic1: 3.80825e-08, Loss_ic2: 2.53874e-08, Loss_b1: 3.53207e-09, Loss_b2: 8.17267e-09, Loss_b3: 1.71391e-08, Loss_b4: 1.64599e-08\n",
      "Iter 58300, Loss: 7.37256e-07, Loss_res: 6.28490e-07, Loss_ic1: 3.80790e-08, Loss_ic2: 2.53849e-08, Loss_b1: 3.53196e-09, Loss_b2: 8.17208e-09, Loss_b3: 1.71387e-08, Loss_b4: 1.64593e-08\n",
      "Iter 58400, Loss: 7.37209e-07, Loss_res: 6.28451e-07, Loss_ic1: 3.80754e-08, Loss_ic2: 2.53825e-08, Loss_b1: 3.53185e-09, Loss_b2: 8.17149e-09, Loss_b3: 1.71384e-08, Loss_b4: 1.64588e-08\n",
      "Iter 58500, Loss: 7.37163e-07, Loss_res: 6.28412e-07, Loss_ic1: 3.80719e-08, Loss_ic2: 2.53801e-08, Loss_b1: 3.53175e-09, Loss_b2: 8.17090e-09, Loss_b3: 1.71381e-08, Loss_b4: 1.64582e-08\n",
      "Iter 58600, Loss: 7.37117e-07, Loss_res: 6.28374e-07, Loss_ic1: 3.80684e-08, Loss_ic2: 2.53777e-08, Loss_b1: 3.53164e-09, Loss_b2: 8.17031e-09, Loss_b3: 1.71378e-08, Loss_b4: 1.64576e-08\n",
      "Iter 58700, Loss: 7.37072e-07, Loss_res: 6.28336e-07, Loss_ic1: 3.80649e-08, Loss_ic2: 2.53753e-08, Loss_b1: 3.53154e-09, Loss_b2: 8.16973e-09, Loss_b3: 1.71375e-08, Loss_b4: 1.64571e-08\n",
      "Iter 58800, Loss: 7.37026e-07, Loss_res: 6.28297e-07, Loss_ic1: 3.80614e-08, Loss_ic2: 2.53729e-08, Loss_b1: 3.53143e-09, Loss_b2: 8.16914e-09, Loss_b3: 1.71372e-08, Loss_b4: 1.64565e-08\n",
      "Iter 58900, Loss: 7.36980e-07, Loss_res: 6.28259e-07, Loss_ic1: 3.80579e-08, Loss_ic2: 2.53705e-08, Loss_b1: 3.53133e-09, Loss_b2: 8.16856e-09, Loss_b3: 1.71369e-08, Loss_b4: 1.64560e-08\n",
      "Iter 59000, Loss: 7.36935e-07, Loss_res: 6.28221e-07, Loss_ic1: 3.80544e-08, Loss_ic2: 2.53681e-08, Loss_b1: 3.53123e-09, Loss_b2: 8.16797e-09, Loss_b3: 1.71366e-08, Loss_b4: 1.64554e-08\n",
      "Iter 59100, Loss: 7.36889e-07, Loss_res: 6.28183e-07, Loss_ic1: 3.80509e-08, Loss_ic2: 2.53657e-08, Loss_b1: 3.53113e-09, Loss_b2: 8.16739e-09, Loss_b3: 1.71363e-08, Loss_b4: 1.64549e-08\n",
      "Iter 59200, Loss: 7.36844e-07, Loss_res: 6.28145e-07, Loss_ic1: 3.80475e-08, Loss_ic2: 2.53634e-08, Loss_b1: 3.53103e-09, Loss_b2: 8.16681e-09, Loss_b3: 1.71360e-08, Loss_b4: 1.64543e-08\n",
      "Iter 59300, Loss: 7.36798e-07, Loss_res: 6.28107e-07, Loss_ic1: 3.80440e-08, Loss_ic2: 2.53610e-08, Loss_b1: 3.53093e-09, Loss_b2: 8.16623e-09, Loss_b3: 1.71357e-08, Loss_b4: 1.64538e-08\n",
      "Iter 59400, Loss: 7.36753e-07, Loss_res: 6.28069e-07, Loss_ic1: 3.80405e-08, Loss_ic2: 2.53586e-08, Loss_b1: 3.53083e-09, Loss_b2: 8.16566e-09, Loss_b3: 1.71354e-08, Loss_b4: 1.64532e-08\n",
      "Iter 59500, Loss: 7.36708e-07, Loss_res: 6.28031e-07, Loss_ic1: 3.80371e-08, Loss_ic2: 2.53562e-08, Loss_b1: 3.53074e-09, Loss_b2: 8.16508e-09, Loss_b3: 1.71351e-08, Loss_b4: 1.64527e-08\n",
      "Iter 59600, Loss: 7.36663e-07, Loss_res: 6.27993e-07, Loss_ic1: 3.80336e-08, Loss_ic2: 2.53539e-08, Loss_b1: 3.53064e-09, Loss_b2: 8.16450e-09, Loss_b3: 1.71348e-08, Loss_b4: 1.64521e-08\n",
      "Iter 59700, Loss: 7.36618e-07, Loss_res: 6.27955e-07, Loss_ic1: 3.80302e-08, Loss_ic2: 2.53515e-08, Loss_b1: 3.53055e-09, Loss_b2: 8.16393e-09, Loss_b3: 1.71345e-08, Loss_b4: 1.64516e-08\n",
      "Iter 59800, Loss: 7.36573e-07, Loss_res: 6.27918e-07, Loss_ic1: 3.80268e-08, Loss_ic2: 2.53492e-08, Loss_b1: 3.53045e-09, Loss_b2: 8.16336e-09, Loss_b3: 1.71342e-08, Loss_b4: 1.64510e-08\n",
      "Iter 59900, Loss: 7.36528e-07, Loss_res: 6.27880e-07, Loss_ic1: 3.80233e-08, Loss_ic2: 2.53468e-08, Loss_b1: 3.53036e-09, Loss_b2: 8.16279e-09, Loss_b3: 1.71340e-08, Loss_b4: 1.64505e-08\n",
      "Iter 60000, Loss: 7.36483e-07, Loss_res: 6.27843e-07, Loss_ic1: 3.80199e-08, Loss_ic2: 2.53445e-08, Loss_b1: 3.53027e-09, Loss_b2: 8.16222e-09, Loss_b3: 1.71337e-08, Loss_b4: 1.64499e-08\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d954aad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T14:30:10.192803Z",
     "iopub.status.busy": "2025-12-06T14:30:10.192522Z",
     "iopub.status.idle": "2025-12-06T14:30:10.195818Z",
     "shell.execute_reply": "2025-12-06T14:30:10.195233Z"
    },
    "papermill": {
     "duration": 0.031075,
     "end_time": "2025-12-06T14:30:10.196968",
     "exception": false,
     "start_time": "2025-12-06T14:30:10.165893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_states1 = {\"model\": model.net.state_dict(), \"LBFGS\": model.optimizer2.state_dict()}\n",
    "# torch.save(obj=all_states1, f=\"/kaggle/working/all_states1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35fb07f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T14:30:10.249245Z",
     "iopub.status.busy": "2025-12-06T14:30:10.248967Z",
     "iopub.status.idle": "2025-12-06T14:30:10.319993Z",
     "shell.execute_reply": "2025-12-06T14:30:10.319377Z"
    },
    "papermill": {
     "duration": 0.098758,
     "end_time": "2025-12-06T14:30:10.321357",
     "exception": false,
     "start_time": "2025-12-06T14:30:10.222599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "u_p,v_p = model.predict(X)\n",
    "u_true = func_u(X)\n",
    "v_true = func_v(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96949af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T14:30:10.375151Z",
     "iopub.status.busy": "2025-12-06T14:30:10.374460Z",
     "iopub.status.idle": "2025-12-06T14:30:10.381449Z",
     "shell.execute_reply": "2025-12-06T14:30:10.380708Z"
    },
    "papermill": {
     "duration": 0.034698,
     "end_time": "2025-12-06T14:30:10.382599",
     "exception": false,
     "start_time": "2025-12-06T14:30:10.347901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001447785275423277\n"
     ]
    }
   ],
   "source": [
    "L2 = np.linalg.norm(u_p.flatten() - u_true.flatten())/np.linalg.norm(u_true.flatten())\n",
    "\n",
    "print (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "201be943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T14:30:10.438600Z",
     "iopub.status.busy": "2025-12-06T14:30:10.438117Z",
     "iopub.status.idle": "2025-12-06T14:30:10.443000Z",
     "shell.execute_reply": "2025-12-06T14:30:10.442403Z"
    },
    "papermill": {
     "duration": 0.032972,
     "end_time": "2025-12-06T14:30:10.444027",
     "exception": false,
     "start_time": "2025-12-06T14:30:10.411055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001677824242172674\n"
     ]
    }
   ],
   "source": [
    "L2 = np.linalg.norm(v_p.flatten() - v_true.flatten())/np.linalg.norm(v_true.flatten())\n",
    "\n",
    "print (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fcf235e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T14:30:10.497857Z",
     "iopub.status.busy": "2025-12-06T14:30:10.497154Z",
     "iopub.status.idle": "2025-12-06T14:30:10.506272Z",
     "shell.execute_reply": "2025-12-06T14:30:10.505514Z"
    },
    "papermill": {
     "duration": 0.03719,
     "end_time": "2025-12-06T14:30:10.507438",
     "exception": false,
     "start_time": "2025-12-06T14:30:10.470248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pinndata = {\n",
    "    'x': x_mesh.flatten()[:, None],       # x网格数据（竖排）\n",
    "    't': t_mesh.flatten()[:, None],       # t网格数据（竖排）\n",
    "    'h_true': u_true.flatten()[:, None],  # u真实值（竖排）\n",
    "    'g_true': v_true.flatten()[:, None],  # v真实值（竖排）\n",
    "    'h_pred': u_p.flatten()[:, None],     # u预测值（竖排）\n",
    "    'g_pred': v_p.flatten()[:, None]      # v预测值（竖排）\n",
    "}\n",
    "\n",
    "# 保存到单个MAT文件\n",
    "scipy.io.savemat('pinnall_data.mat', pinndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98c538e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T14:30:10.559931Z",
     "iopub.status.busy": "2025-12-06T14:30:10.559671Z",
     "iopub.status.idle": "2025-12-06T14:30:10.563199Z",
     "shell.execute_reply": "2025-12-06T14:30:10.562684Z"
    },
    "papermill": {
     "duration": 0.030967,
     "end_time": "2025-12-06T14:30:10.564211",
     "exception": false,
     "start_time": "2025-12-06T14:30:10.533244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_total = model.loss_history['total']\n",
    "loss_residual = model.loss_history['residual']\n",
    "loss_ic = model.loss_history['ic']\n",
    "loss_b = model.loss_history['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33caf035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T14:30:10.618088Z",
     "iopub.status.busy": "2025-12-06T14:30:10.617381Z",
     "iopub.status.idle": "2025-12-06T14:30:10.621593Z",
     "shell.execute_reply": "2025-12-06T14:30:10.620961Z"
    },
    "papermill": {
     "duration": 0.032543,
     "end_time": "2025-12-06T14:30:10.622714",
     "exception": false,
     "start_time": "2025-12-06T14:30:10.590171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_iterations = len(loss_total)  # 损失记录的总数量（即总迭代次数）\n",
    "iter_steps = list(range(100, 100 + num_iterations * 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ffe559e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T14:30:10.677137Z",
     "iopub.status.busy": "2025-12-06T14:30:10.676485Z",
     "iopub.status.idle": "2025-12-06T14:30:10.682108Z",
     "shell.execute_reply": "2025-12-06T14:30:10.681609Z"
    },
    "papermill": {
     "duration": 0.034083,
     "end_time": "2025-12-06T14:30:10.683147",
     "exception": false,
     "start_time": "2025-12-06T14:30:10.649064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. 将数据转换为竖排（列向量）：通过reshape(-1, 1)实现，形状变为(n, 1)\n",
    "iter_steps_col = np.array(iter_steps).reshape(-1, 1)       # 竖排迭代步数\n",
    "loss_total_col = np.array(loss_total).reshape(-1, 1)       # 竖排总损失\n",
    "loss_residual_col = np.array(loss_residual).reshape(-1, 1) # 竖排残差损失\n",
    "loss_ic_col = np.array(loss_ic).reshape(-1, 1)             # 竖排初始条件损失\n",
    "loss_b_col = np.array(loss_b).reshape(-1, 1)               # 竖排边界条件损失\n",
    "\n",
    "# 4. 整理并保存为mat文件（此时所有数据均为列向量）\n",
    "data_loss = {\n",
    "    'iter_steps': iter_steps_col,\n",
    "    'loss_total': loss_total_col,\n",
    "    'loss_residual': loss_residual_col,\n",
    "    'loss_ic': loss_ic_col,\n",
    "    'loss_b': loss_b_col\n",
    "}\n",
    "\n",
    "scipy.io.savemat('pinnloss_history.mat', data_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "198a1fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T14:30:10.737351Z",
     "iopub.status.busy": "2025-12-06T14:30:10.736750Z",
     "iopub.status.idle": "2025-12-06T14:30:10.740060Z",
     "shell.execute_reply": "2025-12-06T14:30:10.739490Z"
    },
    "papermill": {
     "duration": 0.031591,
     "end_time": "2025-12-06T14:30:10.741058",
     "exception": false,
     "start_time": "2025-12-06T14:30:10.709467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scipy.io.savemat('3wavedata_PINN/x.mat', {'array': x_mesh.flatten()[:, None]})\n",
    "# scipy.io.savemat('3wavedata_PINN/t.mat', {'array': t_mesh.flatten()[:, None]})\n",
    "# scipy.io.savemat('3wavedata_PINN/h_true.mat', {'array': u_true.flatten()[:, None]})\n",
    "# scipy.io.savemat('3wavedata_PINN/g_true.mat', {'array': v_true.flatten()[:, None]})\n",
    "# scipy.io.savemat('3wavedata_PINN/h_pred.mat', {'array': u_p.flatten()[:, None]})\n",
    "# scipy.io.savemat('3wavedata_PINN/g_pred.mat', {'array': v_p.flatten()[:, None]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8a31b",
   "metadata": {
    "papermill": {
     "duration": 0.026225,
     "end_time": "2025-12-06T14:30:10.793922",
     "exception": false,
     "start_time": "2025-12-06T14:30:10.767697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8883561,
     "sourceId": 13939329,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8933757,
     "sourceId": 14029436,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2217.675237,
   "end_time": "2025-12-06T14:30:12.541441",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-06T13:53:14.866204",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
